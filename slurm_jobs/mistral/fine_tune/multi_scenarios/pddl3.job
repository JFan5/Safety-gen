#!/bin/bash

#SBATCH --mail-user=jfan5@nd.edu
#SBATCH --mail-type=BEGIN,END,FAIL
#SBATCH --partition=gpu
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=28
#SBATCH --job-name=fine_tune_mistral_pddl3
#SBATCH --output=fine_tune_mistral_pddl3.o

conda activate llmstl

# Fine-tune Mistral on the PDDL3 multi-scenario dataset.
# Ensure the dataset is generated via:
#   python3 script/collect_finetuned_dataset_together.py --pddl PDDL3 --output data/sft/multiple_scenarios/combined_pddl3.hf

MODEL_NAME="unsloth/mistral-7b-instruct-v0.3-bnb-4bit"
DATASET_PATH="data/sft/multiple_scenarios/combined_pddl3.hf"
OUTPUT_NOTE="mistral_multi_pddl3"

if [ ! -d "${DATASET_PATH}" ]; then
  echo "Dataset not found at ${DATASET_PATH}"
  echo "Please generate it before submitting this job."
  exit 1
fi

python3 pddl_finetune.py \
  --mode train \
  --model "${MODEL_NAME}" \
  --output "${OUTPUT_NOTE}" \
  --dataset "${DATASET_PATH}" \
  --scenarios all


CondaError: Run 'conda init' before 'conda activate'

[torchao|WARNING]Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA A100 80GB PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.10.12: Fast Gpt_Oss patching. Transformers: 4.56.2.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.00s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.11s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.46it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.22it/s]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from data/sft/ferry/pddl3.hf...
Loading HuggingFace dataset...
Dataset loaded with 2000 entries
Scenario distribution:
  ferry: 2000

Filtering scenarios to: ['ferry']
Filtered dataset size: 2000
Processing dataset format (chat template)...
Map:   0%|          | 0/1900 [00:00<?, ? examples/s]Map:  16%|â–ˆâ–Œ        | 305/1900 [00:00<00:00, 3025.99 examples/s]Map:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1000/1900 [00:00<00:00, 4929.92 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 1896/1900 [00:00<00:00, 6686.95 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:00<00:00, 5607.82 examples/s]
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 5702.50 examples/s]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251030_223744-vh7ntzdc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_pddl3
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/vh7ntzdc
wandb: Detected [huggingface_hub.inference] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Testing initial model performance...
Initial model output:
analysisWe need to parse domain and problem. The domain: ferry domain, actions: sail, board, debark. This problem: initial state - at-c0 l2, at-c1 l0, at-c2 l0, at-ferry l0, empty-ferry. Goal: c0 at l1, c1 at l0, c2 at l2. Also there are constraints: 
1) (sometime-before (at c0 l1) (at-ferry l0))
2) (sometime-before (at c2 l2) (at-ferry l1))

Interpretation: there must be some ordering constraints between events: (at c0 l1) must happen before (at-ferry l0). Wait, but (at-ferry l0) is the state t...

Resolved training arguments:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-05
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 2048
  load_in_4bit: True

Creating trainer...
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/1900 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   3%|â–Ž         | 60/1900 [00:01<00:57, 31.78 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   6%|â–‹         | 120/1900 [00:02<00:27, 65.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  13%|â–ˆâ–Ž        | 240/1900 [00:02<00:13, 118.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 360/1900 [00:02<00:08, 185.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 480/1900 [00:03<00:06, 218.12 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 540/1900 [00:03<00:05, 229.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 600/1900 [00:03<00:05, 242.14 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 660/1900 [00:04<00:05, 208.89 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 779/1900 [00:04<00:04, 276.64 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 838/1900 [00:04<00:03, 266.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 897/1900 [00:04<00:03, 254.60 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 956/1900 [00:05<00:04, 214.96 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1015/1900 [00:05<00:03, 241.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1074/1900 [00:05<00:03, 233.35 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1192/1900 [00:05<00:02, 317.10 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1251/1900 [00:06<00:02, 276.64 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1369/1900 [00:06<00:01, 284.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1428/1900 [00:06<00:01, 284.11 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1487/1900 [00:07<00:01, 285.93 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1546/1900 [00:07<00:01, 288.58 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1605/1900 [00:07<00:01, 288.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1664/1900 [00:07<00:00, 283.37 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1723/1900 [00:07<00:00, 234.60 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1782/1900 [00:08<00:00, 265.02 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:08<00:00, 342.64 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:08<00:00, 217.07 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   4%|â–         | 4/100 [00:02<00:48,  1.97 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   8%|â–Š         | 8/100 [00:02<00:23,  4.00 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 16/100 [00:02<00:08,  9.33 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 22/100 [00:02<00:06, 12.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:03<00:06, 11.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 28/100 [00:03<00:05, 12.77 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:03<00:05, 13.47 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:03<00:04, 13.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:03<00:04, 13.88 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:03<00:04, 14.54 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:04<00:03, 14.94 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:04<00:03, 14.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:04<00:03, 14.55 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:04<00:03, 15.25 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:04<00:02, 15.48 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:05<00:02, 15.24 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:05<00:02, 14.53 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:05<00:02, 15.42 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:05<00:02, 14.85 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:05<00:01, 15.14 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:06<00:01, 15.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:06<00:02, 10.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:06<00:00, 15.95 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:07<00:00, 16.43 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:07<00:00, 13.15 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:07<00:00, 14.32 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:07<00:00, 15.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 12.07 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,900 | Num Epochs = 3 | Total steps = 357
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)

Starting training...
  0%|          | 0/357 [00:00<?, ?it/s]  0%|          | 1/357 [00:15<1:29:24, 15.07s/it]  1%|          | 2/357 [00:21<1:00:09, 10.17s/it]  1%|          | 3/357 [00:28<50:51,  8.62s/it]    1%|          | 4/357 [00:35<46:25,  7.89s/it]  1%|â–         | 5/357 [00:42<43:55,  7.49s/it]  2%|â–         | 6/357 [00:48<42:20,  7.24s/it]  2%|â–         | 7/357 [00:55<41:15,  7.07s/it]  2%|â–         | 8/357 [01:02<40:33,  6.97s/it]  3%|â–Ž         | 9/357 [01:09<40:03,  6.91s/it]  3%|â–Ž         | 10/357 [01:15<39:40,  6.86s/it]                                                  3%|â–Ž         | 10/357 [01:15<39:40,  6.86s/it]  3%|â–Ž         | 11/357 [01:22<39:23,  6.83s/it]  3%|â–Ž         | 12/357 [01:29<39:09,  6.81s/it]  4%|â–Ž         | 13/357 [01:36<38:59,  6.80s/it]  4%|â–         | 14/357 [01:42<38:48,  6.79s/it]  4%|â–         | 15/357 [01:49<38:37,  6.78s/it]  4%|â–         | 16/357 [01:56<38:30,  6.78s/it]  5%|â–         | 17/357 [02:03<38:23,  6.78s/it]  5%|â–Œ         | 18/357 [02:10<38:15,  6.77s/it]  5%|â–Œ         | 19/357 [02:16<38:07,  6.77s/it]  6%|â–Œ         | 20/357 [02:23<37:58,  6.76s/it]                                                  6%|â–Œ         | 20/357 [02:23<37:58,  6.76s/it]  6%|â–Œ         | 21/357 [02:30<37:51,  6.76s/it]  6%|â–Œ         | 22/357 [02:37<37:43,  6.76s/it]  6%|â–‹         | 23/357 [02:43<37:35,  6.75s/it]  7%|â–‹         | 24/357 [02:50<37:29,  6.75s/it]  7%|â–‹         | 25/357 [02:57<37:24,  6.76s/it]  7%|â–‹         | 26/357 [03:04<37:19,  6.77s/it]  8%|â–Š         | 27/357 [03:10<37:16,  6.78s/it]  8%|â–Š         | 28/357 [03:17<37:10,  6.78s/it]  8%|â–Š         | 29/357 [03:24<37:00,  6.77s/it]  8%|â–Š         | 30/357 [03:31<36:53,  6.77s/it]                                                  8%|â–Š         | 30/357 [03:31<36:53,  6.77s/it]  9%|â–Š         | 31/357 [03:37<36:43,  6.76s/it]  9%|â–‰         | 32/357 [03:44<36:34,  6.75s/it]  9%|â–‰         | 33/357 [03:51<36:26,  6.75s/it] 10%|â–‰         | 34/357 [03:58<37:02,  6.88s/it] 10%|â–‰         | 35/357 [04:05<36:47,  6.85s/it] 10%|â–ˆ         | 36/357 [04:12<36:29,  6.82s/it] 10%|â–ˆ         | 37/357 [04:18<36:14,  6.80s/it] 11%|â–ˆ         | 38/357 [04:25<36:02,  6.78s/it] 11%|â–ˆ         | 39/357 [04:32<35:51,  6.77s/it] 11%|â–ˆ         | 40/357 [04:39<35:42,  6.76s/it]                                                 11%|â–ˆ         | 40/357 [04:39<35:42,  6.76s/it] 11%|â–ˆâ–        | 41/357 [04:45<35:35,  6.76s/it] 12%|â–ˆâ–        | 42/357 [04:52<35:26,  6.75s/it] 12%|â–ˆâ–        | 43/357 [04:59<35:19,  6.75s/it] 12%|â–ˆâ–        | 44/357 [05:06<35:11,  6.75s/it] 13%|â–ˆâ–Ž        | 45/357 [05:12<35:04,  6.74s/it] 13%|â–ˆâ–Ž        | 46/357 [05:19<34:57,  6.74s/it] 13%|â–ˆâ–Ž        | 47/357 [05:26<34:51,  6.75s/it] 13%|â–ˆâ–Ž        | 48/357 [05:33<34:44,  6.74s/it] 14%|â–ˆâ–Ž        | 49/357 [05:39<34:37,  6.75s/it] 14%|â–ˆâ–        | 50/357 [05:46<34:30,  6.74s/it]                                                 14%|â–ˆâ–        | 50/357 [05:46<34:30,  6.74s/it] 14%|â–ˆâ–        | 51/357 [05:53<34:24,  6.75s/it] 15%|â–ˆâ–        | 52/357 [06:00<34:18,  6.75s/it] 15%|â–ˆâ–        | 53/357 [06:06<34:11,  6.75s/it] 15%|â–ˆâ–Œ        | 54/357 [06:13<34:05,  6.75s/it] 15%|â–ˆâ–Œ        | 55/357 [06:20<33:58,  6.75s/it] 16%|â–ˆâ–Œ        | 56/357 [06:27<33:52,  6.75s/it] 16%|â–ˆâ–Œ        | 57/357 [06:33<33:45,  6.75s/it] 16%|â–ˆâ–Œ        | 58/357 [06:40<33:39,  6.75s/it] 17%|â–ˆâ–‹        | 59/357 [06:47<33:32,  6.75s/it] 17%|â–ˆâ–‹        | 60/357 [06:54<33:25,  6.75s/it]                                                 17%|â–ˆâ–‹        | 60/357 [06:54<33:25,  6.75s/it] 17%|â–ˆâ–‹        | 61/357 [07:00<33:18,  6.75s/it] 17%|â–ˆâ–‹        | 62/357 [07:07<33:12,  6.75s/it] 18%|â–ˆâ–Š        | 63/357 [07:14<33:05,  6.75s/it] 18%|â–ˆâ–Š        | 64/357 [07:21<32:59,  6.76s/it] 18%|â–ˆâ–Š        | 65/357 [07:27<32:54,  6.76s/it] 18%|â–ˆâ–Š        | 66/357 [07:34<32:46,  6.76s/it] 19%|â–ˆâ–‰        | 67/357 [07:41<32:40,  6.76s/it] 19%|â–ˆâ–‰        | 68/357 [07:48<33:07,  6.88s/it] 19%|â–ˆâ–‰        | 69/357 [07:55<32:54,  6.86s/it] 20%|â–ˆâ–‰        | 70/357 [08:02<32:41,  6.83s/it]                                                 20%|â–ˆâ–‰        | 70/357 [08:02<32:41,  6.83s/it] 20%|â–ˆâ–‰        | 71/357 [08:08<32:29,  6.82s/it] 20%|â–ˆâ–ˆ        | 72/357 [08:15<32:20,  6.81s/it] 20%|â–ˆâ–ˆ        | 73/357 [08:22<32:12,  6.80s/it] 21%|â–ˆâ–ˆ        | 74/357 [08:29<32:02,  6.79s/it] 21%|â–ˆâ–ˆ        | 75/357 [08:35<31:54,  6.79s/it] 21%|â–ˆâ–ˆâ–       | 76/357 [08:42<31:45,  6.78s/it] 22%|â–ˆâ–ˆâ–       | 77/357 [08:49<31:36,  6.77s/it] 22%|â–ˆâ–ˆâ–       | 78/357 [08:56<31:31,  6.78s/it] 22%|â–ˆâ–ˆâ–       | 79/357 [09:03<31:23,  6.77s/it] 22%|â–ˆâ–ˆâ–       | 80/357 [09:09<31:15,  6.77s/it]                                                 22%|â–ˆâ–ˆâ–       | 80/357 [09:09<31:15,  6.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 81/357 [09:16<31:08,  6.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/357 [09:23<31:00,  6.77s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/357 [09:30<30:53,  6.76s/it] 24%|â–ˆâ–ˆâ–Ž       | 84/357 [09:36<30:45,  6.76s/it] 24%|â–ˆâ–ˆâ–       | 85/357 [09:43<30:39,  6.76s/it] 24%|â–ˆâ–ˆâ–       | 86/357 [09:50<30:31,  6.76s/it] 24%|â–ˆâ–ˆâ–       | 87/357 [09:57<30:24,  6.76s/it] 25%|â–ˆâ–ˆâ–       | 88/357 [10:03<30:17,  6.76s/it] 25%|â–ˆâ–ˆâ–       | 89/357 [10:10<30:10,  6.76s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:17<30:03,  6.76s/it]                                                 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:17<30:03,  6.76s/it] 25%|â–ˆâ–ˆâ–Œ       | 91/357 [10:24<29:58,  6.76s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/357 [10:30<29:51,  6.76s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/357 [10:37<29:46,  6.77s/it] 26%|â–ˆâ–ˆâ–‹       | 94/357 [10:44<29:39,  6.76s/it] 27%|â–ˆâ–ˆâ–‹       | 95/357 [10:51<29:33,  6.77s/it] 27%|â–ˆâ–ˆâ–‹       | 96/357 [10:58<29:26,  6.77s/it] 27%|â–ˆâ–ˆâ–‹       | 97/357 [11:04<29:18,  6.77s/it] 27%|â–ˆâ–ˆâ–‹       | 98/357 [11:11<29:12,  6.76s/it] 28%|â–ˆâ–ˆâ–Š       | 99/357 [11:18<29:03,  6.76s/it] 28%|â–ˆâ–ˆâ–Š       | 100/357 [11:25<28:56,  6.76s/it]                                                  28%|â–ˆâ–ˆâ–Š       | 100/357 [11:25<28:56,  6.76s/it] 28%|â–ˆâ–ˆâ–Š       | 101/357 [11:32<29:24,  6.89s/it] 29%|â–ˆâ–ˆâ–Š       | 102/357 [11:39<29:06,  6.85s/it] 29%|â–ˆâ–ˆâ–‰       | 103/357 [11:45<28:52,  6.82s/it] 29%|â–ˆâ–ˆâ–‰       | 104/357 [11:52<28:40,  6.80s/it] 29%|â–ˆâ–ˆâ–‰       | 105/357 [11:59<28:30,  6.79s/it] 30%|â–ˆâ–ˆâ–‰       | 106/357 [12:06<28:21,  6.78s/it] 30%|â–ˆâ–ˆâ–‰       | 107/357 [12:12<28:12,  6.77s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/357 [12:19<28:05,  6.77s/it] 31%|â–ˆâ–ˆâ–ˆ       | 109/357 [12:26<27:57,  6.77s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:33<27:50,  6.76s/it]                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:33<27:50,  6.76s/it] 31%|â–ˆâ–ˆâ–ˆ       | 111/357 [12:39<27:43,  6.76s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 112/357 [12:46<27:38,  6.77s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 113/357 [12:53<27:30,  6.76s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 114/357 [13:00<27:23,  6.76s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 115/357 [13:06<27:15,  6.76s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 116/357 [13:13<27:08,  6.76s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/357 [13:20<27:01,  6.75s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/357 [13:27<26:53,  6.75s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [13:32<24:46,  6.25s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 4.5487, 'grad_norm': 44.896663665771484, 'learning_rate': 5e-06, 'epoch': 0.08}
{'loss': 3.6675, 'grad_norm': 24.39150619506836, 'learning_rate': 1.0555555555555557e-05, 'epoch': 0.17}
{'loss': 2.3283, 'grad_norm': 6.375252723693848, 'learning_rate': 1.6111111111111115e-05, 'epoch': 0.25}
{'loss': 1.4198, 'grad_norm': 1.9770184755325317, 'learning_rate': 1.9995690062269985e-05, 'epoch': 0.34}
{'loss': 1.1244, 'grad_norm': 1.7172174453735352, 'learning_rate': 1.9919172253651637e-05, 'epoch': 0.42}
{'loss': 0.8315, 'grad_norm': 1.8241373300552368, 'learning_rate': 1.974772117649135e-05, 'epoch': 0.51}
{'loss': 0.5198, 'grad_norm': 2.1565659046173096, 'learning_rate': 1.9482977734962753e-05, 'epoch': 0.59}
{'loss': 0.2325, 'grad_norm': 1.9565085172653198, 'learning_rate': 1.9127475705028864e-05, 'epoch': 0.67}
{'loss': 0.0819, 'grad_norm': 0.7474777102470398, 'learning_rate': 1.8684617484471662e-05, 'epoch': 0.76}
{'loss': 0.0351, 'grad_norm': 0.5986076593399048, 'learning_rate': 1.815864152961624e-05, 'epoch': 0.84}
{'loss': 0.0263, 'grad_norm': 0.4412355124950409, 'learning_rate': 1.7554581790402372e-05, 'epoch': 0.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:13,  1.66it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:20,  1.06it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:23,  1.12s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.28s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:25,  1.33s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:24,  1.35s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:09<00:23,  1.37s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.44s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:12<00:21,  1.43s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:19,  1.43s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:15<00:18,  1.42s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:18<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.44s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:21<00:12,  1.43s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.48s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:24<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:25<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:28<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:31<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:34<00:00,  1.49s/it][A                                                 
                                               [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [14:08<24:46,  6.25s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:45<1:43:56, 26.32s/it]                                                    34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:45<1:43:56, 26.32s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 121/357 [14:50<1:18:26, 19.94s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 122/357 [14:54<1:00:01, 15.33s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 123/357 [14:59<47:11, 12.10s/it]   35%|â–ˆâ–ˆâ–ˆâ–      | 124/357 [15:04<38:12,  9.84s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/357 [15:09<32:24,  8.38s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/357 [15:13<27:51,  7.24s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 127/357 [15:18<24:39,  6.43s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 128/357 [15:22<22:24,  5.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 129/357 [15:27<20:48,  5.48s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:32<20:08,  5.32s/it]                                                  36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:32<20:08,  5.32s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/357 [15:36<19:10,  5.09s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 132/357 [15:41<18:29,  4.93s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 133/357 [15:45<17:59,  4.82s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 134/357 [15:50<17:36,  4.74s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 135/357 [15:55<17:46,  4.80s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 136/357 [15:59<17:25,  4.73s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 137/357 [16:04<17:09,  4.68s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 138/357 [16:09<16:56,  4.64s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 139/357 [16:14<17:13,  4.74s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [16:18<16:56,  4.69s/it]                                                  39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [16:18<16:56,  4.69s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 141/357 [16:23<16:44,  4.65s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 142/357 [16:27<16:34,  4.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/357 [16:32<16:24,  4.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/357 [16:37<16:42,  4.71s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 145/357 [16:41<16:28,  4.66s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 146/357 [16:46<16:17,  4.63s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 147/357 [16:50<16:08,  4.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/357 [16:55<16:26,  4.72s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/357 [17:00<16:11,  4.67s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [17:05<16:00,  4.64s/it]                                                  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [17:05<16:00,  4.64s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 151/357 [17:09<15:50,  4.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 152/357 [17:14<15:43,  4.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/357 [17:19<16:05,  4.73s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 154/357 [17:23<15:51,  4.68s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 155/357 [17:28<15:43,  4.67s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 156/357 [17:33<15:35,  4.65s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/357 [17:37<15:26,  4.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/357 [17:42<15:44,  4.74s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/357 [17:47<15:30,  4.70s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:51<15:19,  4.67s/it]                                                  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:51<15:19,  4.67s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 161/357 [17:56<15:10,  4.65s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 162/357 [18:01<15:24,  4.74s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 163/357 [18:05<15:11,  4.70s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 164/357 [18:10<15:00,  4.67s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 165/357 [18:15<14:52,  4.65s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 166/357 [18:19<14:43,  4.63s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 167/357 [18:24<14:59,  4.73s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 168/357 [18:29<14:44,  4.68s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 169/357 [18:33<14:34,  4.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:38<14:25,  4.63s/it]                                                  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:38<14:25,  4.63s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 171/357 [18:43<14:18,  4.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 172/357 [18:48<14:33,  4.72s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 173/357 [18:52<14:21,  4.68s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 174/357 [18:57<14:11,  4.65s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 175/357 [19:01<14:04,  4.64s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 176/357 [19:06<14:21,  4.76s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 177/357 [19:11<14:07,  4.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 178/357 [19:15<13:56,  4.67s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 179/357 [19:20<13:48,  4.65s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [19:25<13:39,  4.63s/it]                                                  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [19:25<13:39,  4.63s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 181/357 [19:30<13:56,  4.75s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 182/357 [19:34<13:43,  4.70s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/357 [19:39<13:31,  4.66s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 184/357 [19:43<13:22,  4.64s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 185/357 [19:48<13:14,  4.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 186/357 [19:53<13:31,  4.75s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 187/357 [19:58<13:18,  4.70s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 188/357 [20:02<13:08,  4.66s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 189/357 [20:07<12:59,  4.64s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [20:11<12:51,  4.62s/it]                                                  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [20:11<12:51,  4.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 191/357 [20:16<13:08,  4.75s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 192/357 [20:21<12:56,  4.70s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 193/357 [20:26<12:44,  4.66s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 194/357 [20:30<12:34,  4.63s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/357 [20:35<12:48,  4.74s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 196/357 [20:40<12:35,  4.69s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 197/357 [20:44<12:25,  4.66s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 198/357 [20:49<12:17,  4.64s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 199/357 [20:53<12:09,  4.62s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [20:58<12:21,  4.72s/it]                                                  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [20:58<12:21,  4.72s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 201/357 [21:03<12:10,  4.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 202/357 [21:08<12:00,  4.65s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 203/357 [21:12<11:51,  4.62s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 204/357 [21:17<12:03,  4.73s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 205/357 [21:22<11:52,  4.69s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 206/357 [21:26<11:42,  4.65s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 207/357 [21:31<11:33,  4.62s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 208/357 [21:35<11:26,  4.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 209/357 [21:40<11:39,  4.73s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:45<11:27,  4.67s/it]                                                  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:45<11:27,  4.67s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 211/357 [21:50<11:19,  4.65s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 212/357 [21:54<11:11,  4.63s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 213/357 [21:59<11:05,  4.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 214/357 [22:04<11:17,  4.74s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 215/357 [22:08<11:05,  4.69s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 216/357 [22:13<10:56,  4.66s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 217/357 [22:18<10:48,  4.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 218/357 [22:23<10:59,  4.74s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 219/357 [22:27<10:47,  4.69s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:32<10:36,  4.65s/it]                                                  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:32<10:36,  4.65s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 221/357 [22:36<10:28,  4.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 222/357 [22:41<10:22,  4.61s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 223/357 [22:46<10:32,  4.72s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 224/357 [22:50<10:21,  4.67s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 225/357 [22:55<10:13,  4.65s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 226/357 [22:59<10:05,  4.62s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 227/357 [23:04<09:58,  4.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 228/357 [23:09<10:09,  4.72s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 229/357 [23:14<09:59,  4.68s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [23:18<09:50,  4.65s/it]                                                  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [23:18<09:50,  4.65s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/357 [23:23<09:42,  4.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/357 [23:28<09:52,  4.74s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 233/357 [23:32<09:41,  4.69s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 234/357 [23:37<09:31,  4.65s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 235/357 [23:41<09:23,  4.62s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 236/357 [23:46<09:16,  4.60s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 237/357 [23:51<09:26,  4.72s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [23:54<08:35,  4.33s/it]{'eval_loss': 0.02150917984545231, 'eval_runtime': 36.7932, 'eval_samples_per_second': 2.718, 'eval_steps_per_second': 0.679, 'epoch': 1.0}

==================================================
Testing model performance...
==================================================
Generated solution:
commentary functions# Invoking 'verify_plan' with the generated plan
plan_str = """sail l0 l1
debark c0 l1
sail l1 l2
board c2 l2
debark c2 l2"""
functions.verify_plan(plan_str, domain_str, problem_str)
commentaryanalysisWe need to check the plan for validity given domain and problem, including constraints if any. Domain includes constraints, but problem may include its own constraints. In this example, if they had a constraint, must satisfy. Here, we need to compute states and ensure each action's preconditions hold, respecting types, and not violate invariants. Also, if initial state satisfies goals and constraints, output nothing.

Let's manually trace.

Objects: locations: l0 l1 l2. cars: c0 c1 c2.

Domain predicates: not-eq ?x ?y, car ?c, location ?l, at-ferry ?l, at ?c ?l, empty-ferry, on ?c.

Initial state predicates:
location l0, l1, l2.
car c0, c1, c2.
not-eq l0 l1, l1 l0, l0 l2, l2 l0, l1 l2, l2 l1.
empty-ferry.
at c0 l2.
at c1 l0.
at c2 l0.
at-ferry l0.

Goals: at c0 l1, at c1 l0, at c2 l2.

Constraints: 
(:constraints
  (and
    (sometime-before  (at c0 l1) (at-ferry l0))
    (sometime-before  (at c2 l2) (at-ferry l1))
  )
)

So we must ensure that at c0 l1 occurs sometime before at-ferry l0, and at c2 l2 occurs before at-ferry l1.

Plan given: 
sail l0 l1
debark c0 l1
sail l1 l2
board c2 l2
debark c2 l2

We need to ensure each action's preconditions hold at its step, given state evolves.

Initial state: at-ferry l0, at c0 l2, at c1 l0, at c2 l0, empty-ferry, location l0,l1,l2, car c0,c1,c2
==================================================
{'loss': 0.0238, 'grad_norm': 0.2644358277320862, 'learning_rate': 1.687821953203765e-05, 'epoch': 1.01}
{'loss': 0.019, 'grad_norm': 0.22509430348873138, 'learning_rate': 1.613602800433194e-05, 'epoch': 1.09}
{'loss': 0.0163, 'grad_norm': 0.23193010687828064, 'learning_rate': 1.5335110488265497e-05, 'epoch': 1.18}
{'loss': 0.0149, 'grad_norm': 0.28348633646965027, 'learning_rate': 1.4483132312727501e-05, 'epoch': 1.26}
{'loss': 0.0133, 'grad_norm': 0.18539462983608246, 'learning_rate': 1.358824749207136e-05, 'epoch': 1.35}
{'loss': 0.0128, 'grad_norm': 0.15368837118148804, 'learning_rate': 1.2659020686615602e-05, 'epoch': 1.43}
{'loss': 0.013, 'grad_norm': 0.13305912911891937, 'learning_rate': 1.170434523298175e-05, 'epoch': 1.51}
{'loss': 0.0123, 'grad_norm': 0.13849690556526184, 'learning_rate': 1.073335802877504e-05, 'epoch': 1.6}
{'loss': 0.0126, 'grad_norm': 0.14689263701438904, 'learning_rate': 9.755352086219733e-06, 'epoch': 1.68}
{'loss': 0.0128, 'grad_norm': 0.2537078261375427, 'learning_rate': 8.779687591670687e-06, 'epoch': 1.77}
{'loss': 0.0117, 'grad_norm': 0.13820300996303558, 'learning_rate': 7.815702322222539e-06, 'epoch': 1.85}
{'loss': 0.0115, 'grad_norm': 0.1698753535747528, 'learning_rate': 6.872622276790804e-06, 'epoch': 1.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:21,  1.00it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.41s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.47s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [24:31<08:35,  4.33s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 239/357 [25:08<49:10, 25.01s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [25:12<36:48, 18.87s/it]                                                  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [25:12<36:48, 18.87s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 241/357 [25:17<28:28, 14.73s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 242/357 [25:22<22:23, 11.68s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 243/357 [25:26<18:09,  9.55s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 244/357 [25:31<15:10,  8.05s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 245/357 [25:36<13:04,  7.00s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 246/357 [25:41<11:51,  6.41s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 247/357 [25:45<10:44,  5.86s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 248/357 [25:50<09:56,  5.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 249/357 [25:54<09:22,  5.21s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [25:59<08:56,  5.02s/it]                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [25:59<08:56,  5.02s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 251/357 [26:04<08:53,  5.03s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 252/357 [26:09<08:33,  4.89s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 253/357 [26:13<08:18,  4.80s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 254/357 [26:18<08:06,  4.73s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 255/357 [26:22<07:56,  4.68s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 256/357 [26:27<08:02,  4.78s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 257/357 [26:32<07:51,  4.71s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 258/357 [26:36<07:41,  4.66s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 259/357 [26:41<07:34,  4.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:46<07:40,  4.75s/it]                                                  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:46<07:40,  4.75s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 261/357 [26:50<07:30,  4.69s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 262/357 [26:55<07:23,  4.66s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 263/357 [27:00<07:15,  4.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 264/357 [27:04<07:09,  4.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 265/357 [27:09<07:16,  4.74s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 266/357 [27:14<07:06,  4.69s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 267/357 [27:18<06:58,  4.65s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 268/357 [27:23<06:51,  4.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 269/357 [27:28<06:45,  4.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [27:33<06:52,  4.74s/it]                                                  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [27:33<06:52,  4.74s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 271/357 [27:37<06:42,  4.68s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 272/357 [27:42<06:34,  4.64s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 273/357 [27:46<06:28,  4.62s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 274/357 [27:51<06:22,  4.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 275/357 [27:56<06:27,  4.72s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 276/357 [28:00<06:18,  4.67s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 277/357 [28:05<06:11,  4.65s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 278/357 [28:10<06:05,  4.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 279/357 [28:14<05:59,  4.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [28:19<06:04,  4.73s/it]                                                  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [28:19<06:04,  4.73s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 281/357 [28:24<05:55,  4.68s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 282/357 [28:28<05:48,  4.64s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 283/357 [28:33<05:41,  4.62s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 284/357 [28:38<05:45,  4.74s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 285/357 [28:42<05:37,  4.69s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 286/357 [28:47<05:29,  4.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 287/357 [28:51<05:23,  4.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 288/357 [28:56<05:17,  4.60s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 289/357 [29:01<05:21,  4.73s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [29:06<05:13,  4.68s/it]                                                  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [29:06<05:13,  4.68s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 291/357 [29:10<05:06,  4.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 292/357 [29:15<04:59,  4.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 293/357 [29:19<04:54,  4.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294/357 [29:24<04:56,  4.71s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 295/357 [29:29<04:49,  4.66s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 296/357 [29:33<04:42,  4.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 297/357 [29:38<04:36,  4.61s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 298/357 [29:43<04:31,  4.60s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 299/357 [29:48<04:33,  4.72s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:52<04:26,  4.67s/it]                                                  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:52<04:26,  4.67s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 301/357 [29:57<04:19,  4.64s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 302/357 [30:01<04:13,  4.61s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 303/357 [30:06<04:15,  4.74s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 304/357 [30:11<04:08,  4.68s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 305/357 [30:15<04:01,  4.64s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 306/357 [30:20<03:55,  4.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 307/357 [30:24<03:50,  4.60s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 308/357 [30:29<03:51,  4.73s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 309/357 [30:34<03:44,  4.68s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:39<03:38,  4.64s/it]                                                  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:39<03:38,  4.64s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 311/357 [30:43<03:32,  4.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 312/357 [30:48<03:26,  4.60s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 313/357 [30:53<03:27,  4.72s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 314/357 [30:57<03:20,  4.67s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 315/357 [31:02<03:14,  4.64s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 316/357 [31:06<03:09,  4.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 317/357 [31:11<03:03,  4.60s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 318/357 [31:16<03:04,  4.72s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 319/357 [31:20<02:57,  4.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [31:25<02:51,  4.64s/it]                                                  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [31:25<02:51,  4.64s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 321/357 [31:30<02:46,  4.61s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 322/357 [31:35<02:45,  4.72s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 323/357 [31:39<02:38,  4.67s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 324/357 [31:44<02:33,  4.64s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 325/357 [31:48<02:27,  4.61s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 326/357 [31:53<02:22,  4.60s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 327/357 [31:58<02:21,  4.71s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 328/357 [32:02<02:15,  4.66s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/357 [32:07<02:09,  4.63s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [32:11<02:04,  4.61s/it]                                                  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [32:11<02:04,  4.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 331/357 [32:16<01:59,  4.59s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 332/357 [32:21<01:57,  4.70s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 333/357 [32:26<01:51,  4.66s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 334/357 [32:30<01:46,  4.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 335/357 [32:35<01:41,  4.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 336/357 [32:39<01:36,  4.59s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 337/357 [32:44<01:34,  4.70s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 338/357 [32:49<01:28,  4.67s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 339/357 [32:53<01:23,  4.63s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [32:58<01:18,  4.61s/it]                                                  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [32:58<01:18,  4.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 341/357 [33:02<01:13,  4.59s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 342/357 [33:07<01:10,  4.71s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 343/357 [33:12<01:05,  4.67s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 344/357 [33:16<01:00,  4.64s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 345/357 [33:21<00:55,  4.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 346/357 [33:26<00:51,  4.72s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 347/357 [33:31<00:46,  4.68s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 348/357 [33:35<00:41,  4.64s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 349/357 [33:40<00:36,  4.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:44<00:32,  4.60s/it]                                                  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:44<00:32,  4.60s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 351/357 [33:49<00:28,  4.72s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 352/357 [33:54<00:23,  4.68s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 353/357 [33:58<00:18,  4.64s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 354/357 [34:03<00:13,  4.62s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 355/357 [34:08<00:09,  4.60s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 356/357 [34:13<00:04,  4.72s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:16<00:00,  4.33s/it]{'eval_loss': 0.012520045042037964, 'eval_runtime': 36.7444, 'eval_samples_per_second': 2.722, 'eval_steps_per_second': 0.68, 'epoch': 2.0}

==================================================
Testing model performance...
==================================================
Generated solution:
commentary functionspae block-2-2)
commentaryanalysisWe need to produce the final output. We must solve the ferry domain L3 C3. Let's reason.

Locations: l0 l1 l2. l0, l1, l2. Constraints not-eq between all distinct pairs given.

Cars: c0 c1 c2.

Initial:
- location l0 l1 l2
- car c0 c1 c2
- not-eq pairs as usual.
- empty-ferry
- at c0 l2
- at c1 l0
- at c2 l0
- at-ferry l0

So ferry starts at l0.

Goal:
- at c0 l1
- at c1 l0
- at c2 l2

So c1 already at l0 (good). c2 at l0 needs to go to l2. c0 at l2 needs to go to l1.

Constraints (PDDL3):
(:constraints
  (and
    (sometime-before  (at c0 l1) (at-ferry l0))
    (sometime-before  (at c2 l2) (at-ferry l1))
  )
)

So need:
- c0 must reach l1 before ferry reaches l0.
- c2 must reach l2 before ferry reaches l1.

Plan must satisfy goals and constraints.

We need a sequential, grounded plan.

Let's find a sequence.

Initial states:
- at c0 l2
- at c1 l0
- at c2 l0
- at-ferry l0
- empty-ferry

Other:
- location l0 l1 l2
- not-eq all pairs among l0,l1,l2.

We need:
- at c0 l1
- at c2 l2
- at-ferry? at goals don't require at-ferry, but constraints require at-ferry l0 before at c0 l1, and at-ferry l1 before at c2 l2.

So plan must ensure these orderings.

Let's design.

Since ferry starts at l0, to satisfy first constraint: c0 must reach l1 before ferry returns to l0. So ferry must go to l1, l2, etc before back to l0.

Also second: c2 must reach l2 before ferry reaches l1. So ferry must go to l1 after sending c2 to
==================================================
{'loss': 0.0114, 'grad_norm': 0.17427797615528107, 'learning_rate': 5.959473376986686e-06, 'epoch': 2.02}
{'loss': 0.0111, 'grad_norm': 0.14607344567775726, 'learning_rate': 5.084995082868658e-06, 'epoch': 2.1}
{'loss': 0.0116, 'grad_norm': 0.11737997084856033, 'learning_rate': 4.257556750327176e-06, 'epoch': 2.19}
{'loss': 0.0113, 'grad_norm': 0.1231122836470604, 'learning_rate': 3.485077530619664e-06, 'epoch': 2.27}
{'loss': 0.0117, 'grad_norm': 0.13590657711029053, 'learning_rate': 2.77495057867198e-06, 'epoch': 2.35}
{'loss': 0.011, 'grad_norm': 0.2606890797615051, 'learning_rate': 2.133972295524875e-06, 'epoch': 2.44}
{'loss': 0.0113, 'grad_norm': 0.1733989268541336, 'learning_rate': 1.5682772821236192e-06, 'epoch': 2.52}
{'loss': 0.011, 'grad_norm': 0.2567986845970154, 'learning_rate': 1.0832796269875757e-06, 'epoch': 2.61}
{'loss': 0.0109, 'grad_norm': 0.14416095614433289, 'learning_rate': 6.836210896769014e-07, 'epoch': 2.69}
{'loss': 0.0114, 'grad_norm': 0.22568663954734802, 'learning_rate': 3.731266759760854e-07, 'epoch': 2.77}
{'loss': 0.0113, 'grad_norm': 0.19810891151428223, 'learning_rate': 1.5476802997022812e-07, 'epoch': 2.86}
{'loss': 0.011, 'grad_norm': 0.1239466443657875, 'learning_rate': 3.063499337692788e-08, 'epoch': 2.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.41it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:22,  1.00s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.41s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:53<00:00,  4.33s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [35:25<00:00,  4.33s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [35:25<00:00,  5.95s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–‚â–
wandb:            eval/runtime â–ˆâ–‚â–
wandb: eval/samples_per_second â–â–ˆâ–ˆ
wandb:   eval/steps_per_second â–â–…â–ˆ
wandb:             train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/learning_rate â–ƒâ–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:              train/loss â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.01161
wandb:            eval/runtime 36.735
wandb: eval/samples_per_second 2.722
wandb:   eval/steps_per_second 0.681
wandb:              total_flos 7.127275269390336e+17
wandb:             train/epoch 3
wandb:       train/global_step 357
wandb:         train/grad_norm 0.12395
wandb:     train/learning_rate 0.0
wandb:              train/loss 0.011
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_pddl3 at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/vh7ntzdc
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251030_223744-vh7ntzdc/logs
{'eval_loss': 0.01161006186157465, 'eval_runtime': 36.735, 'eval_samples_per_second': 2.722, 'eval_steps_per_second': 0.681, 'epoch': 3.0}

==================================================
Testing model performance...
==================================================
Generated solution:
commentary functions{"name":"is_initial","arguments":"{}"}commentaryfunctions_output{"is_initial":true}commentary{"name":"is_goal","arguments":"{}"}commentary to=functions_outputcommentary{"is_goal":true}commentary to=functions_outputcommentary{"name":"predict_step","arguments":"{}"}commentary{"predicted_step":"sail l0 l1"}commentary to=functions_outputcommentary{"predicted_step":"sail l1 l2"}commentary to=functions_outputcommentary{"name":"apply","arguments":"{'action':'sail','params':['l1','l2']}"}commentary{'valid':true,'state':{'location':{'l0','l1','l2'},'car':{'c0','c1','c2'},'at-ferry':{'l1'},'at':{'c0':{'l2'},'c1':{'l0'},'c2':{'l0'}},'empty-ferry':false,'on':{'c0'}}}commentary to=functions_outputcommentary{"name":"predict_step","arguments":"{}"}commentary{"predicted_step":"debark c0 l1"}commentary to=functions_outputcommentary{"name":"apply","arguments":"{'action':'debark','params':['c0','l1']}"}commentary{'valid':true,'state':{'location':{'l0','l1','l2'},'car':{'c0','c1','c2'},'at-ferry':{'l1'},'at':{'c0':{'l1'},'c1':{'l0'},'c2':{'l0'}},'empty-ferry':false,'on':{'c0','c1'}}}commentary to=functions_outputcommentary{"name":"predict_step","arguments":"{}"}commentary{"predicted_step":"empty-ferry"}commentary to=functions_outputcommentary{"name":"apply","arguments":"{'action':'empty-ferry','params':[]}"}commentary{'valid':true,'state':{'location':{'l0','l1','l2'},'car':{'c0','c1','c2'},'at-ferry':{'l1'},'at
==================================================
{'train_runtime': 2125.0303, 'train_samples_per_second': 2.682, 'train_steps_per_second': 0.168, 'train_loss': 0.4238834717318791, 'epoch': 3.0}

Saving model to sft_models/gpt_oss_20b/ferry/pddl3 ...
Training completed!

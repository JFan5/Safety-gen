# å¢å¼ºè®­ç»ƒæŒ‡å—ï¼šä½¿ç”¨ Prompt å˜ä½“è¿›è¡Œæ•°æ®å¢å¼º

## ğŸ¯ æ¦‚è¿°

é€šè¿‡ä¸ºæ¯ä¸ª problem ç”Ÿæˆ 5 ä¸ªä¸åŒçš„ prompt å˜ä½“ï¼Œå°†è®­ç»ƒæ•°æ®ä» **2000 æ¡æ‰©å±•åˆ° 10000 æ¡**ï¼ˆ5x å¢å¼ºï¼‰ã€‚

## ğŸ“Š æ•°æ®å¢å¼ºç­–ç•¥

### åŸå§‹æ•°æ®
- **Problems**: 2000 ä¸ªï¼ˆ4 ä¸ªåœºæ™¯ Ã— 500ï¼‰
- **è®­ç»ƒæ ·æœ¬**: 2000 æ¡

### å¢å¼ºåæ•°æ®
- **Problems**: 2000 ä¸ªï¼ˆç›¸åŒï¼‰
- **Prompt å˜ä½“**: æ¯ä¸ª problem 5 ä¸ªä¸åŒçš„ prompt
- **è®­ç»ƒæ ·æœ¬**: 10000 æ¡ï¼ˆ2000 Ã— 5ï¼‰

### Prompt å˜ä½“ç¤ºä¾‹

åŒä¸€ä¸ª problemï¼Œ5 ä¸ªä¸åŒçš„ prompt æ¨¡æ¿ï¼š

**å˜ä½“ 1:**
```
You are a planning expert. Produce a **valid plan** for the domain and problem below.

DOMAIN:
(define (domain blocksworld) ...)

PROBLEM:
(define (problem BW-rand-3) ...)

### Output Rules
- Output **only** plan steps, one per line.
...
```

**å˜ä½“ 2:**
```
Act as a planner. Generate a **valid plan** that solves the given problem in the given domain.

[DOMAIN]
(define (domain blocksworld) ...)

[PROBLEM]
(define (problem BW-rand-3) ...)

== REQUIRED OUTPUT ==
- Return plan steps **only**, one per line.
...
```

**å˜ä½“ 3-5:** å…¶ä»–ä¸åŒçš„è¡¨è¿°æ–¹å¼...

## ğŸš€ ä½¿ç”¨æ­¥éª¤

### æ­¥éª¤ 1: è½¬æ¢ä¸ºå¢å¼ºçš„ HuggingFace æ ¼å¼

```bash
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/mixed_dataset.json \
  --output /jfan5/sft_data/four_scenarios500_randomized_augmented/combined.hf \
  --num-variants 5 \
  --val-ratio 0.1 \
  --seed 42
```

**å‚æ•°è¯´æ˜ï¼š**
- `--num-variants 5`: æ¯ä¸ª problem ç”Ÿæˆ 5 ä¸ªå˜ä½“
- `--val-ratio 0.1`: 10% éªŒè¯é›†
- é»˜è®¤ä½¿ç”¨é¡ºåºæ¨¡æ¿ 1-5

**è¾“å‡ºï¼š**
```
åŸå§‹æ•°æ®: 2000 problems
å¢å¼ºåæ•°æ®: 10000 æ¡è®­ç»ƒæ ·æœ¬
  - è®­ç»ƒé›†: ~9000 æ¡
  - éªŒè¯é›†: ~1000 æ¡
```

### æ­¥éª¤ 2: å¯åŠ¨è®­ç»ƒ

```bash
sbatch shells/finetune_mistral_7b_randomized_augmented.sh
```

### æ­¥éª¤ 3: ç›‘æ§è®­ç»ƒ

```bash
tail -f job_outputs/finetune_mistral_7b_randomized_augmented.o
```

## ğŸ“‹ é«˜çº§é€‰é¡¹

### é€‰é¡¹ 1: ä½¿ç”¨æ‰€æœ‰ 10 ä¸ªæ¨¡æ¿

```bash
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/mixed_dataset.json \
  --output /jfan5/sft_data/four_scenarios500_randomized_augmented_10x/combined.hf \
  --num-variants 10 \
  --val-ratio 0.1
```

ç»“æœï¼š**20000 æ¡è®­ç»ƒæ ·æœ¬**ï¼ˆ2000 Ã— 10ï¼‰

### é€‰é¡¹ 2: éšæœºé€‰æ‹©æ¨¡æ¿

```bash
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/mixed_dataset.json \
  --output /jfan5/sft_data/four_scenarios500_randomized_augmented/combined.hf \
  --num-variants 5 \
  --random-variants
```

æ¯ä¸ª problem éšæœºé€‰æ‹© 5 ä¸ªä¸åŒçš„æ¨¡æ¿ï¼ˆä» 10 ä¸ªä¸­é€‰ï¼‰

### é€‰é¡¹ 3: åªä½¿ç”¨ç‰¹å®šåœºæ™¯

```bash
# åªå¢å¼º blocksworld
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/blocksworld_dataset.json \
  --output /jfan5/sft_data/blocksworld_randomized_augmented/combined.hf \
  --num-variants 5
```

ç»“æœï¼š**2500 æ¡è®­ç»ƒæ ·æœ¬**ï¼ˆ500 Ã— 5ï¼‰

## ğŸ” éªŒè¯è½¬æ¢ç»“æœ

```python
from datasets import load_from_disk

# åŠ è½½å¢å¼ºæ•°æ®é›†
dataset = load_from_disk('/jfan5/sft_data/four_scenarios500_randomized_augmented/combined.hf')

print(f"è®­ç»ƒé›†: {len(dataset['train'])} æ¡")
print(f"éªŒè¯é›†: {len(dataset['validation'])} æ¡")

# æŸ¥çœ‹åŒä¸€ problem çš„ä¸åŒå˜ä½“
train_data = dataset['train']
problem_ids = train_data['problem_id']

# æ‰¾åˆ°ç¬¬ä¸€ä¸ª problem çš„æ‰€æœ‰å˜ä½“
base_id = problem_ids[0].rsplit('_v', 1)[0]
variants = [i for i, pid in enumerate(problem_ids) if pid.startswith(base_id)]

print(f"\nProblem {base_id} çš„å˜ä½“æ•°é‡: {len(variants)}")
for idx in variants[:3]:  # æ˜¾ç¤ºå‰ 3 ä¸ª
    print(f"\nå˜ä½“ {train_data[idx]['variant_id']}:")
    print(train_data[idx]['text'][:200] + "...")
```

## ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡

### å¢å¼ºå‰åå¯¹æ¯”

| ç‰¹æ€§ | åŸå§‹ | å¢å¼º (5x) | å¢å¼º (10x) |
|------|------|-----------|------------|
| Problems | 2000 | 2000 | 2000 |
| è®­ç»ƒæ ·æœ¬ | 2000 | 10000 | 20000 |
| Prompt å˜ä½“ | 1 | 5 | 10 |
| è®­ç»ƒ steps (3 epochs) | ~750 | ~3750 | ~7500 |

### å„åœºæ™¯åˆ†å¸ƒï¼ˆ5x å¢å¼ºï¼‰

| Domain | åŸå§‹ Problems | å¢å¼ºåæ ·æœ¬ |
|--------|--------------|-----------|
| blocksworld | 500 | 2500 |
| ferry | 500 | 2500 |
| spanner | 500 | 2500 |
| grippers | 500 | 2500 |
| **æ€»è®¡** | **2000** | **10000** |

## ğŸ’¡ å¢å¼ºçš„ä¼˜åŠ¿

### 1. æ›´å¤šè®­ç»ƒæ•°æ®
- ä» 2000 æ¡å¢åŠ åˆ° 10000 æ¡
- æ›´å……åˆ†çš„è®­ç»ƒï¼Œå‡å°‘è¿‡æ‹Ÿåˆ

### 2. Prompt å¤šæ ·æ€§
- å­¦ä¹ ä¸åŒçš„è¡¨è¿°æ–¹å¼
- æé«˜æ¨¡å‹å¯¹ä¸åŒ prompt æ ¼å¼çš„é²æ£’æ€§

### 3. æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›
- ç»“åˆéšæœºåŒ–ç¬¦å·åç§°
- ç»“åˆå¤šæ ·åŒ– prompt
- åŒé‡æ³›åŒ–èƒ½åŠ›æå‡

### 4. é˜²æ­¢è®°å¿†ç‰¹å®šæ¨¡æ¿
- é¿å…è¿‡æ‹Ÿåˆåˆ°å•ä¸€ prompt æ ¼å¼
- æé«˜å®é™…åº”ç”¨çš„é€‚åº”æ€§

## ğŸ“ è®­ç»ƒå‚æ•°å»ºè®®

### æ ‡å‡†é…ç½®ï¼ˆ10000 æ¡æ•°æ®ï¼‰

```bash
# åœ¨ finetune_mistral_7b_randomized_augmented.sh ä¸­
NUM_EPOCHS=3
BATCH_SIZE=4
GRADIENT_ACCUMULATION_STEPS=2
LEARNING_RATE=2e-4
```

- **æœ‰æ•ˆ batch size**: 8
- **æ€»è®­ç»ƒ steps**: ~3750ï¼ˆ10000 / 8 Ã— 3ï¼‰
- **é¢„è®¡è®­ç»ƒæ—¶é—´**: å–å†³äº GPUï¼ˆé€šå¸¸ 2-4 å°æ—¶ï¼‰

### å¤§è§„æ¨¡é…ç½®ï¼ˆ20000 æ¡æ•°æ®ï¼Œ10x å¢å¼ºï¼‰

```bash
NUM_EPOCHS=2  # å‡å°‘ epochsï¼Œå› ä¸ºæ•°æ®é‡å¢åŠ 
BATCH_SIZE=4
GRADIENT_ACCUMULATION_STEPS=2
LEARNING_RATE=2e-4
```

- **æ€»è®­ç»ƒ steps**: ~5000ï¼ˆ20000 / 8 Ã— 2ï¼‰

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒ/éªŒè¯é›†å¦‚ä½•åˆ†å‰²ï¼Ÿ

é»˜è®¤æŒ‰ **problem åˆ†ç»„**ï¼š
- åŒä¸€ problem çš„æ‰€æœ‰ 5 ä¸ªå˜ä½“éƒ½åœ¨è®­ç»ƒé›†æˆ–éªŒè¯é›†ä¸­
- é¿å…æ•°æ®æ³„éœ²

å¦‚æœæƒ³éšæœºåˆ†å‰²ï¼ˆä¸æ¨èï¼‰ï¼š
```bash
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/mixed_dataset.json \
  --output /jfan5/sft_data/four_scenarios500_randomized_augmented/combined.hf \
  --num-variants 5 \
  --no-group-by-problem
```

### Q2: å¦‚ä½•é€‰æ‹©å˜ä½“æ•°é‡ï¼Ÿ

- **5 ä¸ªå˜ä½“**: å¹³è¡¡æ•°æ®é‡å’Œå¤šæ ·æ€§ï¼Œæ¨è
- **3 ä¸ªå˜ä½“**: è¾ƒå°‘æ•°æ®å¢å¼ºï¼Œé€‚åˆå¿«é€Ÿå®éªŒ
- **10 ä¸ªå˜ä½“**: æœ€å¤§å¤šæ ·æ€§ï¼Œä½†è®­ç»ƒæ—¶é—´é•¿

### Q3: é¡ºåºæ¨¡æ¿ vs éšæœºæ¨¡æ¿ï¼Ÿ

**é¡ºåºæ¨¡æ¿ï¼ˆé»˜è®¤ï¼‰**ï¼š
- ç¡®å®šæ€§ï¼Œå¯é‡ç°
- æ¯ä¸ª problem ä½¿ç”¨æ¨¡æ¿ 1-5

**éšæœºæ¨¡æ¿**ï¼š
- æ›´å¤šéšæœºæ€§
- æ¯ä¸ª problem éšæœºé€‰æ‹© 5 ä¸ªä¸åŒæ¨¡æ¿

æ¨èä½¿ç”¨é¡ºåºæ¨¡æ¿ä»¥ä¿è¯å¯é‡ç°æ€§ã€‚

### Q4: å†…å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ

åˆ†æ‰¹å¤„ç†ï¼š
```python
import json

# åªä½¿ç”¨å‰ 1000 ä¸ª problems
data = json.load(open('data_randomized/mixed_dataset.json'))
subset = data[:1000]
json.dump(subset, open('data_randomized/mixed_dataset_subset.json', 'w'))

# ç„¶åè½¬æ¢
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/mixed_dataset_subset.json \
  --output /jfan5/sft_data/subset_augmented/combined.hf \
  --num-variants 5
```

## ğŸ“Š å®Œæ•´å·¥ä½œæµç¨‹

```bash
# æ­¥éª¤ 1: ç”ŸæˆéšæœºåŒ–æ•°æ®é›†ï¼ˆå·²å®Œæˆï¼‰
python randomize_pddl.py \
  --output_root data_randomized \
  --domains blocksworld ferry spanner grippers \
  --seed 42

# æ­¥éª¤ 2: éªŒè¯éšæœºåŒ–
python verify_randomization.py

# æ­¥éª¤ 3: è½¬æ¢ä¸ºå¢å¼ºçš„ HF æ ¼å¼ï¼ˆ5x å¢å¼ºï¼‰
python convert_randomized_to_hf_augmented.py \
  --input data_randomized/mixed_dataset.json \
  --output /jfan5/sft_data/four_scenarios500_randomized_augmented/combined.hf \
  --num-variants 5

# æ­¥éª¤ 4: æäº¤è®­ç»ƒ
sbatch shells/finetune_mistral_7b_randomized_augmented.sh

# æ­¥éª¤ 5: ç›‘æ§è®­ç»ƒ
tail -f job_outputs/finetune_mistral_7b_randomized_augmented.o
```

## ğŸ“š ç›¸å…³æ–‡ä»¶

- `convert_randomized_to_hf_augmented.py` - å¢å¼ºè½¬æ¢è„šæœ¬
- `shells/finetune_mistral_7b_randomized_augmented.sh` - å¢å¼ºè®­ç»ƒè„šæœ¬
- `script/prompt_variants.py` - Prompt æ¨¡æ¿å®šä¹‰
- `README_RANDOMIZATION.md` - éšæœºåŒ–æ–‡æ¡£
- `TRAINING_RANDOMIZED.md` - åŸºç¡€è®­ç»ƒæŒ‡å—

## âœ… æ£€æŸ¥æ¸…å•

- [ ] å·²ç”ŸæˆéšæœºåŒ–æ•°æ®é›†
- [ ] å·²éªŒè¯éšæœºåŒ–ç»“æœ
- [ ] å·²è½¬æ¢ä¸ºå¢å¼ºçš„ HF æ ¼å¼
- [ ] å·²æ£€æŸ¥å¢å¼ºåçš„æ•°æ®é›†
- [ ] å·²æäº¤è®­ç»ƒä»»åŠ¡
- [ ] å·²ç›‘æ§è®­ç»ƒè¿›åº¦

---

**ç°åœ¨ä½ æœ‰äº†ä¸€ä¸ª 10000 æ¡æ ·æœ¬çš„å¢å¼ºè®­ç»ƒé›†ï¼** ğŸ‰

ç›¸æ¯”åŸå§‹ 2000 æ¡ï¼Œè¿™å°†æ˜¾è‘—æå‡æ¨¡å‹çš„è®­ç»ƒæ•ˆæœå’Œæ³›åŒ–èƒ½åŠ›ã€‚

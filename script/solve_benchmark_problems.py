#!/usr/bin/env python3
"""
Solve benchmark problems using OPTIC and LLM solvers.

This script orchestrates the solving process by calling the separate
OPTIC and LLM solver modules.
"""
from __future__ import annotations

import argparse
import sys
from pathlib import Path

from benchmark_common import (
    CACHE_FILENAME,
    DEFAULT_TIME_LIMIT,
    PROJECT_ROOT,
    ensure_binaries,
    load_solver_cache,
    save_solver_cache,
)

from generate_benchmark_problems import load_existing_problems

from solve_llm import solve_with_llm, write_llm_results
from solve_optic import solve_with_optic, write_optic_results
from solve_results import (
    compute_solver_summary,
    merge_results,
    write_summary_csv,
    write_summary_json,
)

try:
    from evaluate_llm_solver import MAX_NEW_TOKENS  # type: ignore

    HAVE_LLM = True
except Exception:
    HAVE_LLM = False
    MAX_NEW_TOKENS = 8000


def main():
    """Command-line interface for problem solving."""
    parser = argparse.ArgumentParser(description="Solve benchmark problems.")
    parser.add_argument(
        "--benchmark-dir",
        type=Path,
        default=PROJECT_ROOT / "benchmark_problems",
        help="Directory containing benchmark problems.",
    )
    parser.add_argument(
        "--time-limit",
        type=float,
        default=DEFAULT_TIME_LIMIT,
        help="Per-problem time limit (seconds) for OPTIC.",
    )
    parser.add_argument(
        "--skip-llm",
        action="store_true",
        help="Skip the LLM solver benchmark.",
    )
    parser.add_argument(
        "--skip-optic",
        action="store_true",
        help="Skip the OPTIC solver benchmark.",
    )
    parser.add_argument(
        "--llm-model",
        type=str,
        default="unsloth/gpt-oss-20b-unsloth-bnb-4bit",
        help="LLM model to use.",
    )
    parser.add_argument(
        "--llm-family",
        type=str,
        default="gpt",
        choices=["auto", "mistral", "llama", "phi", "qwen", "gemma", "gpt"],
        help="Model family for tokenizer templating.",
    )
    parser.add_argument(
        "--llm-max-new-tokens",
        type=int,
        default=MAX_NEW_TOKENS if HAVE_LLM else 8000,
        help="Maximum number of tokens generated by the LLM solver.",
    )
    parser.add_argument(
        "--llm-hardest-only",
        action="store_true",
        help="Only run the LLM solver on the hardest problem per scenario.",
    )
    parser.add_argument(
        "--skip-solved",
        action="store_true",
        help="Reuse cached solver results when available.",
    )
    parser.add_argument(
        "--instances-per-parameter",
        type=int,
        default=None,
        help="Limit to this many instances per parameter value when loading problems.",
    )
    
    args = parser.parse_args()
    
    if args.skip_optic and args.skip_llm:
        print("Error: Cannot skip both OPTIC and LLM solvers.", file=sys.stderr)
        sys.exit(1)
    
    # Check required binaries
    check_optic = not args.skip_optic
    check_validator = not args.skip_llm
    ensure_binaries(check_optic=check_optic, check_validator=check_validator)
    
    # Load cache
    cache_path = args.benchmark_dir / CACHE_FILENAME
    cache = load_solver_cache(cache_path)
    
    # Load existing problems
    print("Loading existing problems...", flush=True)
    generated = load_existing_problems(
        args.benchmark_dir,
        instances_per_parameter=args.instances_per_parameter,
    )
    total_problems = sum(len(problems) for problems in generated.values())
    if total_problems == 0:
        print(f"Error: No problems found in {args.benchmark_dir}", file=sys.stderr)
        sys.exit(1)
    
    print(f"Loaded {total_problems} problems across {len(generated)} scenarios.")
    
    # Run solvers
    optic_results = {}
    llm_results = {}
    
    if not args.skip_optic:
        optic_csv = args.benchmark_dir / "optic_results.csv"
        optic_results = solve_with_optic(
            args.benchmark_dir,
            generated,
            args.time_limit,
            incremental_write=True,
            results_csv=optic_csv,
            skip_solved=args.skip_solved,
            cache=cache,
            cache_path=cache_path,
        )
    
    if not args.skip_llm:
        llm_csv = args.benchmark_dir / "llm_results.csv"
        llm_results = solve_with_llm(
            args.benchmark_dir,
            generated,
            args.llm_model,
            args.llm_family,
            args.llm_max_new_tokens,
            args.llm_hardest_only,
            incremental_write=True,
            results_csv=llm_csv,
            skip_solved=args.skip_solved,
            cache=cache,
            cache_path=cache_path,
        )
    
    # Write summaries
    has_optic = len(optic_results) > 0
    has_llm = len(llm_results) > 0
    
    optic_summary = compute_solver_summary(generated, optic_results, only_present=False) if has_optic else {}
    llm_summary = compute_solver_summary(generated, llm_results, only_present=True) if has_llm else None
    
    write_summary_csv(args.benchmark_dir, optic_summary, llm_summary)
    print(f"Summary written to: {args.benchmark_dir / 'solver_summary.csv'}")
    
    # Write JSON summary
    if has_optic and has_llm:
        write_summary_json(
            args.benchmark_dir,
            generated,
            optic_results,
            llm_results,
            optic_summary,
            llm_summary,
            args.instances_per_parameter or 2,
            0,  # problems_per_scenario (not applicable when loading existing)
            args.time_limit,
            args.llm_model,
            args.llm_family,
            args.llm_max_new_tokens,
            args.llm_hardest_only,
            "solver_summary.json",
        )
    elif has_optic:
        write_summary_json(
            args.benchmark_dir,
            generated,
            optic_results,
            {},
            optic_summary,
            None,
            args.instances_per_parameter or 2,
            0,
            args.time_limit,
            args.llm_model,
            args.llm_family,
            args.llm_max_new_tokens,
            args.llm_hardest_only,
            "optic_summary.json",
        )
    elif has_llm:
        write_summary_json(
            args.benchmark_dir,
            generated,
            {},
            llm_results,
            {},
            llm_summary,
            args.instances_per_parameter or 2,
            0,
            args.time_limit,
            args.llm_model,
            args.llm_family,
            args.llm_max_new_tokens,
            args.llm_hardest_only,
            "llm_summary.json",
        )
    
    if cache is not None:
        save_solver_cache(cache_path, cache)
    
    print("Solving completed.")


if __name__ == "__main__":
    main()

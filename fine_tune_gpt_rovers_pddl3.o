
CondaError: Run 'conda init' before 'conda activate'

[torchao|WARNING]Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA A100 80GB PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.10.12: Fast Gpt_Oss patching. Transformers: 4.56.2.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.01s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.11s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.47it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.22it/s]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from data/sft/rovers/pddl3.hf...
Loading HuggingFace dataset...
Dataset loaded with 2000 entries
Scenario distribution:
  rovers: 2000

Filtering scenarios to: ['rovers']
Filtered dataset size: 2000
Processing dataset format (chat template)...
Map:   0%|          | 0/1900 [00:00<?, ? examples/s]Map:   4%|â–Ž         | 70/1900 [00:00<00:02, 691.59 examples/s]Map:  16%|â–ˆâ–‹        | 310/1900 [00:00<00:00, 1688.55 examples/s]Map:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 847/1900 [00:00<00:00, 3360.72 examples/s]Map:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1426/1900 [00:00<00:00, 3814.21 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:00<00:00, 3923.92 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:00<00:00, 3437.77 examples/s]
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 4930.30 examples/s]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251031_002830-0x0mrnr1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_pddl3
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/0x0mrnr1
wandb: Detected [huggingface_hub.inference] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Testing initial model performance...
Initial model output:
analysisWe need to produce a valid plan for given PDDL domain and problem. Let's interpret. Domain: Rover domain with actions navigate, sample_soil, sample_rock, drop, calibrate, take_image, communicate_soil_data, communicate_rock_data, communicate_image_data.

Problem gives initial state, goal: communicated soil data for waypoint4 and waypoint11, and image data for objective3 colour and objective1 low_res.

There's also a constraint: (sometime-before (at rover0 waypoint3) (at rover0 waypoint9))...

Resolved training arguments:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-05
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 2048
  load_in_4bit: True

Creating trainer...
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/1900 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   3%|â–Ž         | 60/1900 [00:02<01:13, 24.87 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   9%|â–‰         | 180/1900 [00:02<00:21, 79.56 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  13%|â–ˆâ–Ž        | 240/1900 [00:02<00:15, 108.54 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 300/1900 [00:03<00:11, 140.52 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 360/1900 [00:03<00:11, 131.38 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 420/1900 [00:03<00:09, 163.17 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 480/1900 [00:03<00:07, 196.09 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 540/1900 [00:04<00:05, 226.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 660/1900 [00:04<00:03, 330.54 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 720/1900 [00:04<00:05, 227.12 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 838/1900 [00:05<00:03, 311.65 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 897/1900 [00:05<00:03, 262.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1015/1900 [00:05<00:02, 345.73 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1133/1900 [00:05<00:01, 420.20 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1192/1900 [00:05<00:01, 389.42 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1251/1900 [00:06<00:01, 389.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1310/1900 [00:06<00:02, 247.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1428/1900 [00:06<00:01, 337.08 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1546/1900 [00:06<00:00, 416.24 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1605/1900 [00:07<00:00, 304.78 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1664/1900 [00:07<00:00, 325.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1782/1900 [00:07<00:00, 410.76 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1841/1900 [00:07<00:00, 381.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:08<00:00, 229.75 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   4%|â–         | 4/100 [00:02<00:48,  1.97 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   8%|â–Š         | 8/100 [00:02<00:22,  4.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  12%|â–ˆâ–        | 12/100 [00:02<00:13,  6.52 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 16/100 [00:02<00:09,  8.57 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 19/100 [00:02<00:08,  9.34 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 22/100 [00:03<00:07,  9.91 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:03<00:06, 11.44 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 28/100 [00:03<00:05, 12.90 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:03<00:06, 10.51 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:04<00:05, 11.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:04<00:04, 14.26 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:04<00:03, 14.40 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:05<00:03, 13.72 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:05<00:02, 16.15 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:05<00:02, 16.55 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:05<00:02, 16.96 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 67/100 [00:06<00:01, 16.60 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:06<00:01, 17.18 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:06<00:02, 12.84 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:06<00:01, 15.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:07<00:01, 14.46 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:07<00:00, 15.14 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:07<00:00, 15.69 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:08<00:00, 16.53 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 16.78 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:08<00:00, 11.60 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,900 | Num Epochs = 3 | Total steps = 357
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)

Starting training...
  0%|          | 0/357 [00:00<?, ?it/s]  0%|          | 1/357 [00:14<1:23:30, 14.07s/it]  1%|          | 2/357 [00:21<58:40,  9.92s/it]    1%|          | 3/357 [00:27<50:21,  8.54s/it]  1%|          | 4/357 [00:34<45:55,  7.81s/it]  1%|â–         | 5/357 [00:41<43:26,  7.40s/it]  2%|â–         | 6/357 [00:48<41:54,  7.17s/it]  2%|â–         | 7/357 [00:54<40:56,  7.02s/it]  2%|â–         | 8/357 [01:01<40:15,  6.92s/it]  3%|â–Ž         | 9/357 [01:08<39:43,  6.85s/it]  3%|â–Ž         | 10/357 [01:14<39:20,  6.80s/it]                                                  3%|â–Ž         | 10/357 [01:14<39:20,  6.80s/it]  3%|â–Ž         | 11/357 [01:21<39:03,  6.77s/it]  3%|â–Ž         | 12/357 [01:28<38:48,  6.75s/it]  4%|â–Ž         | 13/357 [01:34<38:37,  6.74s/it]  4%|â–         | 14/357 [01:41<38:26,  6.72s/it]  4%|â–         | 15/357 [01:48<38:16,  6.71s/it]  4%|â–         | 16/357 [01:55<38:07,  6.71s/it]  5%|â–         | 17/357 [02:01<38:00,  6.71s/it]  5%|â–Œ         | 18/357 [02:08<37:56,  6.71s/it]  5%|â–Œ         | 19/357 [02:15<37:49,  6.71s/it]  6%|â–Œ         | 20/357 [02:21<37:42,  6.71s/it]                                                  6%|â–Œ         | 20/357 [02:21<37:42,  6.71s/it]  6%|â–Œ         | 21/357 [02:28<37:36,  6.71s/it]  6%|â–Œ         | 22/357 [02:35<37:28,  6.71s/it]  6%|â–‹         | 23/357 [02:42<37:22,  6.71s/it]  7%|â–‹         | 24/357 [02:48<37:14,  6.71s/it]  7%|â–‹         | 25/357 [02:55<37:06,  6.71s/it]  7%|â–‹         | 26/357 [03:02<36:59,  6.70s/it]  8%|â–Š         | 27/357 [03:08<36:51,  6.70s/it]  8%|â–Š         | 28/357 [03:15<36:44,  6.70s/it]  8%|â–Š         | 29/357 [03:22<36:37,  6.70s/it]  8%|â–Š         | 30/357 [03:28<36:30,  6.70s/it]                                                  8%|â–Š         | 30/357 [03:28<36:30,  6.70s/it]  9%|â–Š         | 31/357 [03:35<36:27,  6.71s/it]  9%|â–‰         | 32/357 [03:42<36:23,  6.72s/it]  9%|â–‰         | 33/357 [03:49<36:21,  6.73s/it] 10%|â–‰         | 34/357 [03:56<36:55,  6.86s/it] 10%|â–‰         | 35/357 [04:03<36:39,  6.83s/it] 10%|â–ˆ         | 36/357 [04:09<36:25,  6.81s/it] 10%|â–ˆ         | 37/357 [04:16<36:14,  6.80s/it] 11%|â–ˆ         | 38/357 [04:23<36:04,  6.79s/it] 11%|â–ˆ         | 39/357 [04:30<35:55,  6.78s/it] 11%|â–ˆ         | 40/357 [04:36<35:47,  6.78s/it]                                                 11%|â–ˆ         | 40/357 [04:36<35:47,  6.78s/it] 11%|â–ˆâ–        | 41/357 [04:43<35:40,  6.77s/it] 12%|â–ˆâ–        | 42/357 [04:50<35:34,  6.78s/it] 12%|â–ˆâ–        | 43/357 [04:57<35:30,  6.79s/it] 12%|â–ˆâ–        | 44/357 [05:04<35:23,  6.78s/it] 13%|â–ˆâ–Ž        | 45/357 [05:10<35:15,  6.78s/it] 13%|â–ˆâ–Ž        | 46/357 [05:17<35:09,  6.78s/it] 13%|â–ˆâ–Ž        | 47/357 [05:24<35:01,  6.78s/it] 13%|â–ˆâ–Ž        | 48/357 [05:31<34:54,  6.78s/it] 14%|â–ˆâ–Ž        | 49/357 [05:37<34:46,  6.77s/it] 14%|â–ˆâ–        | 50/357 [05:44<34:40,  6.78s/it]                                                 14%|â–ˆâ–        | 50/357 [05:44<34:40,  6.78s/it] 14%|â–ˆâ–        | 51/357 [05:51<34:32,  6.77s/it] 15%|â–ˆâ–        | 52/357 [05:58<34:26,  6.78s/it] 15%|â–ˆâ–        | 53/357 [06:05<34:19,  6.77s/it] 15%|â–ˆâ–Œ        | 54/357 [06:11<34:13,  6.78s/it] 15%|â–ˆâ–Œ        | 55/357 [06:18<34:06,  6.78s/it] 16%|â–ˆâ–Œ        | 56/357 [06:25<33:58,  6.77s/it] 16%|â–ˆâ–Œ        | 57/357 [06:32<33:51,  6.77s/it] 16%|â–ˆâ–Œ        | 58/357 [06:38<33:46,  6.78s/it] 17%|â–ˆâ–‹        | 59/357 [06:45<33:39,  6.78s/it] 17%|â–ˆâ–‹        | 60/357 [06:52<33:32,  6.78s/it]                                                 17%|â–ˆâ–‹        | 60/357 [06:52<33:32,  6.78s/it] 17%|â–ˆâ–‹        | 61/357 [06:59<33:24,  6.77s/it] 17%|â–ˆâ–‹        | 62/357 [07:06<33:18,  6.77s/it] 18%|â–ˆâ–Š        | 63/357 [07:12<33:11,  6.77s/it] 18%|â–ˆâ–Š        | 64/357 [07:19<33:04,  6.77s/it] 18%|â–ˆâ–Š        | 65/357 [07:26<32:58,  6.77s/it] 18%|â–ˆâ–Š        | 66/357 [07:33<32:51,  6.78s/it] 19%|â–ˆâ–‰        | 67/357 [07:39<32:44,  6.77s/it] 19%|â–ˆâ–‰        | 68/357 [07:47<33:14,  6.90s/it] 19%|â–ˆâ–‰        | 69/357 [07:53<32:56,  6.86s/it] 20%|â–ˆâ–‰        | 70/357 [08:00<32:43,  6.84s/it]                                                 20%|â–ˆâ–‰        | 70/357 [08:00<32:43,  6.84s/it] 20%|â–ˆâ–‰        | 71/357 [08:07<32:31,  6.82s/it] 20%|â–ˆâ–ˆ        | 72/357 [08:14<32:20,  6.81s/it] 20%|â–ˆâ–ˆ        | 73/357 [08:20<32:11,  6.80s/it] 21%|â–ˆâ–ˆ        | 74/357 [08:27<32:03,  6.80s/it] 21%|â–ˆâ–ˆ        | 75/357 [08:34<31:56,  6.80s/it] 21%|â–ˆâ–ˆâ–       | 76/357 [08:41<31:49,  6.80s/it] 22%|â–ˆâ–ˆâ–       | 77/357 [08:48<31:41,  6.79s/it] 22%|â–ˆâ–ˆâ–       | 78/357 [08:54<31:34,  6.79s/it] 22%|â–ˆâ–ˆâ–       | 79/357 [09:01<31:27,  6.79s/it] 22%|â–ˆâ–ˆâ–       | 80/357 [09:08<31:21,  6.79s/it]                                                 22%|â–ˆâ–ˆâ–       | 80/357 [09:08<31:21,  6.79s/it] 23%|â–ˆâ–ˆâ–Ž       | 81/357 [09:15<31:15,  6.79s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/357 [09:22<31:07,  6.79s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/357 [09:28<31:00,  6.79s/it] 24%|â–ˆâ–ˆâ–Ž       | 84/357 [09:35<30:53,  6.79s/it] 24%|â–ˆâ–ˆâ–       | 85/357 [09:42<30:46,  6.79s/it] 24%|â–ˆâ–ˆâ–       | 86/357 [09:49<30:39,  6.79s/it] 24%|â–ˆâ–ˆâ–       | 87/357 [09:56<30:32,  6.79s/it] 25%|â–ˆâ–ˆâ–       | 88/357 [10:02<30:25,  6.79s/it] 25%|â–ˆâ–ˆâ–       | 89/357 [10:09<30:18,  6.78s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:16<30:10,  6.78s/it]                                                 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:16<30:10,  6.78s/it] 25%|â–ˆâ–ˆâ–Œ       | 91/357 [10:23<30:03,  6.78s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/357 [10:29<29:56,  6.78s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/357 [10:36<29:49,  6.78s/it] 26%|â–ˆâ–ˆâ–‹       | 94/357 [10:43<29:41,  6.77s/it] 27%|â–ˆâ–ˆâ–‹       | 95/357 [10:50<29:33,  6.77s/it] 27%|â–ˆâ–ˆâ–‹       | 96/357 [10:57<29:26,  6.77s/it] 27%|â–ˆâ–ˆâ–‹       | 97/357 [11:03<29:18,  6.76s/it] 27%|â–ˆâ–ˆâ–‹       | 98/357 [11:10<29:11,  6.76s/it] 28%|â–ˆâ–ˆâ–Š       | 99/357 [11:17<29:05,  6.76s/it] 28%|â–ˆâ–ˆâ–Š       | 100/357 [11:24<28:57,  6.76s/it]                                                  28%|â–ˆâ–ˆâ–Š       | 100/357 [11:24<28:57,  6.76s/it] 28%|â–ˆâ–ˆâ–Š       | 101/357 [11:30<28:51,  6.76s/it] 29%|â–ˆâ–ˆâ–Š       | 102/357 [11:37<29:16,  6.89s/it] 29%|â–ˆâ–ˆâ–‰       | 103/357 [11:44<29:01,  6.86s/it] 29%|â–ˆâ–ˆâ–‰       | 104/357 [11:51<28:48,  6.83s/it] 29%|â–ˆâ–ˆâ–‰       | 105/357 [11:58<28:37,  6.82s/it] 30%|â–ˆâ–ˆâ–‰       | 106/357 [12:05<28:27,  6.80s/it] 30%|â–ˆâ–ˆâ–‰       | 107/357 [12:11<28:18,  6.80s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/357 [12:18<28:10,  6.79s/it] 31%|â–ˆâ–ˆâ–ˆ       | 109/357 [12:25<28:02,  6.79s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:32<27:55,  6.78s/it]                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:32<27:55,  6.78s/it] 31%|â–ˆâ–ˆâ–ˆ       | 111/357 [12:38<27:49,  6.78s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 112/357 [12:45<27:41,  6.78s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 113/357 [12:52<27:34,  6.78s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 114/357 [12:59<27:27,  6.78s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 115/357 [13:06<27:21,  6.78s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 116/357 [13:12<27:14,  6.78s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/357 [13:19<27:07,  6.78s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/357 [13:26<26:59,  6.78s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [13:31<24:52,  6.27s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.9044, 'grad_norm': 74.66744995117188, 'learning_rate': 5e-06, 'epoch': 0.08}
{'loss': 2.812, 'grad_norm': 30.571544647216797, 'learning_rate': 1.0555555555555557e-05, 'epoch': 0.17}
{'loss': 1.4161, 'grad_norm': 3.485154390335083, 'learning_rate': 1.6111111111111115e-05, 'epoch': 0.25}
{'loss': 0.9406, 'grad_norm': 1.660339593887329, 'learning_rate': 1.9995690062269985e-05, 'epoch': 0.34}
{'loss': 0.7113, 'grad_norm': 1.6289968490600586, 'learning_rate': 1.9919172253651637e-05, 'epoch': 0.42}
{'loss': 0.4758, 'grad_norm': 1.9986368417739868, 'learning_rate': 1.974772117649135e-05, 'epoch': 0.51}
{'loss': 0.2555, 'grad_norm': 1.8106131553649902, 'learning_rate': 1.9482977734962753e-05, 'epoch': 0.59}
{'loss': 0.1078, 'grad_norm': 1.0861576795578003, 'learning_rate': 1.9127475705028864e-05, 'epoch': 0.67}
{'loss': 0.0284, 'grad_norm': 0.6276162266731262, 'learning_rate': 1.8684617484471662e-05, 'epoch': 0.76}
{'loss': 0.0124, 'grad_norm': 0.20179106295108795, 'learning_rate': 1.815864152961624e-05, 'epoch': 0.84}
{'loss': 0.0081, 'grad_norm': 0.12327498197555542, 'learning_rate': 1.7554581790402372e-05, 'epoch': 0.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:13,  1.66it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:20,  1.07it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:23,  1.11s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.28s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:25,  1.32s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:24,  1.35s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:09<00:23,  1.37s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.44s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:12<00:21,  1.43s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:19,  1.43s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:15<00:18,  1.42s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:18<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.44s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:21<00:12,  1.43s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.48s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:24<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:25<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:28<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:31<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:34<00:00,  1.49s/it][A                                                 
                                               [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [14:08<24:52,  6.27s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:45<1:44:52, 26.55s/it]                                                    34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:45<1:44:52, 26.55s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 121/357 [14:50<1:18:58, 20.08s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 122/357 [14:54<1:00:23, 15.42s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 123/357 [14:59<47:25, 12.16s/it]   35%|â–ˆâ–ˆâ–ˆâ–      | 124/357 [15:04<38:21,  9.88s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/357 [15:08<32:29,  8.40s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/357 [15:13<27:54,  7.25s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 127/357 [15:18<24:40,  6.44s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 128/357 [15:22<22:24,  5.87s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 129/357 [15:27<20:47,  5.47s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:32<20:04,  5.31s/it]                                                  36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:32<20:04,  5.31s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/357 [15:36<19:07,  5.08s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 132/357 [15:41<18:26,  4.92s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 133/357 [15:45<17:55,  4.80s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 134/357 [15:50<17:33,  4.72s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 135/357 [15:55<17:41,  4.78s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 136/357 [15:59<17:21,  4.71s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 137/357 [16:04<17:05,  4.66s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 138/357 [16:08<16:52,  4.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 139/357 [16:13<17:07,  4.71s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [16:18<16:51,  4.66s/it]                                                  39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [16:18<16:51,  4.66s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 141/357 [16:22<16:39,  4.63s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 142/357 [16:27<16:29,  4.60s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/357 [16:31<16:21,  4.58s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/357 [16:36<16:39,  4.69s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 145/357 [16:41<16:25,  4.65s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 146/357 [16:45<16:14,  4.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 147/357 [16:50<16:05,  4.60s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/357 [16:55<16:24,  4.71s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/357 [17:00<16:09,  4.66s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [17:04<15:58,  4.63s/it]                                                  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [17:04<15:58,  4.63s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 151/357 [17:09<15:48,  4.60s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 152/357 [17:13<15:40,  4.59s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/357 [17:18<15:57,  4.69s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 154/357 [17:23<15:43,  4.65s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 155/357 [17:27<15:32,  4.62s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 156/357 [17:32<15:23,  4.60s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/357 [17:36<15:16,  4.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/357 [17:41<15:32,  4.69s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/357 [17:46<15:19,  4.64s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:50<15:08,  4.61s/it]                                                  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:50<15:08,  4.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 161/357 [17:55<14:59,  4.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 162/357 [18:00<15:14,  4.69s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 163/357 [18:04<15:01,  4.65s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 164/357 [18:09<14:50,  4.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 165/357 [18:13<14:41,  4.59s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 166/357 [18:18<14:34,  4.58s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 167/357 [18:23<14:50,  4.69s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 168/357 [18:27<14:37,  4.64s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 169/357 [18:32<14:27,  4.61s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:37<14:19,  4.59s/it]                                                  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:37<14:19,  4.59s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 171/357 [18:41<14:11,  4.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 172/357 [18:46<14:26,  4.69s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 173/357 [18:51<14:14,  4.64s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 174/357 [18:55<14:04,  4.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 175/357 [19:00<13:55,  4.59s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 176/357 [19:05<14:12,  4.71s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 177/357 [19:09<13:59,  4.66s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 178/357 [19:14<13:48,  4.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 179/357 [19:18<13:39,  4.60s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [19:23<13:31,  4.59s/it]                                                  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [19:23<13:31,  4.59s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 181/357 [19:28<13:45,  4.69s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 182/357 [19:32<13:33,  4.65s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/357 [19:37<13:23,  4.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 184/357 [19:41<13:15,  4.60s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 185/357 [19:46<13:07,  4.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 186/357 [19:51<13:20,  4.68s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 187/357 [19:55<13:08,  4.64s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 188/357 [20:00<12:59,  4.61s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 189/357 [20:04<12:51,  4.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [20:09<13:03,  4.69s/it]                                                  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [20:09<13:03,  4.69s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 191/357 [20:14<12:51,  4.65s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 192/357 [20:18<12:41,  4.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 193/357 [20:23<12:33,  4.59s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 194/357 [20:28<12:26,  4.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/357 [20:32<12:39,  4.69s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 196/357 [20:37<12:27,  4.64s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 197/357 [20:42<12:18,  4.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 198/357 [20:46<12:10,  4.59s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 199/357 [20:51<12:02,  4.57s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [20:56<12:14,  4.68s/it]                                                  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [20:56<12:14,  4.68s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 201/357 [21:00<12:03,  4.64s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 202/357 [21:05<11:54,  4.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 203/357 [21:09<11:46,  4.59s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 204/357 [21:14<11:39,  4.57s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 205/357 [21:19<11:51,  4.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 206/357 [21:23<11:41,  4.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 207/357 [21:28<11:31,  4.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 208/357 [21:32<11:24,  4.59s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 209/357 [21:37<11:17,  4.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:42<11:30,  4.70s/it]                                                  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:42<11:30,  4.70s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 211/357 [21:46<11:19,  4.65s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 212/357 [21:51<11:09,  4.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 213/357 [21:55<11:01,  4.60s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 214/357 [22:00<11:11,  4.70s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 215/357 [22:05<11:01,  4.66s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 216/357 [22:10<10:51,  4.62s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 217/357 [22:14<10:43,  4.60s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 218/357 [22:19<10:36,  4.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 219/357 [22:24<10:46,  4.68s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:28<10:36,  4.65s/it]                                                  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:28<10:36,  4.65s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 221/357 [22:33<10:27,  4.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 222/357 [22:37<10:20,  4.59s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 223/357 [22:42<10:29,  4.69s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 224/357 [22:47<10:18,  4.65s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 225/357 [22:51<10:09,  4.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 226/357 [22:56<10:02,  4.60s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 227/357 [23:00<09:55,  4.58s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 228/357 [23:05<10:04,  4.69s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 229/357 [23:10<09:54,  4.64s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [23:14<09:46,  4.62s/it]                                                  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [23:14<09:46,  4.62s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/357 [23:19<09:39,  4.60s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/357 [23:23<09:32,  4.58s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 233/357 [23:28<09:40,  4.69s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 234/357 [23:33<09:31,  4.64s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 235/357 [23:37<09:22,  4.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 236/357 [23:42<09:15,  4.59s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 237/357 [23:46<09:09,  4.58s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [23:50<08:36,  4.34s/it]{'eval_loss': 0.0049598440527915955, 'eval_runtime': 36.7106, 'eval_samples_per_second': 2.724, 'eval_steps_per_second': 0.681, 'epoch': 1.0}

==================================================
Testing model performance...
==================================================
Generated solution:
analysisThe user requests the plan only. They provided a domain and a problem. The domain has types: rover, waypoint, store, camera, objective, lander. It also has a constant 'general' of type lander.

Objects defined in problem: rover0 - Rover; rover0store - Store; waypoints 0-11 - Waypoint; camera0, camera1, camera2 - Camera; objective0-3 - Objective.

Initial facts list numerous visibles, samples, at positions, store mapping, empties, equipped, can_traverse, on_board. The goal is that communicated_soil_data waypoint4 and waypoint11, communicated_image_data objective3 colour, communicated_image_data objective1 low_res are true. Also available rover0. The side channel: the lander general at waypoint0, channel_free general. Also the store mapping.

Also there's a constraint: sometime-before (at rover0 waypoint3) (at rover0 waypoint9). So rover0 must visit waypoint3 before visiting waypoint9. That's important for the plan order.

Goal facts:

- communicated_soil_data waypoint4
- communicated_soil_data waypoint11
- communicated_image_data objective3 colour
- communicated_image_data objective1 low_res

Thus we need the rover to sample soil at waypoint4 and waypoint11, communicate those from its current waypoint to the lander at waypoint0 (the visible ones allow communication). And also need to take images for objective3 colour and objective1 low_res. Images must be taken at waypoints visible to those objectives with calibrated camera that target that objective. Then communicate that image data from current waypoint to lander at waypoint0 using objective3 low_res communication for objective3 colour? Wait, the constraints: for communication we need have_image ?r ?o ?m and visible waypoint->lander. The image data to be communicated are objective3 colour (i.e., the image taken by camera currently on rover0, with model supports colour and calibration target objective3). And objective1 low_res.

Thus we need to calibrate cameras to objective2 and objective3 (camera0 to objective2; camera1 to objective3; camera2 to objective3). But only camera0 can be used for colour images of objective2? No, visible_from objective2 waypoint1,5,6,7,8,11. So camera to be used for objective3 colour needs calibration_target camera2 objective3. But also supports colour. Good. For objective1 low_res, visible_from objective1 at waypoints
==================================================
{'loss': 0.0059, 'grad_norm': 0.17765332758426666, 'learning_rate': 1.687821953203765e-05, 'epoch': 1.01}
{'loss': 0.0041, 'grad_norm': 0.11786257475614548, 'learning_rate': 1.613602800433194e-05, 'epoch': 1.09}
{'loss': 0.0026, 'grad_norm': 0.059441182762384415, 'learning_rate': 1.5335110488265497e-05, 'epoch': 1.18}
{'loss': 0.0014, 'grad_norm': 0.05312442407011986, 'learning_rate': 1.4483132312727501e-05, 'epoch': 1.26}
{'loss': 0.0008, 'grad_norm': 0.03841991722583771, 'learning_rate': 1.358824749207136e-05, 'epoch': 1.35}
{'loss': 0.0006, 'grad_norm': 0.10136964917182922, 'learning_rate': 1.2659020686615602e-05, 'epoch': 1.43}
{'loss': 0.0005, 'grad_norm': 0.01845114305615425, 'learning_rate': 1.170434523298175e-05, 'epoch': 1.51}
{'loss': 0.0004, 'grad_norm': 0.014272961765527725, 'learning_rate': 1.073335802877504e-05, 'epoch': 1.6}
{'loss': 0.0004, 'grad_norm': 0.021824637427926064, 'learning_rate': 9.755352086219733e-06, 'epoch': 1.68}
{'loss': 0.0004, 'grad_norm': 0.011188262142241001, 'learning_rate': 8.779687591670687e-06, 'epoch': 1.77}
{'loss': 0.0003, 'grad_norm': 0.011084013618528843, 'learning_rate': 7.815702322222539e-06, 'epoch': 1.85}
{'loss': 0.0003, 'grad_norm': 0.009185384958982468, 'learning_rate': 6.872622276790804e-06, 'epoch': 1.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:21,  1.00it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.40s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:21<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.48s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [24:27<08:36,  4.34s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 239/357 [25:04<49:33, 25.20s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [25:09<37:03, 19.01s/it]                                                  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [25:09<37:03, 19.01s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 241/357 [25:13<28:21, 14.67s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 242/357 [25:18<22:32, 11.76s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 243/357 [25:23<18:14,  9.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 244/357 [25:27<15:12,  8.08s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 245/357 [25:32<13:05,  7.02s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 246/357 [25:36<11:36,  6.27s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 247/357 [25:41<10:45,  5.87s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 248/357 [25:46<09:56,  5.47s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 249/357 [25:50<09:20,  5.19s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [25:55<08:54,  5.00s/it]                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [25:55<08:54,  5.00s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 251/357 [25:59<08:35,  4.86s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 252/357 [26:04<08:32,  4.88s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 253/357 [26:09<08:17,  4.78s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 254/357 [26:13<08:05,  4.71s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 255/357 [26:18<07:55,  4.66s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 256/357 [26:23<07:58,  4.74s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 257/357 [26:28<07:48,  4.68s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 258/357 [26:32<07:39,  4.64s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 259/357 [26:37<07:31,  4.61s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:41<07:25,  4.59s/it]                                                  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:41<07:25,  4.59s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 261/357 [26:46<07:30,  4.69s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 262/357 [26:51<07:21,  4.65s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 263/357 [26:55<07:13,  4.62s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 264/357 [27:00<07:07,  4.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 265/357 [27:04<07:01,  4.58s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 266/357 [27:09<07:06,  4.69s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 267/357 [27:14<06:57,  4.64s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 268/357 [27:18<06:50,  4.62s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 269/357 [27:23<06:44,  4.60s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [27:28<06:50,  4.72s/it]                                                  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [27:28<06:50,  4.72s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 271/357 [27:32<06:41,  4.67s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 272/357 [27:37<06:33,  4.63s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 273/357 [27:41<06:26,  4.60s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 274/357 [27:46<06:20,  4.58s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 275/357 [27:51<06:24,  4.69s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 276/357 [27:55<06:16,  4.65s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 277/357 [28:00<06:09,  4.62s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 278/357 [28:05<06:02,  4.59s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 279/357 [28:09<05:57,  4.58s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [28:14<06:01,  4.69s/it]                                                  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [28:14<06:01,  4.69s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 281/357 [28:19<05:53,  4.65s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 282/357 [28:23<05:46,  4.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 283/357 [28:28<05:40,  4.59s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 284/357 [28:32<05:34,  4.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 285/357 [28:37<05:37,  4.68s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 286/357 [28:42<05:29,  4.64s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 287/357 [28:46<05:22,  4.61s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 288/357 [28:51<05:16,  4.59s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 289/357 [28:55<05:11,  4.58s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [29:00<05:14,  4.70s/it]                                                  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [29:00<05:14,  4.70s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 291/357 [29:05<05:07,  4.65s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 292/357 [29:09<05:00,  4.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 293/357 [29:14<04:54,  4.60s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294/357 [29:19<04:56,  4.70s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 295/357 [29:23<04:48,  4.65s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 296/357 [29:28<04:42,  4.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 297/357 [29:33<04:35,  4.60s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 298/357 [29:37<04:30,  4.58s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 299/357 [29:42<04:31,  4.69s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:47<04:25,  4.66s/it]                                                  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:47<04:25,  4.66s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 301/357 [29:51<04:19,  4.63s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 302/357 [29:56<04:13,  4.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 303/357 [30:00<04:08,  4.60s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 304/357 [30:05<04:09,  4.72s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 305/357 [30:10<04:03,  4.68s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 306/357 [30:14<03:57,  4.65s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 307/357 [30:19<03:50,  4.62s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 308/357 [30:24<03:45,  4.60s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 309/357 [30:29<03:45,  4.70s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:33<03:39,  4.66s/it]                                                  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:33<03:39,  4.66s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 311/357 [30:38<03:32,  4.63s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 312/357 [30:42<03:27,  4.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 313/357 [30:47<03:27,  4.72s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 314/357 [30:52<03:21,  4.68s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 315/357 [30:56<03:14,  4.64s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 316/357 [31:01<03:08,  4.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 317/357 [31:05<03:03,  4.59s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 318/357 [31:10<03:03,  4.70s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 319/357 [31:15<02:56,  4.65s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [31:19<02:50,  4.62s/it]                                                  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [31:19<02:50,  4.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 321/357 [31:24<02:45,  4.60s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 322/357 [31:29<02:40,  4.58s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 323/357 [31:33<02:39,  4.69s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 324/357 [31:38<02:33,  4.65s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 325/357 [31:43<02:28,  4.63s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 326/357 [31:47<02:22,  4.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 327/357 [31:52<02:17,  4.59s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 328/357 [31:57<02:16,  4.71s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/357 [32:01<02:10,  4.66s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [32:06<02:04,  4.62s/it]                                                  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [32:06<02:04,  4.62s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 331/357 [32:10<01:59,  4.60s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 332/357 [32:15<01:57,  4.70s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 333/357 [32:20<01:51,  4.66s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 334/357 [32:24<01:46,  4.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 335/357 [32:29<01:41,  4.60s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 336/357 [32:33<01:36,  4.59s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 337/357 [32:38<01:34,  4.70s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 338/357 [32:43<01:28,  4.66s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 339/357 [32:48<01:23,  4.62s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [32:52<01:18,  4.60s/it]                                                  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [32:52<01:18,  4.60s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 341/357 [32:57<01:13,  4.58s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 342/357 [33:02<01:10,  4.69s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 343/357 [33:06<01:05,  4.65s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 344/357 [33:11<01:00,  4.62s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 345/357 [33:15<00:55,  4.60s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 346/357 [33:20<00:50,  4.58s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 347/357 [33:25<00:46,  4.69s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 348/357 [33:29<00:41,  4.65s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 349/357 [33:34<00:36,  4.62s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:38<00:32,  4.59s/it]                                                  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:38<00:32,  4.59s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 351/357 [33:43<00:28,  4.71s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 352/357 [33:48<00:23,  4.66s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 353/357 [33:52<00:18,  4.63s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 354/357 [33:57<00:13,  4.60s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 355/357 [34:02<00:09,  4.59s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 356/357 [34:06<00:04,  4.70s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:10<00:00,  4.31s/it]{'eval_loss': 0.00024677274632267654, 'eval_runtime': 36.6996, 'eval_samples_per_second': 2.725, 'eval_steps_per_second': 0.681, 'epoch': 2.0}

==================================================
Testing model performance...
==================================================
Generated solution:
commentary to=functions?><questionaryThe problem is a rover planning problem. The domain defines types rover, waypoint, store, camera, objective, and predicates.

We have a rover0 that can traverse between certain waypoint pairs. The initial state lists many visible relations, soil sample, rock sample positions, etc.

Goal requires communicated_soil_data waypoint4, communicated_soil_data waypoint11, communicated_image_data objective3 colour, communicated_image_data objective1 low_res.

Constraint: sometime-before (at rover0 waypoint3) (at rover0 waypoint9)). So rover0 must visit waypoint3 before waypoint9. And it must be at waypoint9 at some point after visiting waypoint3. The plan can include visits to other waypoints too; but the eventual state must include at waypoint9.

We need to produce a grounded, totally-ordered plan satisfying goal and constraint. We must list actions like (navigate rover0 waypoint1 waypoint8), etc.

No durations, no timestamps.

We need plan that gets soil samples from waypoint4 and waypoint11, drops them at waypoint0, and takes images from objective3 colour (must be waypoint0 to capture objective3 because visible_from objective3 waypoint0). Also must capture objective1 low_res (waypoint1? visible_from objective1 waypoint1, waypoint2, waypoint4, waypoint6, waypoint8, waypoint9...). Wait visible_from objective1 relations include waypoint0,1,2,4,6,8,9. For colour image objective3, visible_from objective3 relations include waypoint0,7,8,11. For objective3 colour image, the waypoint must be visible from that waypoint. Also need to have on board a camera that calibrates to that objective. camera0 calibrates to objective2, cannot capture objective3. camera1 calibrates to objective3 and supports high_res and low_res. camera2 calibrates to objective3 and supports colour.

Goal includes communicated_image_data objective3 colour, so we need to use camera2. Also for objective1 low_res, we need camera1 or camera2; camera1 supports low_res and high_res, but camera1 is already on board, calibrates to objective3. camera2 supports colour, not low_res. So for objective1 low_res, we need camera1 as well. But camera1 supports low_res, but calibration_target camera1 objective3, so camera1 can only be calibrated to objective3. Wait in :init: (calibration_target camera1 objective3). So camera1 can only
==================================================
{'loss': 0.0003, 'grad_norm': 0.00933117140084505, 'learning_rate': 5.959473376986686e-06, 'epoch': 2.02}
{'loss': 0.0003, 'grad_norm': 0.047594908624887466, 'learning_rate': 5.084995082868658e-06, 'epoch': 2.1}
{'loss': 0.0003, 'grad_norm': 0.009079975076019764, 'learning_rate': 4.257556750327176e-06, 'epoch': 2.19}
{'loss': 0.0003, 'grad_norm': 0.00941159576177597, 'learning_rate': 3.485077530619664e-06, 'epoch': 2.27}
{'loss': 0.0003, 'grad_norm': 0.019298287108540535, 'learning_rate': 2.77495057867198e-06, 'epoch': 2.35}
{'loss': 0.0003, 'grad_norm': 0.009549501352012157, 'learning_rate': 2.133972295524875e-06, 'epoch': 2.44}
{'loss': 0.0003, 'grad_norm': 0.008244157768785954, 'learning_rate': 1.5682772821236192e-06, 'epoch': 2.52}
{'loss': 0.0003, 'grad_norm': 0.007917643524706364, 'learning_rate': 1.0832796269875757e-06, 'epoch': 2.61}
{'loss': 0.0003, 'grad_norm': 0.00784531980752945, 'learning_rate': 6.836210896769014e-07, 'epoch': 2.69}
{'loss': 0.0002, 'grad_norm': 0.007833040319383144, 'learning_rate': 3.731266759760854e-07, 'epoch': 2.77}
{'loss': 0.0002, 'grad_norm': 0.007081571035087109, 'learning_rate': 1.5476802997022812e-07, 'epoch': 2.86}
{'loss': 0.0002, 'grad_norm': 0.007783346343785524, 'learning_rate': 3.063499337692788e-08, 'epoch': 2.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:21,  1.00it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.40s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.46s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:47<00:00,  4.31s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [AHTTP Error 504 thrown while requesting HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/config.json
[huggingface_hub.utils._http|WARNING]HTTP Error 504 thrown while requesting HEAD https://huggingface.co/unsloth/gpt-oss-20b-unsloth-bnb-4bit/resolve/main/config.json
Retrying in 1s [Retry 1/5].
[huggingface_hub.utils._http|WARNING]Retrying in 1s [Retry 1/5].
                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [35:21<00:00,  4.31s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [35:21<00:00,  5.94s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–â–
wandb:            eval/runtime â–†â–â–ˆ
wandb: eval/samples_per_second â–â–ˆâ–
wandb:   eval/steps_per_second â–â–â–
wandb:             train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/learning_rate â–ƒâ–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:              train/loss â–ˆâ–†â–„â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.0002
wandb:            eval/runtime 36.7147
wandb: eval/samples_per_second 2.724
wandb:   eval/steps_per_second 0.681
wandb:              total_flos 7.127275269390336e+17
wandb:             train/epoch 3
wandb:       train/global_step 357
wandb:         train/grad_norm 0.00778
wandb:     train/learning_rate 0.0
wandb:              train/loss 0.0002
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_pddl3 at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/0x0mrnr1
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251031_002830-0x0mrnr1/logs
{'eval_loss': 0.00019805201736744493, 'eval_runtime': 36.7147, 'eval_samples_per_second': 2.724, 'eval_steps_per_second': 0.681, 'epoch': 3.0}

==================================================
Testing model performance...
==================================================
Generated solution:
commentaryWe have a domain and a problem. We need to produce a grounded plan that satisfies the goal conditions as listed in the problem, plus satisfiy the constraint: 
```
(sometime-before (at rover0 waypoint3) (at rover0 waypoint9))
```

Thus the plan must include an action that puts rover0 at waypoint3, and later an action that puts rover0 at waypoint9, in that order. The goal conditions are:

```
(communicated_soil_data waypoint4)
(communicated_soil_data waypoint11)
(communicated_image_data objective3 colour)
(communicated_image_data objective1 low_res)
```

We must produce a plan that ends with rover0 at waypoint9, with communications to soil sample at waypoint4, soil sample at waypoint11, image from objective3 with colour channel, image from objective1 low_res channel.

We must have actions: sample_soil, sample_rock, drop, calibrate, take_image, communicate_soil_data, communicate_rock_data, communicate_image_data. Additionally, navigate actions to move between waypoints, given can_traverse relationships.

We need to check initial state: 
```
(visible waypoint0 waypoint8)
(visible waypoint8 waypoint0)
...
```
So each pair of waypoints that can traverse; visible_from for objectives; store_of rover0store rover0; empty rover0store; equipped_for_soil_analysis rover0; equipped_for_imaging rover0; on_board camera0 rover0; calibration_target camera0 objective2; supports camera0 colour; supports camera0 low_res;
on_board camera1 rover0; calibration_target camera1 objective3; supports camera1 high_res; supports camera1 low_res;
on_board camera2 rover0; calibration_target camera2 objective3; supports camera2 colour;

At_soil_sample waypoint4; at_soil_sample waypoint11; both of them also at_rock_sample waypoint1, waypoint2, waypoint3, waypoint5, waypoint7, waypoint10. At_rock_sample for many waypoints.

At waypoint0 to waypoint8: visible and can_traverse relationships.

We have 
(channel_free general)
(at_lander general waypoint0)
(at rover0 waypoint1)
(available rover0)
(store_of rover0store rover0)
(empty rover0store)
(equipped_for_soil_analysis rover0)
(equipped_for_imaging rover0)
(can_traverse rover0 waypoint1 waypoint3)
(can_traverse rover0 waypoint3 waypoint1)
==================================================
{'train_runtime': 2121.4482, 'train_samples_per_second': 2.687, 'train_steps_per_second': 0.168, 'train_loss': 0.29953986212463807, 'epoch': 3.0}

Saving model to sft_models/gpt_oss_20b/rovers/pddl3 ...
Training completed!

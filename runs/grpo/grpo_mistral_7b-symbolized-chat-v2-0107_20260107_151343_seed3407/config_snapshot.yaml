base_model: /jfan5/sft_models/mistral_7b/symbolized_v2
batch_size: 4
beta: 0.01
class_label_field: class_label
dataloader_num_workers: 0
dataset: /jfan5/grpo_data/pddl3_symbolized_four_scenarios-v3/train_combined.jsonl
goal_fallback: -0.5
goal_no_info_fallback: -0.8
goal_not_satisfied_base: -0.8
goal_not_satisfied_scale: 0.6
gradient_accumulation_steps: 4
learning_rate: 1.0e-05
logging_steps: 20
max_grad_norm: 1.0
max_new_tokens: 256
max_prompt_length: 4096
max_steps: 1000
no_4bit: false
no_chat_template: false
no_run_tracking: false
no_wandb: false
num_epochs: 1.0
num_generations: 8
output_dir: /jfan5/grpo_models/mistral_7b-symbolized-chat-v2-0107-1000
prompt_field: prompt
response_field: response
run_name: grpo_mistral_7b-symbolized-chat-v2-0107
runs_root: ./runs
save_steps: 60
seed: 3407
temperature: 0.6
top_k: 50
top_p: 0.9
use_default_reward: false
use_gradient_checkpointing: false
wandb_project: pddl-grpo-mistral7b

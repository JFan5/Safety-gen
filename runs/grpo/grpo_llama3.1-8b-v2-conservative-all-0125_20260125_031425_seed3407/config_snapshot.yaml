base_model: /jfan5/sft_models/llama31_8b/symbolized
batch_size: 8
beta: 0.02
data_root: /jfan5/grpo_data/five_domain_0109/
domains: null
gradient_accumulation_steps: 4
learning_rate: 1.0e-05
logging_steps: 20
max_grad_norm: 1.0
max_new_tokens: 512
max_prompt_length: 1576
max_steps: 1000
no_4bit: false
no_run_tracking: false
no_wandb: false
num_generations: 8
output_dir: /jfan5/grpo_models/llama3.1-8b-v2-conservative-all-0125
run_name: grpo_llama3.1-8b-v2-conservative-all-0125
runs_root: ./runs
save_steps: 100
seed: 3407
temperature: 0.6
top_k: 50
top_p: 0.9
use_gradient_checkpointing: false
wandb_project: pddl-grpo-llama31-8b

base_model: /jfan5/sft_models/llama31_8b/symbolized
batch_size: 4
beta: 0.01
class_label_field: class_label
dataloader_num_workers: 0
dataset: /jfan5/grpo_data/pddl3_symbolized_four_scenarios-v3/train_combined.jsonl
gradient_accumulation_steps: 4
learning_rate: 1.0e-05
logging_steps: 20
max_grad_norm: 1.0
max_new_tokens: 256
max_prompt_length: 4096
max_steps: 1000
no_4bit: false
no_chat_template: false
no_run_tracking: false
no_wandb: false
num_epochs: 1.0
num_generations: 8
output_dir: /jfan5/grpo_models/llama31_8b-symbolized-chat-0106-1000
prompt_field: prompt
response_field: response
run_name: grpo_llama31_8b-symbolized-chat-0106
runs_root: ./runs
save_steps: 60
seed: 3407
temperature: 0.6
top_k: 50
top_p: 0.9
use_gradient_checkpointing: false
wandb_project: pddl-grpo-llama31-8b

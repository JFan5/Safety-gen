{
  "run_id": "20251208_031230_proj-pddl-dpo-mistral7b_method-dpo_base-four_scenarios500-1124_ds-dpo_data-1206_all_scenarios_merged.jsonl_seed-3407_m2tojt8s",
  "project": "pddl-dpo-mistral7b",
  "wandb": {
    "entity": "fjl2401-university-of-notre-dame",
    "project": "pddl-dpo-mistral7b",
    "run_id": "m2tojt8s",
    "run_name": "dpo_mistral_7b-1207",
    "url": "https://wandb.ai/fjl2401-university-of-notre-dame/pddl-dpo-mistral7b/runs/m2tojt8s",
    "group": "",
    "tags": []
  },
  "state": "finished",
  "method": "dpo",
  "base_model": "/jfan5/sft_models/mistral_7b/four_scenarios500-1124",
  "dataset": {
    "dataset_id": "unknown",
    "dataset_path": "/jfan5/dpo_data-1206/all_scenarios_merged.jsonl",
    "dataset_artifact": "unknown",
    "status": "confirmed"
  },
  "train": {
    "seed": 3407,
    "lr": 1e-06,
    "batch_size": 4,
    "epochs": 1,
    "max_steps": -1,
    "other_hparams": {
      "warmup_steps": 0,
      "warmup_ratio": 0.1,
      "weight_decay": 0.01,
      "gradient_accumulation_steps": 8,
      "max_grad_norm": 1,
      "adam_epsilon": 1e-08,
      "adam_beta1": 0.9,
      "adam_beta2": 0.999,
      "lr_scheduler_type": "linear",
      "fp16": false,
      "bf16": true,
      "gradient_checkpointing": true,
      "lora_r": 16,
      "lora_alpha": 32,
      "lora_dropout": 0.05
    }
  },
  "code": {
    "git_commit": "4cb49c0cd87c4b2038e8970d0e9710a5289f4756"
  },
  "created_at": "2025-12-08T03:12:30+00:00",
  "updated_at": null,
  "artifacts": {
    "model_path": "/jfan5/dpo_models/mistral_7b-1207",
    "model_path_status": "confirmed"
  }
}
\section{Conclusion}\label{VI}
We presented a two-stage post-training framework that combines SFT with GRPO to enable LLMs to perform safety-aware task planning for robotic systems.
By injecting verifiable safety knowledge through online RL with fine-grained reward machines, our approach achieves high planning success rates with minimal safety violations, and generalizes to unseen problems across a set of training domains.
Since our experiments use quantized lightweight models and a moderately sized dataset, the reported performance is likely conservative.
Future work includes scaling to more complex robotic settings, integrating richer formal verification tools, and exploring automatic construction of safety constraints from interaction data.
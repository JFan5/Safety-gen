\section{Related Work}\label{sec:related}
This section introduces the related work on classical task planning, AI-based planners, and LLM-based planning.

\subsection{Classical Task Planning}

Classical task planning is a mature area in automated reasoning, with planners such as
Fast Downward \cite{helmert2006fast} and Metric-FF \cite{hoffmann2001ff}
solving symbolic planning problems by heuristic search over PDDL models.
Extensions including Hierarchical Task Networks (HTN) \cite{nau2005applications} and other model-based planners \cite{geffner2013concise} improve scalability through structural decomposition and domain-specific abstractions.

Despite their success, classical planners exhibit several well-recognized limitations. They rely heavily on expert-designed domain models and heuristic functions \cite{geffner2013concise}, making the modeling pipeline labor-intensive and brittle to environmental variations \cite{ghallab2004automated}. Moreover, their assumptions of fully known, deterministic, and discrete environments limit adaptability in realistic CPS settings \cite{nau2005applications}. These constraints motivate the shift toward more flexible,
data-driven planning paradigms.


\subsection{AI-based Planners}
To address the rigidity of classical planners, a broad line of AI-based and learning-driven
approaches has emerged. Early work focuses on learning heuristics or search guidance
from data, such as Learn2Plan and Hierarchical Goal Networks (HGN), enabling planners
to approximate expert reasoning without manually crafted heuristics.
Reinforcement learning (RL) methods have also been used to derive task policies from
interaction data; however, RL alone struggles with long-horizon symbolic structure,
state explosion, and generalization to novel goals \cite{Shivadekar2025CognitiveAI, Wu2025HumanAI}.

Neuro-symbolic planning frameworks attempt to combine symbolic reasoning with neural
representations to improve interpretability and robustness \cite{Fabiano2023PlanSOFAI,
Muniyandy2025NSRL}. While these methods enhance adaptability, they remain largely
domain-specific and do not provide the formal safety guarantees required in
safety-critical CPS applications \cite{Bandi2025RiseOfAgenticAI, Moon2019PDDL,
Sanyal2025KnowledgeDriven}. Hybrid approaches that integrate model-based assurances
with learned components \cite{Lyu2022TrustworthyAI} improve reliability but still depend
on domain-specific engineering.

Overall, despite substantial progress, existing AI-based planners do not achieve
the joint requirements of (i) strong generalization across tasks and domains and
(ii) verifiable adherence to formal safety constraints—two properties that are essential
for CPS deployment.


\subsection{LLM-based Planning}
Recent work explores the use of LLMs for robotic and task
planning by translating natural language into formal specifications or high-level
symbolic plans. Yang \textit{et al.}\ \cite{yang2022automaton} extract automaton-based
task structures from LLM outputs to enable downstream planning, while Pan \textit{et al.}\
\cite{pan2023data} and van de Laar \textit{et al.}\ \cite{van2024vernacopter} translate
instructions into LTL or STL specifications that can be consumed by symbolic planners.
Other works use frozen LLMs for direct PDDL plan generation via prompting
\cite{silver2024generalized}, demonstrating cross-domain generalization without
task-specific training.

Safety-aware planning with LLMs has also gained attention. Obi \textit{et al.}\
\cite{obi2025safeplan} propose a reasoning pipeline combining formal logic with
chain-of-thought prompting to detect unsafe plans, and Yin \textit{et al.}\
\cite{yin2024safeagentbench} introduce a benchmark evaluating LLM agents
under explicit and implicit hazard scenarios. Yang \textit{et al.}\ \cite{yang2024fine}
fine-tune LLMs using automated formal-methods feedback to improve safety in autonomous systems.

However, existing LLM-based planners typically operate in a zero- or few-shot setting with frozen models, limiting their ability to internalize safety reasoning or generalize safety constraints across domains. Most methods rely on external
rule-based validators, rather than embedding safety awareness into the model itself. Moreover, prior fine-tuning approaches remain restricted to single-domain settings and do not address safety generalization to unseen tasks or domains.

This motivates the need for an LLM-based planner that (i) learns safety-aware
planning behavior intrinsically through supervised and preference-based
optimization, and (ii) generalizes safety constraints across both tasks and domains—
which is the objective of the proposed Safe-Gen LLM framework.


CondaError: Run 'conda init' before 'conda activate'

[torchao|WARNING]Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA A100 80GB PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.10.12: Fast Gpt_Oss patching. Transformers: 4.56.2.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.01s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.12s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.46it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.22it/s]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from data/sft/grid/pddl2.hf...
Loading HuggingFace dataset...
Dataset loaded with 2000 entries
Scenario distribution:
  grid: 2000

Filtering scenarios to: ['grid']
Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<00:00, 32405.96 examples/s]
Filtered dataset size: 2000
Processing dataset format (chat template)...
Map:   0%|          | 0/1900 [00:00<?, ? examples/s]Map:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 631/1900 [00:00<00:00, 6263.98 examples/s]Map:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1428/1900 [00:00<00:00, 5579.57 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:00<00:00, 5581.08 examples/s]
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 5302.00 examples/s]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251031_035209-gt8mghhi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_pddl2
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/gt8mghhi
wandb: Detected [huggingface_hub.inference] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Testing initial model performance...
Initial model output:
analysisWe need to parse domain and problem. The goal: at key0 pos0-0.

Initial: key0 at pos1-3. key1 at pos3-3, key2 at pos3-1. Robot at pos2-2. Locked nodes: pos2-0, pos2-1, pos0-3. Others open.

We have actions: unlock, move, pickup, pickup-and-loose, putdown.

We need to move key0 to pos0-0. Path? robot starts pos2-2; open; lock positions locked only to lock positions: pos2-0, pos2-1, pos0-3. We have lock-shape mapping. Not relevant.

Key0 at pos1-3. We need to carry to pos0-0. Path from 1-3...

Resolved training arguments:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-05
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 2048
  load_in_4bit: True

Creating trainer...
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/1900 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   3%|â–Ž         | 60/1900 [00:02<01:09, 26.43 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   9%|â–‰         | 180/1900 [00:02<00:20, 85.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  13%|â–ˆâ–Ž        | 240/1900 [00:02<00:15, 104.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 300/1900 [00:03<00:11, 137.47 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 360/1900 [00:03<00:09, 157.44 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 480/1900 [00:03<00:06, 232.60 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 600/1900 [00:03<00:04, 314.31 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 660/1900 [00:04<00:04, 290.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 779/1900 [00:04<00:03, 340.38 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 838/1900 [00:04<00:03, 303.23 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 897/1900 [00:04<00:04, 233.74 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1015/1900 [00:05<00:03, 229.98 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1074/1900 [00:05<00:03, 238.48 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1192/1900 [00:06<00:03, 233.35 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1310/1900 [00:06<00:02, 276.22 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1428/1900 [00:07<00:01, 267.55 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1546/1900 [00:07<00:01, 263.67 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1664/1900 [00:07<00:00, 300.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1723/1900 [00:07<00:00, 300.97 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 1782/1900 [00:08<00:00, 280.41 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1841/1900 [00:08<00:00, 311.20 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:08<00:00, 282.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:08<00:00, 211.42 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   4%|â–         | 4/100 [00:02<00:51,  1.87 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   8%|â–Š         | 8/100 [00:02<00:23,  3.88 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  12%|â–ˆâ–        | 12/100 [00:02<00:14,  5.97 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 16/100 [00:02<00:10,  8.30 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 19/100 [00:03<00:08,  9.52 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 22/100 [00:03<00:07, 11.07 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:03<00:05, 12.58 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 28/100 [00:03<00:05, 13.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:03<00:05, 11.89 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:04<00:04, 13.34 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:04<00:04, 14.59 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:04<00:03, 15.37 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:04<00:03, 16.55 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:04<00:03, 16.53 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:04<00:02, 17.58 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 52/100 [00:05<00:03, 13.98 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:05<00:02, 19.18 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:05<00:02, 15.35 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:05<00:02, 16.08 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:06<00:01, 20.76 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:06<00:01, 20.22 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 79/100 [00:06<00:01, 19.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:06<00:01, 15.66 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:06<00:00, 20.55 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 91/100 [00:07<00:00, 18.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:07<00:00, 22.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00, 22.94 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:07<00:00, 12.72 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,900 | Num Epochs = 3 | Total steps = 357
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)

Starting training...
  0%|          | 0/357 [00:00<?, ?it/s]  0%|          | 1/357 [00:14<1:27:24, 14.73s/it]  1%|          | 2/357 [00:21<59:23, 10.04s/it]    1%|          | 3/357 [00:28<50:21,  8.54s/it]  1%|          | 4/357 [00:34<45:59,  7.82s/it]  1%|â–         | 5/357 [00:41<43:31,  7.42s/it]  2%|â–         | 6/357 [00:48<41:59,  7.18s/it]  2%|â–         | 7/357 [00:55<41:00,  7.03s/it]  2%|â–         | 8/357 [01:01<40:19,  6.93s/it]  3%|â–Ž         | 9/357 [01:08<39:50,  6.87s/it]  3%|â–Ž         | 10/357 [01:15<39:29,  6.83s/it]                                                  3%|â–Ž         | 10/357 [01:15<39:29,  6.83s/it]  3%|â–Ž         | 11/357 [01:22<39:13,  6.80s/it]  3%|â–Ž         | 12/357 [01:28<39:01,  6.79s/it]  4%|â–Ž         | 13/357 [01:35<38:49,  6.77s/it]  4%|â–         | 14/357 [01:42<38:40,  6.77s/it]  4%|â–         | 15/357 [01:49<38:31,  6.76s/it]  4%|â–         | 16/357 [01:55<38:22,  6.75s/it]  5%|â–         | 17/357 [02:02<38:14,  6.75s/it]  5%|â–Œ         | 18/357 [02:09<38:05,  6.74s/it]  5%|â–Œ         | 19/357 [02:15<37:59,  6.74s/it]  6%|â–Œ         | 20/357 [02:22<37:51,  6.74s/it]                                                  6%|â–Œ         | 20/357 [02:22<37:51,  6.74s/it]  6%|â–Œ         | 21/357 [02:29<37:44,  6.74s/it]  6%|â–Œ         | 22/357 [02:36<37:37,  6.74s/it]  6%|â–‹         | 23/357 [02:42<37:29,  6.73s/it]  7%|â–‹         | 24/357 [02:49<37:20,  6.73s/it]  7%|â–‹         | 25/357 [02:56<37:13,  6.73s/it]  7%|â–‹         | 26/357 [03:03<37:06,  6.73s/it]  8%|â–Š         | 27/357 [03:09<36:58,  6.72s/it]  8%|â–Š         | 28/357 [03:16<36:52,  6.72s/it]  8%|â–Š         | 29/357 [03:23<36:44,  6.72s/it]  8%|â–Š         | 30/357 [03:29<36:36,  6.72s/it]                                                  8%|â–Š         | 30/357 [03:29<36:36,  6.72s/it]  9%|â–Š         | 31/357 [03:36<36:29,  6.72s/it]  9%|â–‰         | 32/357 [03:43<36:24,  6.72s/it]  9%|â–‰         | 33/357 [03:50<36:19,  6.73s/it] 10%|â–‰         | 34/357 [03:57<36:59,  6.87s/it] 10%|â–‰         | 35/357 [04:04<36:42,  6.84s/it] 10%|â–ˆ         | 36/357 [04:10<36:30,  6.82s/it] 10%|â–ˆ         | 37/357 [04:17<36:21,  6.82s/it] 11%|â–ˆ         | 38/357 [04:24<36:11,  6.81s/it] 11%|â–ˆ         | 39/357 [04:31<36:02,  6.80s/it] 11%|â–ˆ         | 40/357 [04:38<35:52,  6.79s/it]                                                 11%|â–ˆ         | 40/357 [04:38<35:52,  6.79s/it] 11%|â–ˆâ–        | 41/357 [04:44<35:45,  6.79s/it] 12%|â–ˆâ–        | 42/357 [04:51<35:37,  6.79s/it] 12%|â–ˆâ–        | 43/357 [04:58<35:30,  6.78s/it] 12%|â–ˆâ–        | 44/357 [05:05<35:22,  6.78s/it] 13%|â–ˆâ–Ž        | 45/357 [05:11<35:14,  6.78s/it] 13%|â–ˆâ–Ž        | 46/357 [05:18<35:07,  6.78s/it] 13%|â–ˆâ–Ž        | 47/357 [05:25<35:01,  6.78s/it] 13%|â–ˆâ–Ž        | 48/357 [05:32<34:56,  6.79s/it] 14%|â–ˆâ–Ž        | 49/357 [05:39<34:50,  6.79s/it] 14%|â–ˆâ–        | 50/357 [05:45<34:42,  6.78s/it]                                                 14%|â–ˆâ–        | 50/357 [05:45<34:42,  6.78s/it] 14%|â–ˆâ–        | 51/357 [05:52<34:34,  6.78s/it] 15%|â–ˆâ–        | 52/357 [05:59<34:27,  6.78s/it] 15%|â–ˆâ–        | 53/357 [06:06<34:19,  6.77s/it] 15%|â–ˆâ–Œ        | 54/357 [06:12<34:13,  6.78s/it] 15%|â–ˆâ–Œ        | 55/357 [06:19<34:05,  6.77s/it] 16%|â–ˆâ–Œ        | 56/357 [06:26<33:59,  6.78s/it] 16%|â–ˆâ–Œ        | 57/357 [06:33<33:51,  6.77s/it] 16%|â–ˆâ–Œ        | 58/357 [06:39<33:43,  6.77s/it] 17%|â–ˆâ–‹        | 59/357 [06:46<33:39,  6.78s/it] 17%|â–ˆâ–‹        | 60/357 [06:53<33:32,  6.78s/it]                                                 17%|â–ˆâ–‹        | 60/357 [06:53<33:32,  6.78s/it] 17%|â–ˆâ–‹        | 61/357 [07:00<33:26,  6.78s/it] 17%|â–ˆâ–‹        | 62/357 [07:07<33:19,  6.78s/it] 18%|â–ˆâ–Š        | 63/357 [07:13<33:12,  6.78s/it] 18%|â–ˆâ–Š        | 64/357 [07:20<33:05,  6.78s/it] 18%|â–ˆâ–Š        | 65/357 [07:27<32:58,  6.78s/it] 18%|â–ˆâ–Š        | 66/357 [07:34<32:52,  6.78s/it] 19%|â–ˆâ–‰        | 67/357 [07:41<33:23,  6.91s/it] 19%|â–ˆâ–‰        | 68/357 [07:48<33:06,  6.87s/it] 19%|â–ˆâ–‰        | 69/357 [07:55<32:52,  6.85s/it] 20%|â–ˆâ–‰        | 70/357 [08:01<32:40,  6.83s/it]                                                 20%|â–ˆâ–‰        | 70/357 [08:01<32:40,  6.83s/it] 20%|â–ˆâ–‰        | 71/357 [08:08<32:29,  6.82s/it] 20%|â–ˆâ–ˆ        | 72/357 [08:15<32:19,  6.80s/it] 20%|â–ˆâ–ˆ        | 73/357 [08:22<32:09,  6.79s/it] 21%|â–ˆâ–ˆ        | 74/357 [08:28<32:01,  6.79s/it] 21%|â–ˆâ–ˆ        | 75/357 [08:35<31:53,  6.79s/it] 21%|â–ˆâ–ˆâ–       | 76/357 [08:42<31:47,  6.79s/it] 22%|â–ˆâ–ˆâ–       | 77/357 [08:49<31:39,  6.78s/it] 22%|â–ˆâ–ˆâ–       | 78/357 [08:56<31:33,  6.79s/it] 22%|â–ˆâ–ˆâ–       | 79/357 [09:02<31:26,  6.79s/it] 22%|â–ˆâ–ˆâ–       | 80/357 [09:09<31:19,  6.78s/it]                                                 22%|â–ˆâ–ˆâ–       | 80/357 [09:09<31:19,  6.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 81/357 [09:16<31:11,  6.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/357 [09:23<31:05,  6.78s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/357 [09:29<30:58,  6.78s/it] 24%|â–ˆâ–ˆâ–Ž       | 84/357 [09:36<30:51,  6.78s/it] 24%|â–ˆâ–ˆâ–       | 85/357 [09:43<30:45,  6.78s/it] 24%|â–ˆâ–ˆâ–       | 86/357 [09:50<30:38,  6.78s/it] 24%|â–ˆâ–ˆâ–       | 87/357 [09:57<30:31,  6.78s/it] 25%|â–ˆâ–ˆâ–       | 88/357 [10:03<30:24,  6.78s/it] 25%|â–ˆâ–ˆâ–       | 89/357 [10:10<30:16,  6.78s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:17<30:11,  6.78s/it]                                                 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:17<30:11,  6.78s/it] 25%|â–ˆâ–ˆâ–Œ       | 91/357 [10:24<30:04,  6.78s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/357 [10:31<29:57,  6.78s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/357 [10:37<29:51,  6.79s/it] 26%|â–ˆâ–ˆâ–‹       | 94/357 [10:44<29:44,  6.79s/it] 27%|â–ˆâ–ˆâ–‹       | 95/357 [10:51<29:38,  6.79s/it] 27%|â–ˆâ–ˆâ–‹       | 96/357 [10:58<29:31,  6.79s/it] 27%|â–ˆâ–ˆâ–‹       | 97/357 [11:04<29:25,  6.79s/it] 27%|â–ˆâ–ˆâ–‹       | 98/357 [11:11<29:19,  6.79s/it] 28%|â–ˆâ–ˆâ–Š       | 99/357 [11:18<29:13,  6.80s/it] 28%|â–ˆâ–ˆâ–Š       | 100/357 [11:25<29:06,  6.80s/it]                                                  28%|â–ˆâ–ˆâ–Š       | 100/357 [11:25<29:06,  6.80s/it] 28%|â–ˆâ–ˆâ–Š       | 101/357 [11:32<29:33,  6.93s/it] 29%|â–ˆâ–ˆâ–Š       | 102/357 [11:39<29:17,  6.89s/it] 29%|â–ˆâ–ˆâ–‰       | 103/357 [11:46<29:04,  6.87s/it] 29%|â–ˆâ–ˆâ–‰       | 104/357 [11:53<28:52,  6.85s/it] 29%|â–ˆâ–ˆâ–‰       | 105/357 [11:59<28:41,  6.83s/it] 30%|â–ˆâ–ˆâ–‰       | 106/357 [12:06<28:32,  6.82s/it] 30%|â–ˆâ–ˆâ–‰       | 107/357 [12:13<28:24,  6.82s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/357 [12:20<28:15,  6.81s/it] 31%|â–ˆâ–ˆâ–ˆ       | 109/357 [12:27<28:09,  6.81s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:33<28:01,  6.81s/it]                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:33<28:01,  6.81s/it] 31%|â–ˆâ–ˆâ–ˆ       | 111/357 [12:40<27:54,  6.81s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 112/357 [12:47<27:47,  6.81s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 113/357 [12:54<27:40,  6.80s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 114/357 [13:01<27:33,  6.80s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 115/357 [13:07<27:25,  6.80s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 116/357 [13:14<27:18,  6.80s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/357 [13:21<27:12,  6.80s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/357 [13:28<27:06,  6.80s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [13:33<24:57,  6.29s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.9391, 'grad_norm': 75.32801055908203, 'learning_rate': 5e-06, 'epoch': 0.08}
{'loss': 2.7921, 'grad_norm': 36.03852462768555, 'learning_rate': 1.0555555555555557e-05, 'epoch': 0.17}
{'loss': 1.2545, 'grad_norm': 3.000701427459717, 'learning_rate': 1.6111111111111115e-05, 'epoch': 0.25}
{'loss': 0.7847, 'grad_norm': 1.4931875467300415, 'learning_rate': 1.9995690062269985e-05, 'epoch': 0.34}
{'loss': 0.5927, 'grad_norm': 1.3589342832565308, 'learning_rate': 1.9919172253651637e-05, 'epoch': 0.42}
{'loss': 0.4112, 'grad_norm': 1.594480037689209, 'learning_rate': 1.974772117649135e-05, 'epoch': 0.51}
{'loss': 0.2341, 'grad_norm': 1.3529236316680908, 'learning_rate': 1.9482977734962753e-05, 'epoch': 0.59}
{'loss': 0.0904, 'grad_norm': 1.196447730064392, 'learning_rate': 1.9127475705028864e-05, 'epoch': 0.67}
{'loss': 0.0255, 'grad_norm': 0.7413185834884644, 'learning_rate': 1.8684617484471662e-05, 'epoch': 0.76}
{'loss': 0.0143, 'grad_norm': 0.3404375910758972, 'learning_rate': 1.815864152961624e-05, 'epoch': 0.84}
{'loss': 0.0108, 'grad_norm': 0.371368944644928, 'learning_rate': 1.7554581790402372e-05, 'epoch': 0.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:13,  1.66it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:20,  1.06it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:23,  1.12s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.28s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:25,  1.33s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:24,  1.35s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:09<00:23,  1.37s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.44s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:12<00:21,  1.43s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:19,  1.43s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:15<00:18,  1.42s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:18<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:21<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:24<00:10,  1.47s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:25<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:31<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:34<00:00,  1.49s/it][A                                                 
                                               [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [14:10<24:57,  6.29s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:46<1:44:16, 26.40s/it]                                                    34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:46<1:44:16, 26.40s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 121/357 [14:51<1:18:38, 20.00s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 122/357 [14:56<1:00:11, 15.37s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 123/357 [15:00<47:18, 12.13s/it]   35%|â–ˆâ–ˆâ–ˆâ–      | 124/357 [15:05<38:18,  9.86s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/357 [15:10<32:26,  8.39s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/357 [15:14<27:53,  7.25s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 127/357 [15:19<24:42,  6.45s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 128/357 [15:24<22:27,  5.89s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 129/357 [15:28<20:53,  5.50s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:33<20:16,  5.36s/it]                                                  36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:33<20:16,  5.36s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/357 [15:38<19:17,  5.12s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 132/357 [15:42<18:35,  4.96s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 133/357 [15:47<18:03,  4.84s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 134/357 [15:52<18:07,  4.88s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 135/357 [15:57<17:42,  4.78s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 136/357 [16:01<17:23,  4.72s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 137/357 [16:06<17:08,  4.68s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 138/357 [16:10<16:58,  4.65s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 139/357 [16:15<17:18,  4.76s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [16:20<17:01,  4.71s/it]                                                  39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [16:20<17:01,  4.71s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 141/357 [16:24<16:49,  4.67s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 142/357 [16:29<16:37,  4.64s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/357 [16:34<16:28,  4.62s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/357 [16:39<16:45,  4.72s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 145/357 [16:43<16:31,  4.68s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 146/357 [16:48<16:20,  4.65s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 147/357 [16:52<16:10,  4.62s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/357 [16:57<16:27,  4.72s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/357 [17:02<16:13,  4.68s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [17:06<16:02,  4.65s/it]                                                  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [17:06<16:02,  4.65s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 151/357 [17:11<15:54,  4.63s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 152/357 [17:16<15:46,  4.62s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/357 [17:21<16:06,  4.74s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 154/357 [17:25<15:52,  4.69s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 155/357 [17:30<15:40,  4.66s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 156/357 [17:34<15:30,  4.63s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/357 [17:39<15:45,  4.73s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/357 [17:44<15:31,  4.68s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/357 [17:48<15:20,  4.65s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:53<15:11,  4.63s/it]                                                  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:53<15:11,  4.63s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 161/357 [17:58<15:03,  4.61s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 162/357 [18:03<15:19,  4.72s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 163/357 [18:07<15:06,  4.67s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 164/357 [18:12<14:56,  4.64s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 165/357 [18:16<14:47,  4.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 166/357 [18:21<14:41,  4.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 167/357 [18:26<15:00,  4.74s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 168/357 [18:30<14:46,  4.69s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 169/357 [18:35<14:34,  4.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:40<14:26,  4.64s/it]                                                  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:40<14:26,  4.64s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 171/357 [18:44<14:19,  4.62s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 172/357 [18:49<14:33,  4.72s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 173/357 [18:54<14:21,  4.68s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 174/357 [18:58<14:10,  4.65s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 175/357 [19:03<14:01,  4.63s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 176/357 [19:08<14:15,  4.73s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 177/357 [19:12<14:02,  4.68s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 178/357 [19:17<13:52,  4.65s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 179/357 [19:22<13:43,  4.63s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [19:26<13:36,  4.61s/it]                                                  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [19:26<13:36,  4.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 181/357 [19:31<13:50,  4.72s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 182/357 [19:36<13:38,  4.68s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/357 [19:40<13:28,  4.65s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 184/357 [19:45<13:20,  4.62s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 185/357 [19:49<13:12,  4.61s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 186/357 [19:54<13:28,  4.73s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 187/357 [19:59<13:17,  4.69s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 188/357 [20:04<13:06,  4.65s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 189/357 [20:08<12:57,  4.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [20:13<12:51,  4.62s/it]                                                  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [20:13<12:51,  4.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 191/357 [20:18<13:05,  4.73s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 192/357 [20:22<12:52,  4.68s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 193/357 [20:27<12:42,  4.65s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 194/357 [20:31<12:34,  4.63s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/357 [20:36<12:45,  4.73s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 196/357 [20:41<12:33,  4.68s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 197/357 [20:46<12:23,  4.65s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 198/357 [20:50<12:16,  4.63s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 199/357 [20:55<12:09,  4.61s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [21:00<12:21,  4.72s/it]                                                  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [21:00<12:21,  4.72s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 201/357 [21:04<12:09,  4.68s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 202/357 [21:09<12:00,  4.65s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 203/357 [21:13<11:52,  4.63s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 204/357 [21:18<12:03,  4.73s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 205/357 [21:23<11:52,  4.68s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 206/357 [21:28<11:42,  4.65s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 207/357 [21:32<11:35,  4.64s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 208/357 [21:37<11:28,  4.62s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 209/357 [21:42<11:42,  4.75s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:46<11:30,  4.70s/it]                                                  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:46<11:30,  4.70s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 211/357 [21:51<11:20,  4.66s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 212/357 [21:56<11:13,  4.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 213/357 [22:00<11:05,  4.62s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 214/357 [22:05<11:16,  4.73s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 215/357 [22:10<11:04,  4.68s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 216/357 [22:14<10:56,  4.65s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 217/357 [22:19<10:48,  4.63s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 218/357 [22:23<10:41,  4.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 219/357 [22:28<10:51,  4.72s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:33<10:40,  4.68s/it]                                                  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:33<10:40,  4.68s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 221/357 [22:38<10:31,  4.65s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 222/357 [22:42<10:24,  4.62s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 223/357 [22:47<10:33,  4.73s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 224/357 [22:52<10:22,  4.68s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 225/357 [22:56<10:13,  4.65s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 226/357 [23:01<10:06,  4.63s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 227/357 [23:05<09:59,  4.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 228/357 [23:10<10:08,  4.72s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 229/357 [23:15<09:58,  4.68s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [23:19<09:50,  4.65s/it]                                                  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [23:19<09:50,  4.65s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/357 [23:24<09:43,  4.63s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/357 [23:29<09:36,  4.61s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 233/357 [23:34<09:47,  4.74s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 234/357 [23:38<09:36,  4.69s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 235/357 [23:43<09:27,  4.65s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 236/357 [23:47<09:20,  4.63s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 237/357 [23:52<09:27,  4.73s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [23:56<08:36,  4.34s/it]{'eval_loss': 0.007092286366969347, 'eval_runtime': 36.7736, 'eval_samples_per_second': 2.719, 'eval_steps_per_second': 0.68, 'epoch': 1.0}

==================================================
Testing model performance...
==================================================
Generated solution:
analysisWe need to construct a valid, grounded, totally-ordered plan for the given grid domain and problem. The domain defines actions unlock, move, pickup, pickup-and-loose, putdown. The problem gives initial state, including locked places, key shapes, lock shapes, etc. The goal: (at key0 pos0-0).

We must produce a sequence of action instantiations such that after executing them from the initial state, the goal holds. Also, we must ensure all constraints (if any) are satisfied. The problem does not specify any explicit constraints. So it's a standard goal-directed planning problem without constraints.

Thus we need a valid plan that takes key0 from its initial location (at key0 pos1-3) to pos0-0 (the goal). Key shapes: key0 shape0. Locks: pos2-0 shape0 locked; pos2-1 shape1 locked; pos0-3 shape1 locked. Place pos0-0 shape0 open. Place pos0-1 shape0 open. Place pos0-2 shape1 open. Place pos0-3 shape1 locked. Place pos1-0 shape0 open. Place pos1-1 shape0 open. Place pos1-2 shape1 open. Place pos1-3 shape1 open. Place pos2-0 shape0 locked. Place pos2-1 shape1 locked. Place pos2-2 shape0 open. Place pos2-3 shape1 open. Place pos3-0 shape0 open. Place pos3-1 shape1 open. Place pos3-2 shape0 open. Place pos3-3 shape1 open.

All open places have shape0 or shape1, but open is open regardless shape, except locked ones cannot be entered unless unlocked, open if open. The robot is at pos2-2 initially. Key0 is at pos1-3. Key shapes: key1 shape1; key2 shape1.

Locks:  pos2-0 shape0 locked; pos2-1 shape1 locked; pos0-3 shape1 locked.

We need to get key0 to pos0-0. But key0 shape0. Where can we get it? It sits at pos1-3. The robot starts at pos2-2. We must pickup key0 at pos1-3. So robot must move to pos1-3. Then pickup key0. Then unlock something to reach pos0-0. Or we could move key0
==================================================
{'loss': 0.0083, 'grad_norm': 0.26048991084098816, 'learning_rate': 1.687821953203765e-05, 'epoch': 1.01}
{'loss': 0.0065, 'grad_norm': 0.17926065623760223, 'learning_rate': 1.613602800433194e-05, 'epoch': 1.09}
{'loss': 0.0046, 'grad_norm': 0.13587941229343414, 'learning_rate': 1.5335110488265497e-05, 'epoch': 1.18}
{'loss': 0.0029, 'grad_norm': 0.11696158349514008, 'learning_rate': 1.4483132312727501e-05, 'epoch': 1.26}
{'loss': 0.0023, 'grad_norm': 0.2034960389137268, 'learning_rate': 1.358824749207136e-05, 'epoch': 1.35}
{'loss': 0.0021, 'grad_norm': 0.1345299333333969, 'learning_rate': 1.2659020686615602e-05, 'epoch': 1.43}
{'loss': 0.002, 'grad_norm': 0.12985944747924805, 'learning_rate': 1.170434523298175e-05, 'epoch': 1.51}
{'loss': 0.002, 'grad_norm': 0.1521865427494049, 'learning_rate': 1.073335802877504e-05, 'epoch': 1.6}
{'loss': 0.0019, 'grad_norm': 0.12198992818593979, 'learning_rate': 9.755352086219733e-06, 'epoch': 1.68}
{'loss': 0.0019, 'grad_norm': 0.08611176162958145, 'learning_rate': 8.779687591670687e-06, 'epoch': 1.77}
{'loss': 0.0018, 'grad_norm': 0.08390655368566513, 'learning_rate': 7.815702322222539e-06, 'epoch': 1.85}
{'loss': 0.0017, 'grad_norm': 0.10654155164957047, 'learning_rate': 6.872622276790804e-06, 'epoch': 1.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:21,  1.00it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.41s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.47s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [24:33<08:36,  4.34s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 239/357 [25:09<49:21, 25.09s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [25:14<36:55, 18.94s/it]                                                  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [25:14<36:55, 18.94s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 241/357 [25:18<28:17, 14.63s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 242/357 [25:23<22:31, 11.75s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 243/357 [25:28<18:13,  9.60s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 244/357 [25:33<15:13,  8.09s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 245/357 [25:37<13:08,  7.04s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 246/357 [25:42<11:54,  6.44s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 247/357 [25:47<10:47,  5.88s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 248/357 [25:51<09:58,  5.49s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 249/357 [25:56<09:23,  5.21s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [26:01<08:56,  5.02s/it]                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [26:01<08:56,  5.02s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 251/357 [26:06<08:50,  5.00s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 252/357 [26:10<08:31,  4.87s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 253/357 [26:15<08:17,  4.78s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 254/357 [26:19<08:05,  4.72s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 255/357 [26:24<07:57,  4.68s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 256/357 [26:29<08:03,  4.79s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 257/357 [26:33<07:52,  4.72s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 258/357 [26:38<07:43,  4.68s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 259/357 [26:43<07:35,  4.65s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:47<07:28,  4.63s/it]                                                  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:47<07:28,  4.63s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 261/357 [26:52<07:34,  4.73s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 262/357 [26:57<07:24,  4.68s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 263/357 [27:01<07:16,  4.65s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 264/357 [27:06<07:10,  4.63s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 265/357 [27:11<07:14,  4.73s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 266/357 [27:15<07:06,  4.68s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 267/357 [27:20<06:58,  4.65s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 268/357 [27:25<06:51,  4.63s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 269/357 [27:29<06:45,  4.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [27:34<06:52,  4.74s/it]                                                  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [27:34<06:52,  4.74s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 271/357 [27:39<06:43,  4.69s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 272/357 [27:43<06:35,  4.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 273/357 [27:48<06:28,  4.63s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 274/357 [27:52<06:22,  4.61s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 275/357 [27:57<06:28,  4.73s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 276/357 [28:02<06:19,  4.68s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 277/357 [28:07<06:12,  4.65s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 278/357 [28:11<06:05,  4.63s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 279/357 [28:16<05:59,  4.61s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [28:21<06:03,  4.72s/it]                                                  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [28:21<06:03,  4.72s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 281/357 [28:25<05:55,  4.68s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 282/357 [28:30<05:48,  4.65s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 283/357 [28:34<05:42,  4.63s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 284/357 [28:39<05:46,  4.75s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 285/357 [28:44<05:38,  4.70s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 286/357 [28:49<05:31,  4.67s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 287/357 [28:53<05:24,  4.64s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 288/357 [28:58<05:18,  4.62s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 289/357 [29:03<05:21,  4.72s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [29:07<05:13,  4.68s/it]                                                  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [29:07<05:13,  4.68s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 291/357 [29:12<05:06,  4.64s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 292/357 [29:16<05:00,  4.62s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 293/357 [29:21<04:54,  4.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294/357 [29:26<04:56,  4.71s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 295/357 [29:31<04:49,  4.67s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 296/357 [29:35<04:42,  4.64s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 297/357 [29:40<04:37,  4.63s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 298/357 [29:44<04:32,  4.61s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 299/357 [29:49<04:33,  4.72s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:54<04:26,  4.67s/it]                                                  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:54<04:26,  4.67s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 301/357 [29:58<04:20,  4.65s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 302/357 [30:03<04:14,  4.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 303/357 [30:08<04:15,  4.74s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 304/357 [30:13<04:08,  4.69s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 305/357 [30:17<04:02,  4.66s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 306/357 [30:22<03:56,  4.63s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 307/357 [30:26<03:50,  4.61s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 308/357 [30:31<03:51,  4.72s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 309/357 [30:36<03:44,  4.68s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:40<03:38,  4.65s/it]                                                  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:40<03:38,  4.65s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 311/357 [30:45<03:32,  4.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 312/357 [30:50<03:27,  4.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 313/357 [30:55<03:27,  4.72s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 314/357 [30:59<03:21,  4.67s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 315/357 [31:04<03:15,  4.65s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 316/357 [31:08<03:09,  4.62s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 317/357 [31:13<03:04,  4.61s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 318/357 [31:18<03:04,  4.73s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 319/357 [31:22<02:57,  4.68s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [31:27<02:52,  4.66s/it]                                                  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [31:27<02:52,  4.66s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 321/357 [31:32<02:46,  4.64s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 322/357 [31:37<02:45,  4.74s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 323/357 [31:41<02:39,  4.69s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 324/357 [31:46<02:33,  4.66s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 325/357 [31:50<02:28,  4.63s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 326/357 [31:55<02:23,  4.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 327/357 [32:00<02:21,  4.72s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 328/357 [32:04<02:15,  4.68s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/357 [32:09<02:10,  4.65s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [32:14<02:04,  4.63s/it]                                                  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [32:14<02:04,  4.63s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 331/357 [32:18<01:59,  4.61s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 332/357 [32:23<01:57,  4.72s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 333/357 [32:28<01:52,  4.68s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 334/357 [32:32<01:46,  4.65s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 335/357 [32:37<01:41,  4.63s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 336/357 [32:41<01:36,  4.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 337/357 [32:46<01:34,  4.74s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 338/357 [32:51<01:29,  4.69s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 339/357 [32:56<01:23,  4.65s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [33:00<01:18,  4.63s/it]                                                  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [33:00<01:18,  4.63s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 341/357 [33:05<01:13,  4.61s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 342/357 [33:10<01:10,  4.73s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 343/357 [33:14<01:05,  4.68s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 344/357 [33:19<01:00,  4.65s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 345/357 [33:24<00:55,  4.63s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 346/357 [33:28<00:50,  4.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 347/357 [33:33<00:47,  4.72s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 348/357 [33:38<00:42,  4.68s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 349/357 [33:42<00:37,  4.65s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:47<00:32,  4.64s/it]                                                  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:47<00:32,  4.64s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 351/357 [33:52<00:28,  4.75s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 352/357 [33:56<00:23,  4.70s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 353/357 [34:01<00:18,  4.66s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 354/357 [34:06<00:13,  4.63s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 355/357 [34:10<00:09,  4.62s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 356/357 [34:15<00:04,  4.74s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:19<00:00,  4.35s/it]{'eval_loss': 0.0016227465821430087, 'eval_runtime': 36.7777, 'eval_samples_per_second': 2.719, 'eval_steps_per_second': 0.68, 'epoch': 2.0}

==================================================
Testing model performance...
==================================================
Generated solution:
analysisThe user has provided a very large chunk of text that includes the domain and problem definitions for a grid of size 4x4, with 2 keys and 3 shapes? Let's inspect:

Dimension: 4-4-2-3-3. Usually that means 4 rows, 4 columns, 2 keys, 3 shapes, 3 places? Actually the name grid-4-4-2-3-3 indicates: rows=4, cols=4, keys=2, shapes=3, places=3?? Wait typical PDDL problems for "grid" tasks include: domain grid, with 4 parameters: place, key, shape. The problem includes places, shapes, keys, initial at positions, locked positions, etc. The domain defines 3 types: place, key, shape. The problem declares objects of these types: places posX-Y, shapes shape0, shape1, keys key0, key1. There are only 2 keys (key0, key1). Wait there is key2? Let's inspect problem's objects list: "pos0-0 pos0-1 pos0-2 pos0-3 pos1-0 pos1-1 pos1-2 pos1-3 pos2-0 pos2-1 pos2-2 pos2-3 pos3-0 pos3-1 pos3-2 pos3-3 shape0 shape1 key0 key1 key2". Yes, there are 3 keys: key0, key1, key2. But the domain declares key as a type. The problem's objects include 3 keys. So the domain supports any number of keys, but the problem declares 3 keys.

The initial state indicates positions of keys: key0 at pos1-3, key1 at pos3-3, key2 at pos3-1. The robot is at pos2-2. Places pos0-0... pos3-3 are all places, and connect as conn.

Locked places: pos2-0, pos2-1, pos0-3. Their shapes: pos2-0 shape0, pos2-1 shape1, pos0-3 shape1. So shape0 open, shape1 open; but locked ones must be opened by keys of appropriate shape. They also open all other places except those three.

Goal: (at key0 pos0-0). So just need key0 at pos0-0. The keys have shapes:
==================================================
{'loss': 0.0017, 'grad_norm': 0.05032027140259743, 'learning_rate': 5.959473376986686e-06, 'epoch': 2.02}
{'loss': 0.0017, 'grad_norm': 0.07128047198057175, 'learning_rate': 5.084995082868658e-06, 'epoch': 2.1}
{'loss': 0.0016, 'grad_norm': 0.09462498873472214, 'learning_rate': 4.257556750327176e-06, 'epoch': 2.19}
{'loss': 0.0016, 'grad_norm': 0.08705833554267883, 'learning_rate': 3.485077530619664e-06, 'epoch': 2.27}
{'loss': 0.0016, 'grad_norm': 0.07121540606021881, 'learning_rate': 2.77495057867198e-06, 'epoch': 2.35}
{'loss': 0.0016, 'grad_norm': 0.14292632043361664, 'learning_rate': 2.133972295524875e-06, 'epoch': 2.44}
{'loss': 0.0016, 'grad_norm': 0.1301180124282837, 'learning_rate': 1.5682772821236192e-06, 'epoch': 2.52}
{'loss': 0.0016, 'grad_norm': 0.09796223044395447, 'learning_rate': 1.0832796269875757e-06, 'epoch': 2.61}
{'loss': 0.0016, 'grad_norm': 0.057607319205999374, 'learning_rate': 6.836210896769014e-07, 'epoch': 2.69}
{'loss': 0.0016, 'grad_norm': 0.06752491742372513, 'learning_rate': 3.731266759760854e-07, 'epoch': 2.77}
{'loss': 0.0016, 'grad_norm': 0.04722810536623001, 'learning_rate': 1.5476802997022812e-07, 'epoch': 2.86}
{'loss': 0.0016, 'grad_norm': 0.1617404818534851, 'learning_rate': 3.063499337692788e-08, 'epoch': 2.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:22,  1.00s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.41s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.47s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:55<00:00,  4.35s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [35:27<00:00,  4.35s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [35:27<00:00,  5.96s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–â–
wandb:            eval/runtime â–†â–ˆâ–
wandb: eval/samples_per_second â–â–â–ˆ
wandb:   eval/steps_per_second â–â–â–
wandb:             train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/learning_rate â–ƒâ–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:              train/loss â–ˆâ–†â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.00153
wandb:            eval/runtime 36.7629
wandb: eval/samples_per_second 2.72
wandb:   eval/steps_per_second 0.68
wandb:              total_flos 7.127275269390336e+17
wandb:             train/epoch 3
wandb:       train/global_step 357
wandb:         train/grad_norm 0.16174
wandb:     train/learning_rate 0.0
wandb:              train/loss 0.0016
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_pddl2 at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/gt8mghhi
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251031_035209-gt8mghhi/logs
{'eval_loss': 0.0015304775442928076, 'eval_runtime': 36.7629, 'eval_samples_per_second': 2.72, 'eval_steps_per_second': 0.68, 'epoch': 3.0}

==================================================
Testing model performance...
==================================================
Generated solution:
analysisWe must generate a plan (sequence of grounded actions) that achieves the goal: at key0 pos0-0. And the initial state is provided. We need to consider constraints: The problem does NOT include any :constraints section. So constraint-free. It's typical PDDL with place, key, shape, and connectivity. The goal: key0 at pos0-0. There are keys at initial positions: key0 at pos1-3, key1 at pos3-3, key2 at pos3-1. Place pos2-2 at robot initially. locked positions: pos2-0, pos2-1, pos0-3. And there are lock-shape constraints: pos2-0 shape0 locked, pos2-1 shape1 locked, pos0-3 shape1 locked. So those places need the appropriate shape keys to unlock.

Our goal: have key0 at pos0-0. But key0 is shape0. So we need to move key0 to pos0-0. pos0-0 is currently open, place pos0-0, open. So we don't need to unlock pos0-0 because it's open. However key0 starts at pos1-3, and to get it to pos0-0, we need to travel the key via robot actions.

We also need at robot pos2-2 (open), and keys at pos1-3, pos3-3, pos3-1. The robot at pos2-2 initially. It can move to place that is open. Initially open places: pos0-0, pos0-1, pos0-2, pos1-0, pos1-1, pos1-2, pos1-3, pos2-2, pos2-3, pos3-0, pos3-1, pos3-2, pos3-3. Locked: pos2-0, pos2-1, pos0-3.

Check shape locks: pos2-0 shape0 locked. pos2-1 shape1 locked. pos0-3 shape1 locked. So only those need keys.

To get key0 to pos0-0, we have to pick up key0 from pos1-3, move robot to pos0-0, and put it down. However key0 is at pos1-3. pos0-0 is open, so we can move robot from pos2-2 to pos0-0 via open places.
==================================================
{'train_runtime': 2127.9065, 'train_samples_per_second': 2.679, 'train_steps_per_second': 0.168, 'train_loss': 0.28593204210118417, 'epoch': 3.0}

Saving model to sft_models/gpt_oss_20b/grid/pddl2 ...
Training completed!

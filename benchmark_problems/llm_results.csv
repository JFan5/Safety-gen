scenario,problem,llm_status,llm_validation,llm_elapsed,llm_plan_path,llm_notes
blocksworld,bw_ops3_n03_seed3001.pddl,invalid,invalid,55.526,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan"
blocksworld,bw_ops3_n04_seed4001.pddl,invalid,invalid,44.984,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan"
blocksworld,bw_ops3_n05_seed5001.pddl,invalid,invalid,44.905,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan"
blocksworld,bw_ops3_n06_seed6001.pddl,invalid,invalid,40.156,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan"
blocksworld,bw_ops3_n07_seed7001.pddl,invalid,invalid,26.258,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan"
blocksworld,bw_ops3_n08_seed8001.pddl,invalid,invalid,33.561,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n08_seed8001.plan,Error: Bad operator in plan!
blocksworld,bw_ops3_n09_seed9001.pddl,invalid,invalid,44.504,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan"
blocksworld,bw_ops3_n10_seed10001.pddl,invalid,invalid,44.385,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan"
blocksworld,bw_ops3_n11_seed11001.pddl,invalid,invalid,44.100,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan"
blocksworld,bw_ops3_n12_seed12001.pddl,invalid,invalid,44.925,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan"
blocksworld,bw_ops3_n13_seed13001.pddl,invalid,invalid,44.489,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan"
blocksworld,bw_ops3_n14_seed14001.pddl,invalid,invalid,44.443,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n14_seed14001.plan,Error: Bad operator in plan!
blocksworld,bw_ops3_n15_seed15001.pddl,invalid,invalid,44.875,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan"
blocksworld,bw_ops3_n16_seed16001.pddl,invalid,invalid,44.605,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan"
blocksworld,bw_ops3_n17_seed17001.pddl,invalid,invalid,32.790,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan"
blocksworld,bw_ops3_n18_seed18001.pddl,invalid,invalid,24.972,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan"
blocksworld,bw_ops3_n19_seed19001.pddl,invalid,invalid,25.003,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan"
blocksworld,bw_ops3_n20_seed20001.pddl,invalid,invalid,25.055,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan"
blocksworld,bw_ops3_n21_seed21001.pddl,invalid,invalid,25.390,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan"
blocksworld,bw_ops3_n22_seed22001.pddl,invalid,invalid,24.988,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan"
blocksworld,bw_ops3_n23_seed23001.pddl,invalid,invalid,24.948,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan"
blocksworld,bw_ops3_n24_seed24001.pddl,invalid,invalid,24.976,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan"
blocksworld,bw_ops3_n25_seed25001.pddl,invalid,invalid,24.955,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan"
blocksworld,bw_ops3_n26_seed26001.pddl,invalid,invalid,25.006,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan"
blocksworld,bw_ops3_n27_seed27001.pddl,invalid,invalid,24.979,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan"
blocksworld,bw_ops3_n28_seed28001.pddl,invalid,invalid,26.326,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan"
blocksworld,bw_ops3_n29_seed29001.pddl,invalid,invalid,33.553,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan"
blocksworld,bw_ops3_n30_seed30001.pddl,invalid,invalid,44.366,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan"
blocksworld,bw_ops3_n31_seed31001.pddl,invalid,invalid,45.303,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan"
blocksworld,bw_ops3_n32_seed32001.pddl,invalid,invalid,44.647,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan"
blocksworld,bw_ops3_n33_seed33001.pddl,invalid,invalid,44.748,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan"
blocksworld,bw_ops3_n34_seed34001.pddl,invalid,invalid,45.157,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan"
blocksworld,bw_ops3_n35_seed35001.pddl,invalid,invalid,44.889,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan"
blocksworld,bw_ops3_n36_seed36001.pddl,invalid,invalid,44.543,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan"
blocksworld,bw_ops3_n37_seed37001.pddl,invalid,invalid,44.350,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan"
blocksworld,bw_ops3_n38_seed38001.pddl,invalid,invalid,44.789,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan"
blocksworld,bw_ops3_n39_seed39001.pddl,invalid,invalid,44.942,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan"
blocksworld,bw_ops3_n40_seed40001.pddl,invalid,invalid,45.189,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan"
blocksworld,bw_ops3_n41_seed41001.pddl,invalid,invalid,45.465,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan"
blocksworld,bw_ops3_n42_seed42001.pddl,invalid,invalid,45.268,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan"
blocksworld,bw_ops3_n43_seed43001.pddl,invalid,invalid,45.127,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan"
blocksworld,bw_ops3_n44_seed44001.pddl,invalid,invalid,45.160,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan"
blocksworld,bw_ops3_n45_seed45001.pddl,invalid,invalid,33.029,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan"
blocksworld,bw_ops3_n46_seed46001.pddl,invalid,invalid,45.258,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan"
blocksworld,bw_ops3_n47_seed47001.pddl,invalid,invalid,45.217,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan"
blocksworld,bw_ops3_n48_seed48001.pddl,invalid,invalid,44.712,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan"
blocksworld,bw_ops3_n49_seed49001.pddl,invalid,invalid,44.957,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan"
blocksworld,bw_ops3_n50_seed50001.pddl,invalid,invalid,39.372,Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan"
grippers,grippers-n1-r5-o3-s3001.pddl,invalid,invalid,26.482,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan"
grippers,grippers-n1-r6-o4-s4001.pddl,invalid,invalid,37.864,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan"
grippers,grippers-n1-r7-o5-s5001.pddl,invalid,invalid,44.310,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan"
grippers,grippers-n1-r8-o6-s6001.pddl,invalid,invalid,44.392,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan"
grippers,grippers-n1-r9-o7-s7001.pddl,invalid,invalid,43.901,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan"
grippers,grippers-n1-r10-o8-s8001.pddl,invalid,invalid,44.312,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan"
grippers,grippers-n1-r11-o9-s9001.pddl,invalid,invalid,44.455,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan"
grippers,grippers-n2-r12-o10-s10001.pddl,invalid,invalid,44.562,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan"
grippers,grippers-n2-r13-o11-s11001.pddl,invalid,invalid,44.840,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan"
grippers,grippers-n2-r14-o12-s12001.pddl,invalid,invalid,45.168,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan"
grippers,grippers-n2-r15-o13-s13001.pddl,invalid,invalid,42.612,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan"
grippers,grippers-n2-r16-o14-s14001.pddl,invalid,invalid,26.332,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan"
grippers,grippers-n2-r17-o15-s15001.pddl,invalid,invalid,33.032,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan"
grippers,grippers-n2-r18-o16-s16001.pddl,invalid,invalid,44.715,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan"
grippers,grippers-n2-r19-o17-s17001.pddl,invalid,invalid,44.682,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan"
grippers,grippers-n2-r20-o18-s18001.pddl,invalid,invalid,44.720,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan"
grippers,grippers-n2-r21-o19-s19001.pddl,invalid,invalid,45.250,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan"
grippers,grippers-n3-r22-o20-s20001.pddl,invalid,invalid,44.758,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan"
grippers,grippers-n3-r23-o21-s21001.pddl,invalid,invalid,45.146,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan"
grippers,grippers-n3-r24-o22-s22001.pddl,invalid,invalid,45.074,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan"
grippers,grippers-n3-r25-o23-s23001.pddl,invalid,invalid,44.814,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan"
grippers,grippers-n3-r26-o24-s24001.pddl,invalid,invalid,35.413,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan"
grippers,grippers-n3-r27-o25-s25001.pddl,invalid,invalid,26.934,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan"
grippers,grippers-n3-r28-o26-s26001.pddl,invalid,invalid,41.430,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan"
grippers,grippers-n3-r29-o27-s27001.pddl,invalid,invalid,45.107,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan"
grippers,grippers-n3-r30-o28-s28001.pddl,invalid,invalid,45.108,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan"
grippers,grippers-n3-r31-o29-s29001.pddl,invalid,invalid,45.116,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan"
grippers,grippers-n3-r32-o30-s30001.pddl,invalid,invalid,45.004,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan"
grippers,grippers-n3-r33-o31-s31001.pddl,invalid,invalid,45.560,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan"
grippers,grippers-n3-r34-o32-s32001.pddl,invalid,invalid,45.384,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan"
grippers,grippers-n3-r35-o33-s33001.pddl,invalid,invalid,45.198,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan"
grippers,grippers-n3-r36-o34-s34001.pddl,invalid,invalid,45.354,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan"
grippers,grippers-n3-r37-o35-s35001.pddl,invalid,invalid,45.025,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan"
grippers,grippers-n3-r38-o36-s36001.pddl,invalid,invalid,34.565,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan"
grippers,grippers-n3-r39-o37-s37001.pddl,invalid,invalid,25.104,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan"
grippers,grippers-n3-r40-o38-s38001.pddl,invalid,invalid,25.123,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan"
grippers,grippers-n3-r41-o39-s39001.pddl,invalid,invalid,25.138,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan"
grippers,grippers-n3-r42-o40-s40001.pddl,invalid,invalid,25.140,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan"
grippers,grippers-n3-r43-o41-s41001.pddl,invalid,invalid,25.561,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan"
grippers,grippers-n3-r44-o42-s42001.pddl,invalid,invalid,25.113,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan"
grippers,grippers-n3-r45-o43-s43001.pddl,invalid,invalid,25.182,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan"
grippers,grippers-n3-r46-o44-s44001.pddl,invalid,invalid,25.221,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan"
grippers,grippers-n3-r47-o45-s45001.pddl,invalid,invalid,26.014,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan"
grippers,grippers-n3-r48-o46-s46001.pddl,invalid,invalid,25.941,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan"
grippers,grippers-n3-r49-o47-s47001.pddl,invalid,invalid,25.315,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan"
grippers,grippers-n3-r50-o48-s48001.pddl,invalid,invalid,25.888,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan"
grippers,grippers-n3-r51-o49-s49001.pddl,invalid,invalid,25.301,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan"
grippers,grippers-n3-r52-o50-s50001.pddl,invalid,invalid,25.575,Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan"
ferry,ferry-l03-c02-s3001.pddl,invalid,invalid,24.849,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan"
ferry,ferry-l04-c03-s4001.pddl,invalid,invalid,24.883,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan"
ferry,ferry-l05-c03-s5001.pddl,invalid,invalid,24.926,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan"
ferry,ferry-l06-c04-s6001.pddl,invalid,invalid,25.010,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan"
ferry,ferry-l07-c04-s7001.pddl,invalid,invalid,25.068,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan"
ferry,ferry-l08-c05-s8001.pddl,invalid,invalid,25.370,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan"
ferry,ferry-l09-c05-s9001.pddl,invalid,invalid,25.260,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan"
ferry,ferry-l10-c06-s10001.pddl,invalid,invalid,25.270,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan"
ferry,ferry-l11-c06-s11001.pddl,invalid,invalid,25.322,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan"
ferry,ferry-l12-c07-s12001.pddl,invalid,invalid,25.857,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan"
ferry,ferry-l13-c07-s13001.pddl,invalid,invalid,25.595,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan"
ferry,ferry-l14-c08-s14001.pddl,invalid,invalid,25.702,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan"
ferry,ferry-l15-c08-s15001.pddl,invalid,invalid,25.877,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan"
ferry,ferry-l16-c09-s16001.pddl,invalid,invalid,26.089,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan"
ferry,ferry-l17-c09-s17001.pddl,invalid,invalid,26.227,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan"
ferry,ferry-l18-c10-s18001.pddl,invalid,invalid,26.354,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan"
ferry,ferry-l19-c10-s19001.pddl,invalid,invalid,26.533,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan"
ferry,ferry-l20-c11-s20001.pddl,invalid,invalid,26.862,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan"
ferry,ferry-l21-c11-s21001.pddl,invalid,invalid,27.489,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan"
ferry,ferry-l22-c12-s22001.pddl,invalid,invalid,27.573,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan"
ferry,ferry-l23-c12-s23001.pddl,invalid,invalid,27.774,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan"
ferry,ferry-l24-c13-s24001.pddl,invalid,invalid,28.091,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan"
ferry,ferry-l25-c13-s25001.pddl,invalid,invalid,28.675,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan"
ferry,ferry-l26-c14-s26001.pddl,invalid,invalid,30.879,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan"
ferry,ferry-l27-c14-s27001.pddl,invalid,invalid,29.955,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan"
ferry,ferry-l28-c15-s28001.pddl,invalid,invalid,32.227,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan"
ferry,ferry-l29-c15-s29001.pddl,invalid,invalid,41.137,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan"
ferry,ferry-l30-c16-s30001.pddl,invalid,invalid,42.369,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan"
ferry,ferry-l31-c16-s31001.pddl,generation_error,,0.723,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l31-c16-s31001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 18.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.02 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 40.24 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l32-c17-s32001.pddl,generation_error,,0.286,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l32-c17-s32001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 19.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.56 GiB is free. Including non-PyTorch memory, this process has 42.68 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 41.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l33-c17-s33001.pddl,generation_error,,0.298,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l33-c17-s33001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 22.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 46.49 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 45.54 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 59.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l34-c18-s34001.pddl,generation_error,,0.315,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l34-c18-s34001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 24.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.92 GiB is free. Including non-PyTorch memory, this process has 50.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 49.35 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l35-c18-s35001.pddl,generation_error,,0.335,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l35-c18-s35001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.13 GiB is free. Including non-PyTorch memory, this process has 54.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 53.16 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 51.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l36-c19-s36001.pddl,generation_error,,0.215,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l36-c19-s36001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 30.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.56 GiB is free. Including non-PyTorch memory, this process has 28.67 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 27.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l37-c19-s37001.pddl,generation_error,,0.300,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l37-c19-s37001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 34.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 26.49 GiB is free. Including non-PyTorch memory, this process has 30.74 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 42.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l38-c20-s38001.pddl,generation_error,,0.320,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l38-c20-s38001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 37.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.91 GiB is free. Including non-PyTorch memory, this process has 32.33 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 31.39 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l39-c20-s39001.pddl,generation_error,,0.332,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l39-c20-s39001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 41.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.82 GiB is free. Including non-PyTorch memory, this process has 34.42 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l40-c21-s40001.pddl,generation_error,,0.346,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l40-c21-s40001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 45.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.71 GiB is free. Including non-PyTorch memory, this process has 36.53 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 35.56 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l41-c21-s41001.pddl,generation_error,,0.372,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l41-c21-s41001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.62 GiB is free. Including non-PyTorch memory, this process has 38.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 37.64 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 82.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l42-c22-s42001.pddl,generation_error,,0.392,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l42-c22-s42001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 54.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.02 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 40.25 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l43-c22-s43001.pddl,generation_error,,0.401,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l43-c22-s43001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 59.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 13.42 GiB is free. Including non-PyTorch memory, this process has 43.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 42.85 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 73.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l44-c23-s44001.pddl,generation_error,,0.421,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l44-c23-s44001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 66.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.77 GiB is free. Including non-PyTorch memory, this process has 47.46 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 46.48 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l45-c23-s45001.pddl,generation_error,,0.441,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l45-c23-s45001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 70.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.68 GiB is free. Including non-PyTorch memory, this process has 49.55 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 48.57 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l46-c24-s46001.pddl,generation_error,,0.467,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l46-c24-s46001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 76.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.58 GiB is free. Including non-PyTorch memory, this process has 52.66 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 51.71 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l47-c24-s47001.pddl,generation_error,,0.547,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l47-c24-s47001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 84.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 307.81 MiB is free. Including non-PyTorch memory, this process has 56.82 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 55.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l48-c25-s48001.pddl,generation_error,,0.328,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l48-c25-s48001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 45.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 42.16 GiB is free. Including non-PyTorch memory, this process has 14.96 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 109.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l49-c25-s49001.pddl,generation_error,,0.301,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l49-c25-s49001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 42.02 GiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 92.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l50-c26-s50001.pddl,generation_error,,0.307,Safety-gen/benchmark_problems/ferry/llm_results/ferry-l50-c26-s50001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 53.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.88 GiB is free. Including non-PyTorch memory, this process has 15.24 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 14.27 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x3_y3_sh2_k4_l4_s3001.pddl,invalid,invalid,36.706,Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan"
grid,grid_x4_y4_sh2_k4_l4_s4001.pddl,invalid,invalid,36.231,Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan"
grid,grid_x5_y5_sh2_k4_l4_s5001.pddl,invalid,invalid,36.408,Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan"
grid,grid_x6_y6_sh2_k4_l4_s6001.pddl,invalid,invalid,37.233,Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan"
grid,grid_x7_y7_sh2_k4_l4_s7001.pddl,invalid,invalid,37.230,Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan"
grid,grid_x8_y8_sh2_k4_l4_s8001.pddl,invalid,invalid,39.335,Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan"
grid,grid_x9_y9_sh2_k4_l4_s9001.pddl,invalid,invalid,40.535,Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan"
grid,grid_x10_y10_sh3_k6_l6_s10001.pddl,invalid,invalid,42.284,Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan"
grid,grid_x11_y11_sh3_k6_l6_s11001.pddl,generation_error,,0.329,Safety-gen/benchmark_problems/grid/llm_results/grid_x11_y11_sh3_k6_l6_s11001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 19.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.83 GiB is free. Including non-PyTorch memory, this process has 41.92 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 40.97 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 55.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x12_y12_sh3_k6_l6_s12001.pddl,generation_error,,0.355,Safety-gen/benchmark_problems/grid/llm_results/grid_x12_y12_sh3_k6_l6_s12001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 26.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.12 GiB is free. Including non-PyTorch memory, this process has 52.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 51.64 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 94.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x13_y13_sh3_k6_l6_s13001.pddl,generation_error,,0.313,Safety-gen/benchmark_problems/grid/llm_results/grid_x13_y13_sh3_k6_l6_s13001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 35.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.43 GiB is free. Including non-PyTorch memory, this process has 31.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x14_y14_sh3_k6_l6_s14001.pddl,generation_error,,0.357,Safety-gen/benchmark_problems/grid/llm_results/grid_x14_y14_sh3_k6_l6_s14001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 46.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 19.71 GiB is free. Including non-PyTorch memory, this process has 37.03 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 36.08 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 63.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x15_y15_sh4_k8_l8_s15001.pddl,generation_error,,0.412,Safety-gen/benchmark_problems/grid/llm_results/grid_x15_y15_sh4_k8_l8_s15001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 61.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 44.87 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 43.89 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x16_y16_sh4_k8_l8_s16001.pddl,generation_error,,0.478,Safety-gen/benchmark_problems/grid/llm_results/grid_x16_y16_sh4_k8_l8_s16001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 78.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 53.69 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 52.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x17_y17_sh4_k8_l8_s17001.pddl,generation_error,,0.312,Safety-gen/benchmark_problems/grid/llm_results/grid_x17_y17_sh4_k8_l8_s17001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.64 GiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 94.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x18_y18_sh4_k8_l8_s18001.pddl,generation_error,,0.310,Safety-gen/benchmark_problems/grid/llm_results/grid_x18_y18_sh4_k8_l8_s18001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 61.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.15 GiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 125.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x19_y19_sh4_k8_l8_s19001.pddl,generation_error,,0.311,Safety-gen/benchmark_problems/grid/llm_results/grid_x19_y19_sh4_k8_l8_s19001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 76.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.65 GiB is free. Including non-PyTorch memory, this process has 16.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 15.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x20_y20_sh5_k10_l10_s20001.pddl,generation_error,,0.344,Safety-gen/benchmark_problems/grid/llm_results/grid_x20_y20_sh5_k10_l10_s20001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 92.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.02 GiB is free. Including non-PyTorch memory, this process has 16.72 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 15.74 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x21_y21_sh5_k10_l10_s21001.pddl,generation_error,,0.361,Safety-gen/benchmark_problems/grid/llm_results/grid_x21_y21_sh5_k10_l10_s21001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 112.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 39.36 GiB is free. Including non-PyTorch memory, this process has 17.38 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 60.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x22_y22_sh5_k10_l10_s22001.pddl,generation_error,,0.330,Safety-gen/benchmark_problems/grid/llm_results/grid_x22_y22_sh5_k10_l10_s22001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 132.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.50 GiB is free. Including non-PyTorch memory, this process has 18.24 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 17.24 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 119.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x23_y23_sh5_k10_l10_s23001.pddl,generation_error,,0.340,Safety-gen/benchmark_problems/grid/llm_results/grid_x23_y23_sh5_k10_l10_s23001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 160.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 37.60 GiB is free. Including non-PyTorch memory, this process has 19.14 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 18.16 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 95.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x24_y24_sh5_k10_l10_s24001.pddl,generation_error,,0.352,Safety-gen/benchmark_problems/grid/llm_results/grid_x24_y24_sh5_k10_l10_s24001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 188.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 36.60 GiB is free. Including non-PyTorch memory, this process has 20.14 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 19.14 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 106.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x25_y25_sh6_k12_l12_s25001.pddl,generation_error,,0.352,Safety-gen/benchmark_problems/grid/llm_results/grid_x25_y25_sh6_k12_l12_s25001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 220.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 35.43 GiB is free. Including non-PyTorch memory, this process has 21.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 20.32 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x26_y26_sh6_k12_l12_s26001.pddl,generation_error,,0.369,Safety-gen/benchmark_problems/grid/llm_results/grid_x26_y26_sh6_k12_l12_s26001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 34.12 GiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x27_y27_sh6_k12_l12_s27001.pddl,generation_error,,0.379,Safety-gen/benchmark_problems/grid/llm_results/grid_x27_y27_sh6_k12_l12_s27001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 296.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 32.72 GiB is free. Including non-PyTorch memory, this process has 24.03 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 113.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x28_y28_sh6_k12_l12_s28001.pddl,generation_error,,0.380,Safety-gen/benchmark_problems/grid/llm_results/grid_x28_y28_sh6_k12_l12_s28001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 344.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 31.10 GiB is free. Including non-PyTorch memory, this process has 25.65 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 24.66 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x29_y29_sh6_k12_l12_s29001.pddl,generation_error,,0.384,Safety-gen/benchmark_problems/grid/llm_results/grid_x29_y29_sh6_k12_l12_s29001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 392.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 29.49 GiB is free. Including non-PyTorch memory, this process has 27.25 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 26.28 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x30_y30_sh6_k12_l12_s30001.pddl,generation_error,,0.420,Safety-gen/benchmark_problems/grid/llm_results/grid_x30_y30_sh6_k12_l12_s30001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 448.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.58 GiB is free. Including non-PyTorch memory, this process has 29.16 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 28.18 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 93.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x31_y31_sh6_k12_l12_s31001.pddl,generation_error,,0.429,Safety-gen/benchmark_problems/grid/llm_results/grid_x31_y31_sh6_k12_l12_s31001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 512.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.31 GiB is free. Including non-PyTorch memory, this process has 31.43 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 102.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x32_y32_sh6_k12_l12_s32001.pddl,generation_error,,0.468,Safety-gen/benchmark_problems/grid/llm_results/grid_x32_y32_sh6_k12_l12_s32001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 592.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.93 GiB is free. Including non-PyTorch memory, this process has 33.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 32.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 85.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x33_y33_sh6_k12_l12_s33001.pddl,generation_error,,0.504,Safety-gen/benchmark_problems/grid/llm_results/grid_x33_y33_sh6_k12_l12_s33001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 656.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.47 GiB is free. Including non-PyTorch memory, this process has 36.27 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 35.29 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 100.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x34_y34_sh6_k12_l12_s34001.pddl,generation_error,,0.503,Safety-gen/benchmark_problems/grid/llm_results/grid_x34_y34_sh6_k12_l12_s34001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 736.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.81 GiB is free. Including non-PyTorch memory, this process has 38.93 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 37.94 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 106.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x35_y35_sh6_k12_l12_s35001.pddl,generation_error,,0.555,Safety-gen/benchmark_problems/grid/llm_results/grid_x35_y35_sh6_k12_l12_s35001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 832.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 41.86 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 40.85 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 120.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x36_y36_sh6_k12_l12_s36001.pddl,generation_error,,0.615,Safety-gen/benchmark_problems/grid/llm_results/grid_x36_y36_sh6_k12_l12_s36001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 928.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.74 GiB is free. Including non-PyTorch memory, this process has 44.98 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 94.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x37_y37_sh6_k12_l12_s37001.pddl,generation_error,,0.527,Safety-gen/benchmark_problems/grid/llm_results/grid_x37_y37_sh6_k12_l12_s37001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 1056.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.55 GiB is free. Including non-PyTorch memory, this process has 49.18 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 48.20 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 96.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x38_y38_sh6_k12_l12_s38001.pddl,generation_error,,0.484,Safety-gen/benchmark_problems/grid/llm_results/grid_x38_y38_sh6_k12_l12_s38001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.92 GiB is free. Including non-PyTorch memory, this process has 48.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 47.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 69.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x39_y39_sh6_k12_l12_s39001.pddl,generation_error,,0.361,Safety-gen/benchmark_problems/grid/llm_results/grid_x39_y39_sh6_k12_l12_s39001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.93 GiB is free. Including non-PyTorch memory, this process has 52.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 51.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x40_y40_sh6_k12_l12_s40001.pddl,generation_error,,0.430,Safety-gen/benchmark_problems/grid/llm_results/grid_x40_y40_sh6_k12_l12_s40001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 11.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.92 GiB is free. Including non-PyTorch memory, this process has 45.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 44.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x41_y41_sh6_k12_l12_s41001.pddl,generation_error,,0.442,Safety-gen/benchmark_problems/grid/llm_results/grid_x41_y41_sh6_k12_l12_s41001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 12.25 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.17 GiB is free. Including non-PyTorch memory, this process has 49.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 48.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 60.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x42_y42_sh6_k12_l12_s42001.pddl,generation_error,,0.500,Safety-gen/benchmark_problems/grid/llm_results/grid_x42_y42_sh6_k12_l12_s42001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.42 GiB is free. Including non-PyTorch memory, this process has 53.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 52.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 60.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x43_y43_sh6_k12_l12_s43001.pddl,generation_error,,0.552,Safety-gen/benchmark_problems/grid/llm_results/grid_x43_y43_sh6_k12_l12_s43001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 29.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 29.17 GiB is free. Including non-PyTorch memory, this process has 27.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 26.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 69.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x44_y44_sh6_k12_l12_s44001.pddl,generation_error,,0.581,Safety-gen/benchmark_problems/grid/llm_results/grid_x44_y44_sh6_k12_l12_s44001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 33.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.43 GiB is free. Including non-PyTorch memory, this process has 29.30 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 28.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 57.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x45_y45_sh6_k12_l12_s45001.pddl,generation_error,,0.616,Safety-gen/benchmark_problems/grid/llm_results/grid_x45_y45_sh6_k12_l12_s45001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.94 GiB is free. Including non-PyTorch memory, this process has 30.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 29.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x46_y46_sh6_k12_l12_s46001.pddl,generation_error,,0.605,Safety-gen/benchmark_problems/grid/llm_results/grid_x46_y46_sh6_k12_l12_s46001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 39.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.44 GiB is free. Including non-PyTorch memory, this process has 32.30 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 31.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 58.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x47_y47_sh6_k12_l12_s47001.pddl,generation_error,,0.629,Safety-gen/benchmark_problems/grid/llm_results/grid_x47_y47_sh6_k12_l12_s47001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 42.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.93 GiB is free. Including non-PyTorch memory, this process has 33.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 32.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 62.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x48_y48_sh6_k12_l12_s48001.pddl,generation_error,,0.322,Safety-gen/benchmark_problems/grid/llm_results/grid_x48_y48_sh6_k12_l12_s48001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 23.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.94 GiB is free. Including non-PyTorch memory, this process has 35.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 34.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 52.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x49_y49_sh6_k12_l12_s49001.pddl,generation_error,,0.354,Safety-gen/benchmark_problems/grid/llm_results/grid_x49_y49_sh6_k12_l12_s49001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 25.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.95 GiB is free. Including non-PyTorch memory, this process has 37.79 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 44.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x50_y50_sh6_k12_l12_s50001.pddl,generation_error,,0.324,Safety-gen/benchmark_problems/grid/llm_results/grid_x50_y50_sh6_k12_l12_s50001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.94 GiB is free. Including non-PyTorch memory, this process has 39.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 38.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 55.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size3_packages1_seed3001.pddl,invalid,invalid,35.914,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan"
delivery,delivery_size4_packages1_seed4001.pddl,invalid,invalid,35.889,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan"
delivery,delivery_size5_packages1_seed5001.pddl,invalid,invalid,35.668,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan"
delivery,delivery_size6_packages1_seed6001.pddl,invalid,invalid,39.711,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan"
delivery,delivery_size7_packages1_seed7001.pddl,invalid,invalid,41.342,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan"
delivery,delivery_size8_packages1_seed8001.pddl,invalid,invalid,39.089,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan"
delivery,delivery_size9_packages1_seed9001.pddl,invalid,invalid,39.135,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan"
delivery,delivery_size10_packages1_seed10001.pddl,invalid,invalid,40.200,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan"
delivery,delivery_size11_packages1_seed11001.pddl,invalid,invalid,41.893,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan"
delivery,delivery_size12_packages1_seed12001.pddl,generation_error,,0.312,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size12_packages1_seed12001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 21.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.97 GiB is free. Including non-PyTorch memory, this process has 45.74 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 44.78 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 71.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size13_packages1_seed13001.pddl,generation_error,,0.266,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size13_packages1_seed13001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 29.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.57 GiB is free. Including non-PyTorch memory, this process has 28.15 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 27.20 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 59.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size14_packages1_seed14001.pddl,generation_error,,0.310,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size14_packages1_seed14001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 39.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.32 GiB is free. Including non-PyTorch memory, this process has 33.40 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 32.42 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size15_packages1_seed15001.pddl,generation_error,,0.348,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size15_packages1_seed15001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 51.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.07 GiB is free. Including non-PyTorch memory, this process has 39.65 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 38.68 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size16_packages1_seed16001.pddl,generation_error,,0.402,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size16_packages1_seed16001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 66.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 8.26 GiB is free. Including non-PyTorch memory, this process has 47.46 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 46.48 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size17_packages1_seed17001.pddl,generation_error,,0.300,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size17_packages1_seed17001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 42.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.89 GiB is free. Including non-PyTorch memory, this process has 14.82 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 13.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 93.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size18_packages1_seed18001.pddl,generation_error,,0.292,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size18_packages1_seed18001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 52.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.46 GiB is free. Including non-PyTorch memory, this process has 15.25 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 113.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size19_packages1_seed19001.pddl,generation_error,,0.292,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size19_packages1_seed19001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.03 GiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 92.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size20_packages1_seed20001.pddl,generation_error,,0.299,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size20_packages1_seed20001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 80.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 39.49 GiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 78.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size21_packages1_seed21001.pddl,generation_error,,0.296,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size21_packages1_seed21001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 96.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.84 GiB is free. Including non-PyTorch memory, this process has 16.88 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size22_packages1_seed22001.pddl,generation_error,,0.314,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size22_packages1_seed22001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 116.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.12 GiB is free. Including non-PyTorch memory, this process has 17.60 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 98.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size23_packages1_seed23001.pddl,generation_error,,0.315,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size23_packages1_seed23001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 136.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 37.38 GiB is free. Including non-PyTorch memory, this process has 18.34 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 17.37 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size24_packages1_seed24001.pddl,generation_error,,0.315,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size24_packages1_seed24001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 164.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 36.34 GiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 18.38 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 111.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size25_packages1_seed25001.pddl,generation_error,,0.429,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size25_packages1_seed25001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 192.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 35.40 GiB is free. Including non-PyTorch memory, this process has 20.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 19.34 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size26_packages1_seed26001.pddl,generation_error,,0.329,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size26_packages1_seed26001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 224.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 34.26 GiB is free. Including non-PyTorch memory, this process has 21.45 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 20.47 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 85.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size27_packages1_seed27001.pddl,generation_error,,0.369,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size27_packages1_seed27001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 264.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 32.95 GiB is free. Including non-PyTorch memory, this process has 22.76 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 21.77 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 93.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size28_packages1_seed28001.pddl,generation_error,,0.365,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size28_packages1_seed28001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 304.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 31.55 GiB is free. Including non-PyTorch memory, this process has 24.16 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 23.15 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 125.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size29_packages1_seed29001.pddl,generation_error,,0.375,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size29_packages1_seed29001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 344.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 30.06 GiB is free. Including non-PyTorch memory, this process has 25.65 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 24.66 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size30_packages1_seed30001.pddl,generation_error,,0.393,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size30_packages1_seed30001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 400.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.31 GiB is free. Including non-PyTorch memory, this process has 27.40 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 26.43 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 85.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size31_packages1_seed31001.pddl,generation_error,,0.458,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size31_packages1_seed31001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 456.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 26.39 GiB is free. Including non-PyTorch memory, this process has 29.32 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 28.31 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 125.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size32_packages1_seed32001.pddl,generation_error,,0.461,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size32_packages1_seed32001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 512.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.28 GiB is free. Including non-PyTorch memory, this process has 31.43 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 102.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size33_packages1_seed33001.pddl,generation_error,,0.472,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size33_packages1_seed33001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 592.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 21.84 GiB is free. Including non-PyTorch memory, this process has 33.87 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 32.89 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 96.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size34_packages1_seed34001.pddl,generation_error,,0.463,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size34_packages1_seed34001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 656.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 19.69 GiB is free. Including non-PyTorch memory, this process has 36.02 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 35.04 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 96.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size35_packages1_seed35001.pddl,generation_error,,0.524,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size35_packages1_seed35001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 736.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.02 GiB is free. Including non-PyTorch memory, this process has 38.70 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 37.68 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 123.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size36_packages1_seed36001.pddl,generation_error,,0.568,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size36_packages1_seed36001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 832.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 13.87 GiB is free. Including non-PyTorch memory, this process has 41.84 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 40.83 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 117.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size37_packages1_seed37001.pddl,generation_error,,0.622,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size37_packages1_seed37001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 928.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 44.96 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 75.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size38_packages1_seed38001.pddl,generation_error,,0.560,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size38_packages1_seed38001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 1024.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.02 GiB is free. Including non-PyTorch memory, this process has 48.70 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 47.70 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 109.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size39_packages1_seed39001.pddl,generation_error,,0.513,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size39_packages1_seed39001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.90 GiB is free. Including non-PyTorch memory, this process has 48.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 47.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 69.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size40_packages1_seed40001.pddl,generation_error,,0.332,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size40_packages1_seed40001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 2.91 GiB is free. Including non-PyTorch memory, this process has 52.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 51.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size41_packages1_seed41001.pddl,generation_error,,0.439,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size41_packages1_seed41001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 11.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.91 GiB is free. Including non-PyTorch memory, this process has 45.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 44.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size42_packages1_seed42001.pddl,generation_error,,0.454,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size42_packages1_seed42001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.90 GiB is free. Including non-PyTorch memory, this process has 48.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 47.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 68.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size43_packages1_seed43001.pddl,generation_error,,0.481,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size43_packages1_seed43001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 13.25 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.15 GiB is free. Including non-PyTorch memory, this process has 52.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 51.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 68.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size44_packages1_seed44001.pddl,generation_error,,0.524,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size44_packages1_seed44001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 29.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.40 GiB is free. Including non-PyTorch memory, this process has 27.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 26.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 65.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size45_packages1_seed45001.pddl,generation_error,,0.550,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size45_packages1_seed45001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 31.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.15 GiB is free. Including non-PyTorch memory, this process has 28.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 27.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size46_packages1_seed46001.pddl,generation_error,,0.539,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size46_packages1_seed46001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 35.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.42 GiB is free. Including non-PyTorch memory, this process has 30.29 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 29.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size47_packages1_seed47001.pddl,generation_error,,0.560,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size47_packages1_seed47001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 38.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 23.92 GiB is free. Including non-PyTorch memory, this process has 31.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 30.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 50.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size48_packages1_seed48001.pddl,generation_error,,0.577,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size48_packages1_seed48001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 41.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.41 GiB is free. Including non-PyTorch memory, this process has 33.30 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 32.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size49_packages1_seed49001.pddl,generation_error,,0.321,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size49_packages1_seed49001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 22.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.42 GiB is free. Including non-PyTorch memory, this process has 35.29 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 34.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 44.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size50_packages1_seed50001.pddl,generation_error,,0.318,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size50_packages1_seed50001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.92 GiB is free. Including non-PyTorch memory, this process has 36.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 35.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 48.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
blocksworld,bw_ops3_n03_seed3001.pddl,invalid,invalid,55.526,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan"
blocksworld,bw_ops3_n04_seed4001.pddl,invalid,invalid,44.984,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan"
blocksworld,bw_ops3_n05_seed5001.pddl,invalid,invalid,44.905,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan"
blocksworld,bw_ops3_n06_seed6001.pddl,invalid,invalid,40.156,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan"
blocksworld,bw_ops3_n07_seed7001.pddl,invalid,invalid,26.258,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan"
blocksworld,bw_ops3_n08_seed8001.pddl,invalid,invalid,33.561,,Error: Bad operator in plan!
blocksworld,bw_ops3_n09_seed9001.pddl,invalid,invalid,44.504,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan"
blocksworld,bw_ops3_n10_seed10001.pddl,invalid,invalid,44.385,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan"
blocksworld,bw_ops3_n11_seed11001.pddl,invalid,invalid,44.100,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan"
blocksworld,bw_ops3_n12_seed12001.pddl,invalid,invalid,44.925,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan"
blocksworld,bw_ops3_n13_seed13001.pddl,invalid,invalid,44.489,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan"
blocksworld,bw_ops3_n14_seed14001.pddl,invalid,invalid,44.443,,Error: Bad operator in plan!
blocksworld,bw_ops3_n15_seed15001.pddl,invalid,invalid,44.875,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan"
blocksworld,bw_ops3_n16_seed16001.pddl,invalid,invalid,44.605,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan"
blocksworld,bw_ops3_n17_seed17001.pddl,invalid,invalid,32.790,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan"
blocksworld,bw_ops3_n18_seed18001.pddl,invalid,invalid,24.972,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan"
blocksworld,bw_ops3_n19_seed19001.pddl,invalid,invalid,25.003,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan"
blocksworld,bw_ops3_n20_seed20001.pddl,invalid,invalid,25.055,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan"
blocksworld,bw_ops3_n21_seed21001.pddl,invalid,invalid,25.390,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan"
blocksworld,bw_ops3_n22_seed22001.pddl,invalid,invalid,24.988,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan"
blocksworld,bw_ops3_n23_seed23001.pddl,invalid,invalid,24.948,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan"
blocksworld,bw_ops3_n24_seed24001.pddl,invalid,invalid,24.976,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan"
blocksworld,bw_ops3_n25_seed25001.pddl,invalid,invalid,24.955,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan"
blocksworld,bw_ops3_n26_seed26001.pddl,invalid,invalid,25.006,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan"
blocksworld,bw_ops3_n27_seed27001.pddl,invalid,invalid,24.979,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan"
blocksworld,bw_ops3_n28_seed28001.pddl,invalid,invalid,26.326,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan"
blocksworld,bw_ops3_n29_seed29001.pddl,invalid,invalid,33.553,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan"
blocksworld,bw_ops3_n30_seed30001.pddl,invalid,invalid,44.366,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan"
blocksworld,bw_ops3_n31_seed31001.pddl,invalid,invalid,45.303,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan"
blocksworld,bw_ops3_n32_seed32001.pddl,invalid,invalid,44.647,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan"
blocksworld,bw_ops3_n33_seed33001.pddl,invalid,invalid,44.748,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan"
blocksworld,bw_ops3_n34_seed34001.pddl,invalid,invalid,45.157,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan"
blocksworld,bw_ops3_n35_seed35001.pddl,invalid,invalid,44.889,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan"
blocksworld,bw_ops3_n36_seed36001.pddl,invalid,invalid,44.543,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan"
blocksworld,bw_ops3_n37_seed37001.pddl,invalid,invalid,44.350,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan"
blocksworld,bw_ops3_n38_seed38001.pddl,invalid,invalid,44.789,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan"
blocksworld,bw_ops3_n39_seed39001.pddl,invalid,invalid,44.942,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan"
blocksworld,bw_ops3_n40_seed40001.pddl,invalid,invalid,45.189,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan"
blocksworld,bw_ops3_n41_seed41001.pddl,invalid,invalid,45.465,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan"
blocksworld,bw_ops3_n42_seed42001.pddl,invalid,invalid,45.268,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan"
blocksworld,bw_ops3_n43_seed43001.pddl,invalid,invalid,45.127,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan"
blocksworld,bw_ops3_n44_seed44001.pddl,invalid,invalid,45.160,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan"
blocksworld,bw_ops3_n45_seed45001.pddl,invalid,invalid,33.029,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan"
blocksworld,bw_ops3_n46_seed46001.pddl,invalid,invalid,45.258,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan"
blocksworld,bw_ops3_n47_seed47001.pddl,invalid,invalid,45.217,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan"
blocksworld,bw_ops3_n48_seed48001.pddl,invalid,invalid,44.712,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan"
blocksworld,bw_ops3_n49_seed49001.pddl,invalid,invalid,44.957,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan"
blocksworld,bw_ops3_n50_seed50001.pddl,invalid,invalid,39.372,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan"
grippers,grippers-n1-r10-o8-s8001.pddl,invalid,invalid,44.312,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan"
grippers,grippers-n1-r11-o9-s9001.pddl,invalid,invalid,44.455,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan"
grippers,grippers-n1-r5-o3-s3001.pddl,invalid,invalid,26.482,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan"
grippers,grippers-n1-r6-o4-s4001.pddl,invalid,invalid,37.864,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan"
grippers,grippers-n1-r7-o5-s5001.pddl,invalid,invalid,44.310,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan"
grippers,grippers-n1-r8-o6-s6001.pddl,invalid,invalid,44.392,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan"
grippers,grippers-n1-r9-o7-s7001.pddl,invalid,invalid,43.901,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan"
grippers,grippers-n2-r12-o10-s10001.pddl,invalid,invalid,44.562,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan"
grippers,grippers-n2-r13-o11-s11001.pddl,invalid,invalid,44.840,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan"
grippers,grippers-n2-r14-o12-s12001.pddl,invalid,invalid,45.168,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan"
grippers,grippers-n2-r15-o13-s13001.pddl,invalid,invalid,42.612,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan"
grippers,grippers-n2-r16-o14-s14001.pddl,invalid,invalid,26.332,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan"
grippers,grippers-n2-r17-o15-s15001.pddl,invalid,invalid,33.032,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan"
grippers,grippers-n2-r18-o16-s16001.pddl,invalid,invalid,44.715,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan"
grippers,grippers-n2-r19-o17-s17001.pddl,invalid,invalid,44.682,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan"
grippers,grippers-n2-r20-o18-s18001.pddl,invalid,invalid,44.720,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan"
grippers,grippers-n2-r21-o19-s19001.pddl,invalid,invalid,45.250,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan"
grippers,grippers-n3-r22-o20-s20001.pddl,invalid,invalid,44.758,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan"
grippers,grippers-n3-r23-o21-s21001.pddl,invalid,invalid,45.146,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan"
grippers,grippers-n3-r24-o22-s22001.pddl,invalid,invalid,45.074,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan"
grippers,grippers-n3-r25-o23-s23001.pddl,invalid,invalid,44.814,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan"
grippers,grippers-n3-r26-o24-s24001.pddl,invalid,invalid,35.413,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan"
grippers,grippers-n3-r27-o25-s25001.pddl,invalid,invalid,26.934,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan"
grippers,grippers-n3-r28-o26-s26001.pddl,invalid,invalid,41.430,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan"
grippers,grippers-n3-r29-o27-s27001.pddl,invalid,invalid,45.107,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan"
grippers,grippers-n3-r30-o28-s28001.pddl,invalid,invalid,45.108,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan"
grippers,grippers-n3-r31-o29-s29001.pddl,invalid,invalid,45.116,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan"
grippers,grippers-n3-r32-o30-s30001.pddl,invalid,invalid,45.004,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan"
grippers,grippers-n3-r33-o31-s31001.pddl,invalid,invalid,45.560,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan"
grippers,grippers-n3-r34-o32-s32001.pddl,invalid,invalid,45.384,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan"
grippers,grippers-n3-r35-o33-s33001.pddl,invalid,invalid,45.198,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan"
grippers,grippers-n3-r36-o34-s34001.pddl,invalid,invalid,45.354,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan"
grippers,grippers-n3-r37-o35-s35001.pddl,invalid,invalid,45.025,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan"
grippers,grippers-n3-r38-o36-s36001.pddl,invalid,invalid,34.565,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan"
grippers,grippers-n3-r39-o37-s37001.pddl,invalid,invalid,25.104,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan"
grippers,grippers-n3-r40-o38-s38001.pddl,invalid,invalid,25.123,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan"
grippers,grippers-n3-r41-o39-s39001.pddl,invalid,invalid,25.138,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan"
grippers,grippers-n3-r42-o40-s40001.pddl,invalid,invalid,25.140,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan"
grippers,grippers-n3-r43-o41-s41001.pddl,invalid,invalid,25.561,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan"
grippers,grippers-n3-r44-o42-s42001.pddl,invalid,invalid,25.113,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan"
grippers,grippers-n3-r45-o43-s43001.pddl,invalid,invalid,25.182,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan"
grippers,grippers-n3-r46-o44-s44001.pddl,invalid,invalid,25.221,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan"
grippers,grippers-n3-r47-o45-s45001.pddl,invalid,invalid,26.014,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan"
grippers,grippers-n3-r48-o46-s46001.pddl,invalid,invalid,25.941,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan"
grippers,grippers-n3-r49-o47-s47001.pddl,invalid,invalid,25.315,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan"
grippers,grippers-n3-r50-o48-s48001.pddl,invalid,invalid,25.888,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan"
grippers,grippers-n3-r51-o49-s49001.pddl,invalid,invalid,25.301,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan"
grippers,grippers-n3-r52-o50-s50001.pddl,invalid,invalid,25.575,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan"
ferry,ferry-l03-c02-s3001.pddl,invalid,invalid,24.849,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan"
ferry,ferry-l04-c03-s4001.pddl,invalid,invalid,24.883,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan"
ferry,ferry-l05-c03-s5001.pddl,invalid,invalid,24.926,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan"
ferry,ferry-l06-c04-s6001.pddl,invalid,invalid,25.010,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan"
ferry,ferry-l07-c04-s7001.pddl,invalid,invalid,25.068,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan"
ferry,ferry-l08-c05-s8001.pddl,invalid,invalid,25.370,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan"
ferry,ferry-l09-c05-s9001.pddl,invalid,invalid,25.260,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan"
ferry,ferry-l10-c06-s10001.pddl,invalid,invalid,25.270,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan"
ferry,ferry-l11-c06-s11001.pddl,invalid,invalid,25.322,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan"
ferry,ferry-l12-c07-s12001.pddl,invalid,invalid,25.857,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan"
ferry,ferry-l13-c07-s13001.pddl,invalid,invalid,25.595,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan"
ferry,ferry-l14-c08-s14001.pddl,invalid,invalid,25.702,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan"
ferry,ferry-l15-c08-s15001.pddl,invalid,invalid,25.877,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan"
ferry,ferry-l16-c09-s16001.pddl,invalid,invalid,26.089,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan"
ferry,ferry-l17-c09-s17001.pddl,invalid,invalid,26.227,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan"
ferry,ferry-l18-c10-s18001.pddl,invalid,invalid,26.354,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan"
ferry,ferry-l19-c10-s19001.pddl,invalid,invalid,26.533,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan"
ferry,ferry-l20-c11-s20001.pddl,invalid,invalid,26.862,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan"
ferry,ferry-l21-c11-s21001.pddl,invalid,invalid,27.489,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan"
ferry,ferry-l22-c12-s22001.pddl,invalid,invalid,27.573,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan"
ferry,ferry-l23-c12-s23001.pddl,invalid,invalid,27.774,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan"
ferry,ferry-l24-c13-s24001.pddl,invalid,invalid,28.091,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan"
ferry,ferry-l25-c13-s25001.pddl,invalid,invalid,28.675,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan"
ferry,ferry-l26-c14-s26001.pddl,invalid,invalid,30.879,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan"
ferry,ferry-l27-c14-s27001.pddl,invalid,invalid,29.955,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan"
ferry,ferry-l28-c15-s28001.pddl,invalid,invalid,32.227,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan"
ferry,ferry-l29-c15-s29001.pddl,invalid,invalid,41.137,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan"
ferry,ferry-l30-c16-s30001.pddl,invalid,invalid,42.369,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan"
ferry,ferry-l31-c16-s31001.pddl,generation_error,,0.723,,"CUDA OOM: CUDA out of memory. Tried to allocate 18.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.02 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 40.24 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l32-c17-s32001.pddl,generation_error,,0.286,,"CUDA OOM: CUDA out of memory. Tried to allocate 19.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.56 GiB is free. Including non-PyTorch memory, this process has 42.68 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 41.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l33-c17-s33001.pddl,generation_error,,0.298,,"CUDA OOM: CUDA out of memory. Tried to allocate 22.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 46.49 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 45.54 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 59.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l34-c18-s34001.pddl,generation_error,,0.315,,"CUDA OOM: CUDA out of memory. Tried to allocate 24.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.92 GiB is free. Including non-PyTorch memory, this process has 50.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 49.35 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l35-c18-s35001.pddl,generation_error,,0.335,,"CUDA OOM: CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.13 GiB is free. Including non-PyTorch memory, this process has 54.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 53.16 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 51.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l36-c19-s36001.pddl,generation_error,,0.215,,"CUDA OOM: CUDA out of memory. Tried to allocate 30.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.56 GiB is free. Including non-PyTorch memory, this process has 28.67 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 27.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l37-c19-s37001.pddl,generation_error,,0.300,,"CUDA OOM: CUDA out of memory. Tried to allocate 34.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 26.49 GiB is free. Including non-PyTorch memory, this process has 30.74 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 42.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l38-c20-s38001.pddl,generation_error,,0.320,,"CUDA OOM: CUDA out of memory. Tried to allocate 37.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.91 GiB is free. Including non-PyTorch memory, this process has 32.33 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 31.39 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l39-c20-s39001.pddl,generation_error,,0.332,,"CUDA OOM: CUDA out of memory. Tried to allocate 41.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.82 GiB is free. Including non-PyTorch memory, this process has 34.42 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l40-c21-s40001.pddl,generation_error,,0.346,,"CUDA OOM: CUDA out of memory. Tried to allocate 45.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.71 GiB is free. Including non-PyTorch memory, this process has 36.53 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 35.56 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l41-c21-s41001.pddl,generation_error,,0.372,,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.62 GiB is free. Including non-PyTorch memory, this process has 38.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 37.64 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 82.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l42-c22-s42001.pddl,generation_error,,0.392,,"CUDA OOM: CUDA out of memory. Tried to allocate 54.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.02 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 40.25 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l43-c22-s43001.pddl,generation_error,,0.401,,"CUDA OOM: CUDA out of memory. Tried to allocate 59.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 13.42 GiB is free. Including non-PyTorch memory, this process has 43.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 42.85 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 73.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l44-c23-s44001.pddl,generation_error,,0.421,,"CUDA OOM: CUDA out of memory. Tried to allocate 66.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.77 GiB is free. Including non-PyTorch memory, this process has 47.46 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 46.48 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l45-c23-s45001.pddl,generation_error,,0.441,,"CUDA OOM: CUDA out of memory. Tried to allocate 70.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.68 GiB is free. Including non-PyTorch memory, this process has 49.55 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 48.57 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l46-c24-s46001.pddl,generation_error,,0.467,,"CUDA OOM: CUDA out of memory. Tried to allocate 76.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.58 GiB is free. Including non-PyTorch memory, this process has 52.66 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 51.71 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l47-c24-s47001.pddl,generation_error,,0.547,,"CUDA OOM: CUDA out of memory. Tried to allocate 84.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 307.81 MiB is free. Including non-PyTorch memory, this process has 56.82 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 55.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l48-c25-s48001.pddl,generation_error,,0.328,,"CUDA OOM: CUDA out of memory. Tried to allocate 45.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 42.16 GiB is free. Including non-PyTorch memory, this process has 14.96 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 109.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l49-c25-s49001.pddl,generation_error,,0.301,,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 42.02 GiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 92.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l50-c26-s50001.pddl,generation_error,,0.307,,"CUDA OOM: CUDA out of memory. Tried to allocate 53.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.88 GiB is free. Including non-PyTorch memory, this process has 15.24 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 14.27 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x10_y10_sh3_k6_l6_s10001.pddl,invalid,invalid,42.284,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan"
grid,grid_x11_y11_sh3_k6_l6_s11001.pddl,generation_error,,0.329,,"CUDA OOM: CUDA out of memory. Tried to allocate 19.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.83 GiB is free. Including non-PyTorch memory, this process has 41.92 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 40.97 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 55.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x12_y12_sh3_k6_l6_s12001.pddl,generation_error,,0.355,,"CUDA OOM: CUDA out of memory. Tried to allocate 26.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.12 GiB is free. Including non-PyTorch memory, this process has 52.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 51.64 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 94.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x13_y13_sh3_k6_l6_s13001.pddl,generation_error,,0.313,,"CUDA OOM: CUDA out of memory. Tried to allocate 35.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.43 GiB is free. Including non-PyTorch memory, this process has 31.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 30.34 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x14_y14_sh3_k6_l6_s14001.pddl,generation_error,,0.357,,"CUDA OOM: CUDA out of memory. Tried to allocate 46.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 19.71 GiB is free. Including non-PyTorch memory, this process has 37.03 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 36.08 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 63.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x15_y15_sh4_k8_l8_s15001.pddl,generation_error,,0.412,,"CUDA OOM: CUDA out of memory. Tried to allocate 61.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.88 GiB is free. Including non-PyTorch memory, this process has 44.87 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 43.89 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x16_y16_sh4_k8_l8_s16001.pddl,generation_error,,0.478,,"CUDA OOM: CUDA out of memory. Tried to allocate 78.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.05 GiB is free. Including non-PyTorch memory, this process has 53.69 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 52.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x17_y17_sh4_k8_l8_s17001.pddl,generation_error,,0.312,,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.64 GiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 94.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x18_y18_sh4_k8_l8_s18001.pddl,generation_error,,0.310,,"CUDA OOM: CUDA out of memory. Tried to allocate 61.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.15 GiB is free. Including non-PyTorch memory, this process has 15.59 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 14.57 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 125.67 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x19_y19_sh4_k8_l8_s19001.pddl,generation_error,,0.311,,"CUDA OOM: CUDA out of memory. Tried to allocate 76.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.65 GiB is free. Including non-PyTorch memory, this process has 16.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 15.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x20_y20_sh5_k10_l10_s20001.pddl,generation_error,,0.344,,"CUDA OOM: CUDA out of memory. Tried to allocate 92.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.02 GiB is free. Including non-PyTorch memory, this process has 16.72 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 15.74 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x21_y21_sh5_k10_l10_s21001.pddl,generation_error,,0.361,,"CUDA OOM: CUDA out of memory. Tried to allocate 112.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 39.36 GiB is free. Including non-PyTorch memory, this process has 17.38 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 16.44 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 60.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x22_y22_sh5_k10_l10_s22001.pddl,generation_error,,0.330,,"CUDA OOM: CUDA out of memory. Tried to allocate 132.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.50 GiB is free. Including non-PyTorch memory, this process has 18.24 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 17.24 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 119.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x23_y23_sh5_k10_l10_s23001.pddl,generation_error,,0.340,,"CUDA OOM: CUDA out of memory. Tried to allocate 160.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 37.60 GiB is free. Including non-PyTorch memory, this process has 19.14 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 18.16 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 95.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x24_y24_sh5_k10_l10_s24001.pddl,generation_error,,0.352,,"CUDA OOM: CUDA out of memory. Tried to allocate 188.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 36.60 GiB is free. Including non-PyTorch memory, this process has 20.14 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 19.14 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 106.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x25_y25_sh6_k12_l12_s25001.pddl,generation_error,,0.352,,"CUDA OOM: CUDA out of memory. Tried to allocate 220.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 35.43 GiB is free. Including non-PyTorch memory, this process has 21.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 20.32 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x26_y26_sh6_k12_l12_s26001.pddl,generation_error,,0.369,,"CUDA OOM: CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 34.12 GiB is free. Including non-PyTorch memory, this process has 22.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 21.65 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x27_y27_sh6_k12_l12_s27001.pddl,generation_error,,0.379,,"CUDA OOM: CUDA out of memory. Tried to allocate 296.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 32.72 GiB is free. Including non-PyTorch memory, this process has 24.03 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 23.02 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 113.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x28_y28_sh6_k12_l12_s28001.pddl,generation_error,,0.380,,"CUDA OOM: CUDA out of memory. Tried to allocate 344.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 31.10 GiB is free. Including non-PyTorch memory, this process has 25.65 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 24.66 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.85 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x29_y29_sh6_k12_l12_s29001.pddl,generation_error,,0.384,,"CUDA OOM: CUDA out of memory. Tried to allocate 392.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 29.49 GiB is free. Including non-PyTorch memory, this process has 27.25 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 26.28 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x30_y30_sh6_k12_l12_s30001.pddl,generation_error,,0.420,,"CUDA OOM: CUDA out of memory. Tried to allocate 448.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.58 GiB is free. Including non-PyTorch memory, this process has 29.16 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 28.18 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 93.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x31_y31_sh6_k12_l12_s31001.pddl,generation_error,,0.429,,"CUDA OOM: CUDA out of memory. Tried to allocate 512.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.31 GiB is free. Including non-PyTorch memory, this process has 31.43 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 102.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x32_y32_sh6_k12_l12_s32001.pddl,generation_error,,0.468,,"CUDA OOM: CUDA out of memory. Tried to allocate 592.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.93 GiB is free. Including non-PyTorch memory, this process has 33.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 32.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 85.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x33_y33_sh6_k12_l12_s33001.pddl,generation_error,,0.504,,"CUDA OOM: CUDA out of memory. Tried to allocate 656.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.47 GiB is free. Including non-PyTorch memory, this process has 36.27 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 35.29 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 100.03 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x34_y34_sh6_k12_l12_s34001.pddl,generation_error,,0.503,,"CUDA OOM: CUDA out of memory. Tried to allocate 736.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.81 GiB is free. Including non-PyTorch memory, this process has 38.93 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 37.94 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 106.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x35_y35_sh6_k12_l12_s35001.pddl,generation_error,,0.555,,"CUDA OOM: CUDA out of memory. Tried to allocate 832.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.88 GiB is free. Including non-PyTorch memory, this process has 41.86 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 40.85 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 120.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x36_y36_sh6_k12_l12_s36001.pddl,generation_error,,0.615,,"CUDA OOM: CUDA out of memory. Tried to allocate 928.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.74 GiB is free. Including non-PyTorch memory, this process has 44.98 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 94.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x37_y37_sh6_k12_l12_s37001.pddl,generation_error,,0.527,,"CUDA OOM: CUDA out of memory. Tried to allocate 1056.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.55 GiB is free. Including non-PyTorch memory, this process has 49.18 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 48.20 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 96.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x38_y38_sh6_k12_l12_s38001.pddl,generation_error,,0.484,,"CUDA OOM: CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.92 GiB is free. Including non-PyTorch memory, this process has 48.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 47.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 69.75 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x39_y39_sh6_k12_l12_s39001.pddl,generation_error,,0.361,,"CUDA OOM: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.93 GiB is free. Including non-PyTorch memory, this process has 52.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 51.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x3_y3_sh2_k4_l4_s3001.pddl,invalid,invalid,36.706,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan"
grid,grid_x40_y40_sh6_k12_l12_s40001.pddl,generation_error,,0.430,,"CUDA OOM: CUDA out of memory. Tried to allocate 11.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.92 GiB is free. Including non-PyTorch memory, this process has 45.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 44.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x41_y41_sh6_k12_l12_s41001.pddl,generation_error,,0.442,,"CUDA OOM: CUDA out of memory. Tried to allocate 12.25 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.17 GiB is free. Including non-PyTorch memory, this process has 49.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 48.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 60.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x42_y42_sh6_k12_l12_s42001.pddl,generation_error,,0.500,,"CUDA OOM: CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.42 GiB is free. Including non-PyTorch memory, this process has 53.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 52.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 60.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x43_y43_sh6_k12_l12_s43001.pddl,generation_error,,0.552,,"CUDA OOM: CUDA out of memory. Tried to allocate 29.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 29.17 GiB is free. Including non-PyTorch memory, this process has 27.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 26.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 69.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x44_y44_sh6_k12_l12_s44001.pddl,generation_error,,0.581,,"CUDA OOM: CUDA out of memory. Tried to allocate 33.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.43 GiB is free. Including non-PyTorch memory, this process has 29.30 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 28.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 57.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x45_y45_sh6_k12_l12_s45001.pddl,generation_error,,0.616,,"CUDA OOM: CUDA out of memory. Tried to allocate 36.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.94 GiB is free. Including non-PyTorch memory, this process has 30.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 29.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x46_y46_sh6_k12_l12_s46001.pddl,generation_error,,0.605,,"CUDA OOM: CUDA out of memory. Tried to allocate 39.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.44 GiB is free. Including non-PyTorch memory, this process has 32.30 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 31.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 58.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x47_y47_sh6_k12_l12_s47001.pddl,generation_error,,0.629,,"CUDA OOM: CUDA out of memory. Tried to allocate 42.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.93 GiB is free. Including non-PyTorch memory, this process has 33.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 32.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 62.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x48_y48_sh6_k12_l12_s48001.pddl,generation_error,,0.322,,"CUDA OOM: CUDA out of memory. Tried to allocate 23.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.94 GiB is free. Including non-PyTorch memory, this process has 35.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 34.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 52.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x49_y49_sh6_k12_l12_s49001.pddl,generation_error,,0.354,,"CUDA OOM: CUDA out of memory. Tried to allocate 25.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.95 GiB is free. Including non-PyTorch memory, this process has 37.79 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 36.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 44.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x4_y4_sh2_k4_l4_s4001.pddl,invalid,invalid,36.231,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan"
grid,grid_x50_y50_sh6_k12_l12_s50001.pddl,generation_error,,0.324,,"CUDA OOM: CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.94 GiB is free. Including non-PyTorch memory, this process has 39.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.91 GiB memory in use. Of the allocated memory 38.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 55.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x5_y5_sh2_k4_l4_s5001.pddl,invalid,invalid,36.408,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan"
grid,grid_x6_y6_sh2_k4_l4_s6001.pddl,invalid,invalid,37.233,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan"
grid,grid_x7_y7_sh2_k4_l4_s7001.pddl,invalid,invalid,37.230,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan"
grid,grid_x8_y8_sh2_k4_l4_s8001.pddl,invalid,invalid,39.335,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan"
grid,grid_x9_y9_sh2_k4_l4_s9001.pddl,invalid,invalid,40.535,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan"
delivery,delivery_size10_packages1_seed10001.pddl,invalid,invalid,40.200,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan"
delivery,delivery_size11_packages1_seed11001.pddl,invalid,invalid,41.893,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan"
delivery,delivery_size12_packages1_seed12001.pddl,generation_error,,0.312,,"CUDA OOM: CUDA out of memory. Tried to allocate 21.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.97 GiB is free. Including non-PyTorch memory, this process has 45.74 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 44.78 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 71.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size13_packages1_seed13001.pddl,generation_error,,0.266,,"CUDA OOM: CUDA out of memory. Tried to allocate 29.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.57 GiB is free. Including non-PyTorch memory, this process has 28.15 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 27.20 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 59.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size14_packages1_seed14001.pddl,generation_error,,0.310,,"CUDA OOM: CUDA out of memory. Tried to allocate 39.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.32 GiB is free. Including non-PyTorch memory, this process has 33.40 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 32.42 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size15_packages1_seed15001.pddl,generation_error,,0.348,,"CUDA OOM: CUDA out of memory. Tried to allocate 51.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.07 GiB is free. Including non-PyTorch memory, this process has 39.65 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 38.68 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size16_packages1_seed16001.pddl,generation_error,,0.402,,"CUDA OOM: CUDA out of memory. Tried to allocate 66.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 8.26 GiB is free. Including non-PyTorch memory, this process has 47.46 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 46.48 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size17_packages1_seed17001.pddl,generation_error,,0.300,,"CUDA OOM: CUDA out of memory. Tried to allocate 42.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.89 GiB is free. Including non-PyTorch memory, this process has 14.82 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 13.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 93.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size18_packages1_seed18001.pddl,generation_error,,0.292,,"CUDA OOM: CUDA out of memory. Tried to allocate 52.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.46 GiB is free. Including non-PyTorch memory, this process has 15.25 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 14.25 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 113.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size19_packages1_seed19001.pddl,generation_error,,0.292,,"CUDA OOM: CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.03 GiB is free. Including non-PyTorch memory, this process has 15.69 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 14.70 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 92.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size20_packages1_seed20001.pddl,generation_error,,0.299,,"CUDA OOM: CUDA out of memory. Tried to allocate 80.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 39.49 GiB is free. Including non-PyTorch memory, this process has 16.23 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 15.27 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 78.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size21_packages1_seed21001.pddl,generation_error,,0.296,,"CUDA OOM: CUDA out of memory. Tried to allocate 96.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.84 GiB is free. Including non-PyTorch memory, this process has 16.88 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 15.89 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size22_packages1_seed22001.pddl,generation_error,,0.314,,"CUDA OOM: CUDA out of memory. Tried to allocate 116.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.12 GiB is free. Including non-PyTorch memory, this process has 17.60 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 16.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 98.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size23_packages1_seed23001.pddl,generation_error,,0.315,,"CUDA OOM: CUDA out of memory. Tried to allocate 136.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 37.38 GiB is free. Including non-PyTorch memory, this process has 18.34 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 17.37 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.81 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size24_packages1_seed24001.pddl,generation_error,,0.315,,"CUDA OOM: CUDA out of memory. Tried to allocate 164.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 36.34 GiB is free. Including non-PyTorch memory, this process has 19.38 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 18.38 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 111.48 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size25_packages1_seed25001.pddl,generation_error,,0.429,,"CUDA OOM: CUDA out of memory. Tried to allocate 192.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 35.40 GiB is free. Including non-PyTorch memory, this process has 20.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 19.34 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 88.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size26_packages1_seed26001.pddl,generation_error,,0.329,,"CUDA OOM: CUDA out of memory. Tried to allocate 224.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 34.26 GiB is free. Including non-PyTorch memory, this process has 21.45 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 20.47 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 85.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size27_packages1_seed27001.pddl,generation_error,,0.369,,"CUDA OOM: CUDA out of memory. Tried to allocate 264.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 32.95 GiB is free. Including non-PyTorch memory, this process has 22.76 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 21.77 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 93.29 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size28_packages1_seed28001.pddl,generation_error,,0.365,,"CUDA OOM: CUDA out of memory. Tried to allocate 304.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 31.55 GiB is free. Including non-PyTorch memory, this process has 24.16 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 23.15 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 125.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size29_packages1_seed29001.pddl,generation_error,,0.375,,"CUDA OOM: CUDA out of memory. Tried to allocate 344.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 30.06 GiB is free. Including non-PyTorch memory, this process has 25.65 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 24.66 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 101.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size30_packages1_seed30001.pddl,generation_error,,0.393,,"CUDA OOM: CUDA out of memory. Tried to allocate 400.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.31 GiB is free. Including non-PyTorch memory, this process has 27.40 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 26.43 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 85.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size31_packages1_seed31001.pddl,generation_error,,0.458,,"CUDA OOM: CUDA out of memory. Tried to allocate 456.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 26.39 GiB is free. Including non-PyTorch memory, this process has 29.32 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 28.31 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 125.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size32_packages1_seed32001.pddl,generation_error,,0.461,,"CUDA OOM: CUDA out of memory. Tried to allocate 512.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.28 GiB is free. Including non-PyTorch memory, this process has 31.43 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 30.44 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 102.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size33_packages1_seed33001.pddl,generation_error,,0.472,,"CUDA OOM: CUDA out of memory. Tried to allocate 592.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 21.84 GiB is free. Including non-PyTorch memory, this process has 33.87 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 32.89 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 96.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size34_packages1_seed34001.pddl,generation_error,,0.463,,"CUDA OOM: CUDA out of memory. Tried to allocate 656.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 19.69 GiB is free. Including non-PyTorch memory, this process has 36.02 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 35.04 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 96.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size35_packages1_seed35001.pddl,generation_error,,0.524,,"CUDA OOM: CUDA out of memory. Tried to allocate 736.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.02 GiB is free. Including non-PyTorch memory, this process has 38.70 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 37.68 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 123.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size36_packages1_seed36001.pddl,generation_error,,0.568,,"CUDA OOM: CUDA out of memory. Tried to allocate 832.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 13.87 GiB is free. Including non-PyTorch memory, this process has 41.84 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 40.83 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 117.63 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size37_packages1_seed37001.pddl,generation_error,,0.622,,"CUDA OOM: CUDA out of memory. Tried to allocate 928.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 44.96 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 44.00 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 75.89 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size38_packages1_seed38001.pddl,generation_error,,0.560,,"CUDA OOM: CUDA out of memory. Tried to allocate 1024.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.02 GiB is free. Including non-PyTorch memory, this process has 48.70 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 47.70 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 109.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size39_packages1_seed39001.pddl,generation_error,,0.513,,"CUDA OOM: CUDA out of memory. Tried to allocate 9.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.90 GiB is free. Including non-PyTorch memory, this process has 48.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 47.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 69.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size3_packages1_seed3001.pddl,invalid,invalid,35.914,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan"
delivery,delivery_size40_packages1_seed40001.pddl,generation_error,,0.332,,"CUDA OOM: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 2.91 GiB is free. Including non-PyTorch memory, this process has 52.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 51.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size41_packages1_seed41001.pddl,generation_error,,0.439,,"CUDA OOM: CUDA out of memory. Tried to allocate 11.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.91 GiB is free. Including non-PyTorch memory, this process has 45.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 44.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size42_packages1_seed42001.pddl,generation_error,,0.454,,"CUDA OOM: CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.90 GiB is free. Including non-PyTorch memory, this process has 48.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 47.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 68.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size43_packages1_seed43001.pddl,generation_error,,0.481,,"CUDA OOM: CUDA out of memory. Tried to allocate 13.25 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.15 GiB is free. Including non-PyTorch memory, this process has 52.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 51.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 68.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size44_packages1_seed44001.pddl,generation_error,,0.524,,"CUDA OOM: CUDA out of memory. Tried to allocate 29.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.40 GiB is free. Including non-PyTorch memory, this process has 27.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 26.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 65.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size45_packages1_seed45001.pddl,generation_error,,0.550,,"CUDA OOM: CUDA out of memory. Tried to allocate 31.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.15 GiB is free. Including non-PyTorch memory, this process has 28.56 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 27.61 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 65.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size46_packages1_seed46001.pddl,generation_error,,0.539,,"CUDA OOM: CUDA out of memory. Tried to allocate 35.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.42 GiB is free. Including non-PyTorch memory, this process has 30.29 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 29.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 46.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size47_packages1_seed47001.pddl,generation_error,,0.560,,"CUDA OOM: CUDA out of memory. Tried to allocate 38.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 23.92 GiB is free. Including non-PyTorch memory, this process has 31.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 30.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 50.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size48_packages1_seed48001.pddl,generation_error,,0.577,,"CUDA OOM: CUDA out of memory. Tried to allocate 41.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.41 GiB is free. Including non-PyTorch memory, this process has 33.30 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 32.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size49_packages1_seed49001.pddl,generation_error,,0.321,,"CUDA OOM: CUDA out of memory. Tried to allocate 22.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.42 GiB is free. Including non-PyTorch memory, this process has 35.29 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 34.36 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 44.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size4_packages1_seed4001.pddl,invalid,invalid,35.889,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan"
delivery,delivery_size50_packages1_seed50001.pddl,generation_error,,0.318,,"CUDA OOM: CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.92 GiB is free. Including non-PyTorch memory, this process has 36.80 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 22.93 GiB memory in use. Of the allocated memory 35.86 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 48.12 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size5_packages1_seed5001.pddl,invalid,invalid,35.668,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan"
delivery,delivery_size6_packages1_seed6001.pddl,invalid,invalid,39.711,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan"
delivery,delivery_size7_packages1_seed7001.pddl,invalid,invalid,41.342,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan"
delivery,delivery_size8_packages1_seed8001.pddl,invalid,invalid,39.089,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan"
delivery,delivery_size9_packages1_seed9001.pddl,invalid,invalid,39.135,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan"
spanner,spanner-s10-n9-l15-s10001.pddl,invalid,invalid,95.138,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s10-n9-l15-s10001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s10-n9-l15-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s10-n9-l15-s10001.plan"
spanner,spanner-s11-n10-l16-s11001.pddl,invalid,invalid,83.030,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s11-n10-l16-s11001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s11-n10-l16-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s11-n10-l16-s11001.plan"
spanner,spanner-s12-n11-l18-s12001.pddl,invalid,invalid,84.159,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s12-n11-l18-s12001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s12-n11-l18-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s12-n11-l18-s12001.plan"
spanner,spanner-s13-n12-l19-s13001.pddl,invalid,invalid,79.210,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s13-n12-l19-s13001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s13-n12-l19-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s13-n12-l19-s13001.plan"
spanner,spanner-s14-n13-l21-s14001.pddl,invalid,invalid,78.504,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s14-n13-l21-s14001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s14-n13-l21-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s14-n13-l21-s14001.plan"
spanner,spanner-s15-n14-l22-s15001.pddl,invalid,invalid,74.856,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s15-n14-l22-s15001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s15-n14-l22-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s15-n14-l22-s15001.plan"
spanner,spanner-s16-n15-l24-s16001.pddl,invalid,invalid,76.775,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s16-n15-l24-s16001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s16-n15-l24-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s16-n15-l24-s16001.plan"
spanner,spanner-s17-n16-l25-s17001.pddl,invalid,invalid,70.438,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s17-n16-l25-s17001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s17-n16-l25-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s17-n16-l25-s17001.plan"
spanner,spanner-s18-n17-l27-s18001.pddl,invalid,invalid,58.565,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s18-n17-l27-s18001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s18-n17-l27-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s18-n17-l27-s18001.plan"
spanner,spanner-s19-n18-l28-s19001.pddl,invalid,invalid,53.601,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s19-n18-l28-s19001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s19-n18-l28-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s19-n18-l28-s19001.plan"
spanner,spanner-s20-n19-l30-s20001.pddl,invalid,invalid,55.978,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s20-n19-l30-s20001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s20-n19-l30-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s20-n19-l30-s20001.plan"
spanner,spanner-s21-n20-l31-s21001.pddl,invalid,invalid,54.901,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s21-n20-l31-s21001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s21-n20-l31-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s21-n20-l31-s21001.plan"
spanner,spanner-s22-n21-l33-s22001.pddl,invalid,invalid,57.520,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s22-n21-l33-s22001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s22-n21-l33-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s22-n21-l33-s22001.plan"
spanner,spanner-s23-n22-l34-s23001.pddl,invalid,invalid,55.997,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s23-n22-l34-s23001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s23-n22-l34-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s23-n22-l34-s23001.plan"
spanner,spanner-s24-n23-l36-s24001.pddl,invalid,invalid,60.110,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s24-n23-l36-s24001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s24-n23-l36-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s24-n23-l36-s24001.plan"
spanner,spanner-s25-n24-l37-s25001.pddl,invalid,invalid,56.714,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s25-n24-l37-s25001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s25-n24-l37-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s25-n24-l37-s25001.plan"
spanner,spanner-s26-n25-l39-s26001.pddl,invalid,invalid,55.168,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s26-n25-l39-s26001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s26-n25-l39-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s26-n25-l39-s26001.plan"
spanner,spanner-s27-n26-l40-s27001.pddl,invalid,invalid,56.788,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s27-n26-l40-s27001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s27-n26-l40-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s27-n26-l40-s27001.plan"
spanner,spanner-s28-n27-l42-s28001.pddl,invalid,invalid,56.275,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s28-n27-l42-s28001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s28-n27-l42-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s28-n27-l42-s28001.plan"
spanner,spanner-s29-n28-l43-s29001.pddl,invalid,invalid,57.337,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s29-n28-l43-s29001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s29-n28-l43-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s29-n28-l43-s29001.plan"
spanner,spanner-s3-n2-l5-s3001.pddl,invalid,invalid,57.600,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s3-n2-l5-s3001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s3-n2-l5-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s3-n2-l5-s3001.plan"
spanner,spanner-s30-n29-l45-s30001.pddl,invalid,invalid,59.941,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s30-n29-l45-s30001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s30-n29-l45-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s30-n29-l45-s30001.plan"
spanner,spanner-s4-n3-l6-s4001.pddl,invalid,invalid,56.146,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s4-n3-l6-s4001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s4-n3-l6-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s4-n3-l6-s4001.plan"
spanner,spanner-s5-n4-l7-s5001.pddl,invalid,invalid,59.278,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s5-n4-l7-s5001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s5-n4-l7-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s5-n4-l7-s5001.plan"
spanner,spanner-s6-n5-l9-s6001.pddl,invalid,invalid,59.301,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s6-n5-l9-s6001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s6-n5-l9-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s6-n5-l9-s6001.plan"
spanner,spanner-s7-n6-l10-s7001.pddl,invalid,invalid,57.604,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s7-n6-l10-s7001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s7-n6-l10-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s7-n6-l10-s7001.plan"
spanner,spanner-s8-n7-l12-s8001.pddl,invalid,invalid,58.178,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s8-n7-l12-s8001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s8-n7-l12-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s8-n7-l12-s8001.plan"
spanner,spanner-s9-n8-l13-s9001.pddl,invalid,invalid,58.729,Safety-gen/benchmark_problems/spanner/llm_results/spanner-s9-n8-l13-s9001.plan,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s9-n8-l13-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s9-n8-l13-s9001.plan"
blocksworld,bw_ops3_n03_seed3001.pddl,invalid,invalid,55.526,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n03_seed3001.plan"
blocksworld,bw_ops3_n04_seed4001.pddl,invalid,invalid,44.984,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n04_seed4001.plan"
blocksworld,bw_ops3_n05_seed5001.pddl,invalid,invalid,44.905,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n05_seed5001.plan"
blocksworld,bw_ops3_n06_seed6001.pddl,invalid,invalid,40.156,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n06_seed6001.plan"
blocksworld,bw_ops3_n07_seed7001.pddl,invalid,invalid,26.258,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n07_seed7001.plan"
blocksworld,bw_ops3_n08_seed8001.pddl,invalid,invalid,33.561,,Error: Bad operator in plan!
blocksworld,bw_ops3_n09_seed9001.pddl,invalid,invalid,44.504,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n09_seed9001.plan"
blocksworld,bw_ops3_n10_seed10001.pddl,invalid,invalid,44.385,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n10_seed10001.plan"
blocksworld,bw_ops3_n11_seed11001.pddl,invalid,invalid,44.100,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n11_seed11001.plan"
blocksworld,bw_ops3_n12_seed12001.pddl,invalid,invalid,44.925,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n12_seed12001.plan"
blocksworld,bw_ops3_n13_seed13001.pddl,invalid,invalid,44.489,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n13_seed13001.plan"
blocksworld,bw_ops3_n14_seed14001.pddl,invalid,invalid,44.443,,Error: Bad operator in plan!
blocksworld,bw_ops3_n15_seed15001.pddl,invalid,invalid,44.875,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n15_seed15001.plan"
blocksworld,bw_ops3_n16_seed16001.pddl,invalid,invalid,44.605,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n16_seed16001.plan"
blocksworld,bw_ops3_n17_seed17001.pddl,invalid,invalid,32.790,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n17_seed17001.plan"
blocksworld,bw_ops3_n18_seed18001.pddl,invalid,invalid,24.972,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n18_seed18001.plan"
blocksworld,bw_ops3_n19_seed19001.pddl,invalid,invalid,25.003,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n19_seed19001.plan"
blocksworld,bw_ops3_n20_seed20001.pddl,invalid,invalid,25.055,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n20_seed20001.plan"
blocksworld,bw_ops3_n21_seed21001.pddl,invalid,invalid,25.390,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n21_seed21001.plan"
blocksworld,bw_ops3_n22_seed22001.pddl,invalid,invalid,24.988,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n22_seed22001.plan"
blocksworld,bw_ops3_n23_seed23001.pddl,invalid,invalid,24.948,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n23_seed23001.plan"
blocksworld,bw_ops3_n24_seed24001.pddl,invalid,invalid,24.976,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n24_seed24001.plan"
blocksworld,bw_ops3_n25_seed25001.pddl,invalid,invalid,24.955,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n25_seed25001.plan"
blocksworld,bw_ops3_n26_seed26001.pddl,invalid,invalid,25.006,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n26_seed26001.plan"
blocksworld,bw_ops3_n27_seed27001.pddl,invalid,invalid,24.979,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n27_seed27001.plan"
blocksworld,bw_ops3_n28_seed28001.pddl,invalid,invalid,26.326,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n28_seed28001.plan"
blocksworld,bw_ops3_n29_seed29001.pddl,invalid,invalid,33.553,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n29_seed29001.plan"
blocksworld,bw_ops3_n30_seed30001.pddl,invalid,invalid,44.366,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n30_seed30001.plan"
blocksworld,bw_ops3_n31_seed31001.pddl,invalid,invalid,45.303,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n31_seed31001.plan"
blocksworld,bw_ops3_n32_seed32001.pddl,invalid,invalid,44.647,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n32_seed32001.plan"
blocksworld,bw_ops3_n33_seed33001.pddl,invalid,invalid,44.748,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n33_seed33001.plan"
blocksworld,bw_ops3_n34_seed34001.pddl,invalid,invalid,45.157,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n34_seed34001.plan"
blocksworld,bw_ops3_n35_seed35001.pddl,invalid,invalid,44.889,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n35_seed35001.plan"
blocksworld,bw_ops3_n36_seed36001.pddl,invalid,invalid,44.543,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n36_seed36001.plan"
blocksworld,bw_ops3_n37_seed37001.pddl,invalid,invalid,44.350,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n37_seed37001.plan"
blocksworld,bw_ops3_n38_seed38001.pddl,invalid,invalid,44.789,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n38_seed38001.plan"
blocksworld,bw_ops3_n39_seed39001.pddl,invalid,invalid,44.942,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n39_seed39001.plan"
blocksworld,bw_ops3_n40_seed40001.pddl,invalid,invalid,45.189,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n40_seed40001.plan"
blocksworld,bw_ops3_n41_seed41001.pddl,invalid,invalid,45.465,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n41_seed41001.plan"
blocksworld,bw_ops3_n42_seed42001.pddl,invalid,invalid,45.268,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n42_seed42001.plan"
blocksworld,bw_ops3_n43_seed43001.pddl,invalid,invalid,45.127,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n43_seed43001.plan"
blocksworld,bw_ops3_n44_seed44001.pddl,invalid,invalid,45.160,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n44_seed44001.plan"
blocksworld,bw_ops3_n45_seed45001.pddl,invalid,invalid,33.029,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n45_seed45001.plan"
blocksworld,bw_ops3_n46_seed46001.pddl,invalid,invalid,45.258,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n46_seed46001.plan"
blocksworld,bw_ops3_n47_seed47001.pddl,invalid,invalid,45.217,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n47_seed47001.plan"
blocksworld,bw_ops3_n48_seed48001.pddl,invalid,invalid,44.712,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n48_seed48001.plan"
blocksworld,bw_ops3_n49_seed49001.pddl,invalid,invalid,44.957,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n49_seed49001.plan"
blocksworld,bw_ops3_n50_seed50001.pddl,invalid,invalid,39.372,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/blocksworld/llm_results/bw_ops3_n50_seed50001.plan"
grippers,grippers-n1-r10-o8-s8001.pddl,invalid,invalid,44.312,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r10-o8-s8001.plan"
grippers,grippers-n1-r11-o9-s9001.pddl,invalid,invalid,44.455,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r11-o9-s9001.plan"
grippers,grippers-n1-r5-o3-s3001.pddl,invalid,invalid,26.482,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r5-o3-s3001.plan"
grippers,grippers-n1-r6-o4-s4001.pddl,invalid,invalid,37.864,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r6-o4-s4001.plan"
grippers,grippers-n1-r7-o5-s5001.pddl,invalid,invalid,44.310,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r7-o5-s5001.plan"
grippers,grippers-n1-r8-o6-s6001.pddl,invalid,invalid,44.392,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r8-o6-s6001.plan"
grippers,grippers-n1-r9-o7-s7001.pddl,invalid,invalid,43.901,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n1-r9-o7-s7001.plan"
grippers,grippers-n2-r12-o10-s10001.pddl,invalid,invalid,44.562,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r12-o10-s10001.plan"
grippers,grippers-n2-r13-o11-s11001.pddl,invalid,invalid,44.840,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r13-o11-s11001.plan"
grippers,grippers-n2-r14-o12-s12001.pddl,invalid,invalid,45.168,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r14-o12-s12001.plan"
grippers,grippers-n2-r15-o13-s13001.pddl,invalid,invalid,42.612,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r15-o13-s13001.plan"
grippers,grippers-n2-r16-o14-s14001.pddl,invalid,invalid,26.332,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r16-o14-s14001.plan"
grippers,grippers-n2-r17-o15-s15001.pddl,invalid,invalid,33.032,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r17-o15-s15001.plan"
grippers,grippers-n2-r18-o16-s16001.pddl,invalid,invalid,44.715,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r18-o16-s16001.plan"
grippers,grippers-n2-r19-o17-s17001.pddl,invalid,invalid,44.682,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r19-o17-s17001.plan"
grippers,grippers-n2-r20-o18-s18001.pddl,invalid,invalid,44.720,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r20-o18-s18001.plan"
grippers,grippers-n2-r21-o19-s19001.pddl,invalid,invalid,45.250,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n2-r21-o19-s19001.plan"
grippers,grippers-n3-r22-o20-s20001.pddl,invalid,invalid,44.758,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r22-o20-s20001.plan"
grippers,grippers-n3-r23-o21-s21001.pddl,invalid,invalid,45.146,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r23-o21-s21001.plan"
grippers,grippers-n3-r24-o22-s22001.pddl,invalid,invalid,45.074,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r24-o22-s22001.plan"
grippers,grippers-n3-r25-o23-s23001.pddl,invalid,invalid,44.814,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r25-o23-s23001.plan"
grippers,grippers-n3-r26-o24-s24001.pddl,invalid,invalid,35.413,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r26-o24-s24001.plan"
grippers,grippers-n3-r27-o25-s25001.pddl,invalid,invalid,26.934,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r27-o25-s25001.plan"
grippers,grippers-n3-r28-o26-s26001.pddl,invalid,invalid,41.430,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r28-o26-s26001.plan"
grippers,grippers-n3-r29-o27-s27001.pddl,invalid,invalid,45.107,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r29-o27-s27001.plan"
grippers,grippers-n3-r30-o28-s28001.pddl,invalid,invalid,45.108,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r30-o28-s28001.plan"
grippers,grippers-n3-r31-o29-s29001.pddl,invalid,invalid,45.116,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r31-o29-s29001.plan"
grippers,grippers-n3-r32-o30-s30001.pddl,invalid,invalid,45.004,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r32-o30-s30001.plan"
grippers,grippers-n3-r33-o31-s31001.pddl,invalid,invalid,45.560,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r33-o31-s31001.plan"
grippers,grippers-n3-r34-o32-s32001.pddl,invalid,invalid,45.384,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r34-o32-s32001.plan"
grippers,grippers-n3-r35-o33-s33001.pddl,invalid,invalid,45.198,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r35-o33-s33001.plan"
grippers,grippers-n3-r36-o34-s34001.pddl,invalid,invalid,45.354,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r36-o34-s34001.plan"
grippers,grippers-n3-r37-o35-s35001.pddl,invalid,invalid,45.025,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r37-o35-s35001.plan"
grippers,grippers-n3-r38-o36-s36001.pddl,invalid,invalid,34.565,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r38-o36-s36001.plan"
grippers,grippers-n3-r39-o37-s37001.pddl,invalid,invalid,25.104,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r39-o37-s37001.plan"
grippers,grippers-n3-r40-o38-s38001.pddl,invalid,invalid,25.123,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r40-o38-s38001.plan"
grippers,grippers-n3-r41-o39-s39001.pddl,invalid,invalid,25.138,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r41-o39-s39001.plan"
grippers,grippers-n3-r42-o40-s40001.pddl,invalid,invalid,25.140,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r42-o40-s40001.plan"
grippers,grippers-n3-r43-o41-s41001.pddl,invalid,invalid,25.561,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r43-o41-s41001.plan"
grippers,grippers-n3-r44-o42-s42001.pddl,invalid,invalid,25.113,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r44-o42-s42001.plan"
grippers,grippers-n3-r45-o43-s43001.pddl,invalid,invalid,25.182,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r45-o43-s43001.plan"
grippers,grippers-n3-r46-o44-s44001.pddl,invalid,invalid,25.221,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r46-o44-s44001.plan"
grippers,grippers-n3-r47-o45-s45001.pddl,invalid,invalid,26.014,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r47-o45-s45001.plan"
grippers,grippers-n3-r48-o46-s46001.pddl,invalid,invalid,25.941,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r48-o46-s46001.plan"
grippers,grippers-n3-r49-o47-s47001.pddl,invalid,invalid,25.315,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r49-o47-s47001.plan"
grippers,grippers-n3-r50-o48-s48001.pddl,invalid,invalid,25.888,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r50-o48-s48001.plan"
grippers,grippers-n3-r51-o49-s49001.pddl,invalid,invalid,25.301,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r51-o49-s49001.plan"
grippers,grippers-n3-r52-o50-s50001.pddl,invalid,invalid,25.575,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grippers/llm_results/grippers-n3-r52-o50-s50001.plan"
ferry,ferry-l03-c02-s3001.pddl,invalid,invalid,24.849,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l03-c02-s3001.plan"
ferry,ferry-l04-c03-s4001.pddl,invalid,invalid,24.883,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l04-c03-s4001.plan"
ferry,ferry-l05-c03-s5001.pddl,invalid,invalid,24.926,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l05-c03-s5001.plan"
ferry,ferry-l06-c04-s6001.pddl,invalid,invalid,25.010,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l06-c04-s6001.plan"
ferry,ferry-l07-c04-s7001.pddl,invalid,invalid,25.068,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l07-c04-s7001.plan"
ferry,ferry-l08-c05-s8001.pddl,invalid,invalid,25.370,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l08-c05-s8001.plan"
ferry,ferry-l09-c05-s9001.pddl,invalid,invalid,25.260,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l09-c05-s9001.plan"
ferry,ferry-l10-c06-s10001.pddl,invalid,invalid,25.270,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l10-c06-s10001.plan"
ferry,ferry-l11-c06-s11001.pddl,invalid,invalid,25.322,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l11-c06-s11001.plan"
ferry,ferry-l12-c07-s12001.pddl,invalid,invalid,25.857,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l12-c07-s12001.plan"
ferry,ferry-l13-c07-s13001.pddl,invalid,invalid,25.595,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l13-c07-s13001.plan"
ferry,ferry-l14-c08-s14001.pddl,invalid,invalid,25.702,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l14-c08-s14001.plan"
ferry,ferry-l15-c08-s15001.pddl,invalid,invalid,25.877,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l15-c08-s15001.plan"
ferry,ferry-l16-c09-s16001.pddl,invalid,invalid,26.089,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l16-c09-s16001.plan"
ferry,ferry-l17-c09-s17001.pddl,invalid,invalid,26.227,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l17-c09-s17001.plan"
ferry,ferry-l18-c10-s18001.pddl,invalid,invalid,26.354,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l18-c10-s18001.plan"
ferry,ferry-l19-c10-s19001.pddl,invalid,invalid,26.533,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l19-c10-s19001.plan"
ferry,ferry-l20-c11-s20001.pddl,invalid,invalid,26.862,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l20-c11-s20001.plan"
ferry,ferry-l21-c11-s21001.pddl,invalid,invalid,27.489,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l21-c11-s21001.plan"
ferry,ferry-l22-c12-s22001.pddl,invalid,invalid,27.573,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l22-c12-s22001.plan"
ferry,ferry-l23-c12-s23001.pddl,invalid,invalid,27.774,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l23-c12-s23001.plan"
ferry,ferry-l24-c13-s24001.pddl,invalid,invalid,28.091,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l24-c13-s24001.plan"
ferry,ferry-l25-c13-s25001.pddl,invalid,invalid,28.675,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l25-c13-s25001.plan"
ferry,ferry-l26-c14-s26001.pddl,invalid,invalid,30.879,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l26-c14-s26001.plan"
ferry,ferry-l27-c14-s27001.pddl,invalid,invalid,29.955,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l27-c14-s27001.plan"
ferry,ferry-l28-c15-s28001.pddl,invalid,invalid,32.227,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l28-c15-s28001.plan"
ferry,ferry-l29-c15-s29001.pddl,invalid,invalid,41.137,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l29-c15-s29001.plan"
ferry,ferry-l30-c16-s30001.pddl,invalid,invalid,42.369,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/ferry/llm_results/ferry-l30-c16-s30001.plan"
ferry,ferry-l31-c16-s31001.pddl,generation_error,,0.723,,"CUDA OOM: CUDA out of memory. Tried to allocate 18.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.02 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 40.24 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l32-c17-s32001.pddl,generation_error,,0.286,,"CUDA OOM: CUDA out of memory. Tried to allocate 19.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.56 GiB is free. Including non-PyTorch memory, this process has 42.68 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 41.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 54.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l33-c17-s33001.pddl,generation_error,,0.298,,"CUDA OOM: CUDA out of memory. Tried to allocate 22.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 10.75 GiB is free. Including non-PyTorch memory, this process has 46.49 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 45.54 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 59.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l34-c18-s34001.pddl,generation_error,,0.315,,"CUDA OOM: CUDA out of memory. Tried to allocate 24.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.92 GiB is free. Including non-PyTorch memory, this process has 50.31 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 49.35 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l35-c18-s35001.pddl,generation_error,,0.335,,"CUDA OOM: CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.13 GiB is free. Including non-PyTorch memory, this process has 54.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 53.16 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 51.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l36-c19-s36001.pddl,generation_error,,0.215,,"CUDA OOM: CUDA out of memory. Tried to allocate 30.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.56 GiB is free. Including non-PyTorch memory, this process has 28.67 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 27.73 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.38 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l37-c19-s37001.pddl,generation_error,,0.300,,"CUDA OOM: CUDA out of memory. Tried to allocate 34.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 26.49 GiB is free. Including non-PyTorch memory, this process has 30.74 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 29.81 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 42.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l38-c20-s38001.pddl,generation_error,,0.320,,"CUDA OOM: CUDA out of memory. Tried to allocate 37.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 24.91 GiB is free. Including non-PyTorch memory, this process has 32.33 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 31.39 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 48.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l39-c20-s39001.pddl,generation_error,,0.332,,"CUDA OOM: CUDA out of memory. Tried to allocate 41.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 22.82 GiB is free. Including non-PyTorch memory, this process has 34.42 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 33.47 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 53.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l40-c21-s40001.pddl,generation_error,,0.346,,"CUDA OOM: CUDA out of memory. Tried to allocate 45.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.71 GiB is free. Including non-PyTorch memory, this process has 36.53 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 35.56 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l41-c21-s41001.pddl,generation_error,,0.372,,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.62 GiB is free. Including non-PyTorch memory, this process has 38.62 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 37.64 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 82.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l42-c22-s42001.pddl,generation_error,,0.392,,"CUDA OOM: CUDA out of memory. Tried to allocate 54.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 16.02 GiB is free. Including non-PyTorch memory, this process has 41.21 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 40.25 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 77.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l43-c22-s43001.pddl,generation_error,,0.401,,"CUDA OOM: CUDA out of memory. Tried to allocate 59.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 13.42 GiB is free. Including non-PyTorch memory, this process has 43.81 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 42.85 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 73.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l44-c23-s44001.pddl,generation_error,,0.421,,"CUDA OOM: CUDA out of memory. Tried to allocate 66.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.77 GiB is free. Including non-PyTorch memory, this process has 47.46 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 46.48 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 89.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l45-c23-s45001.pddl,generation_error,,0.441,,"CUDA OOM: CUDA out of memory. Tried to allocate 70.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.68 GiB is free. Including non-PyTorch memory, this process has 49.55 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 48.57 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 91.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l46-c24-s46001.pddl,generation_error,,0.467,,"CUDA OOM: CUDA out of memory. Tried to allocate 76.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.58 GiB is free. Including non-PyTorch memory, this process has 52.66 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.42 GiB memory in use. Of the allocated memory 51.71 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 61.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l47-c24-s47001.pddl,generation_error,,0.547,,"CUDA OOM: CUDA out of memory. Tried to allocate 84.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 307.81 MiB is free. Including non-PyTorch memory, this process has 56.82 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 55.84 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 84.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l48-c25-s48001.pddl,generation_error,,0.328,,"CUDA OOM: CUDA out of memory. Tried to allocate 45.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 42.16 GiB is free. Including non-PyTorch memory, this process has 14.96 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 13.96 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 109.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l49-c25-s49001.pddl,generation_error,,0.301,,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 42.02 GiB is free. Including non-PyTorch memory, this process has 15.10 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 14.12 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 92.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
ferry,ferry-l50-c26-s50001.pddl,generation_error,,0.307,,"CUDA OOM: CUDA out of memory. Tried to allocate 53.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.88 GiB is free. Including non-PyTorch memory, this process has 15.24 GiB memory in use. Process 294544 has 448.00 MiB memory in use. Process 335957 has 21.53 GiB memory in use. Of the allocated memory 14.27 GiB is allocated by PyTorch, with 110.00 MiB allocated in private pools (e.g., CUDA Graphs), and 76.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x10_y10_sh3_k6_l6_s10001.pddl,invalid,invalid,42.284,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x10_y10_sh3_k6_l6_s10001.plan"
grid,grid_x11_y11_sh3_k6_l6_s11001.pddl,generation_error,,2.943,Safety-gen/benchmark_problems/grid/llm_results/grid_x11_y11_sh3_k6_l6_s11001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 19.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 15.02 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 41.58 GiB memory in use. Of the allocated memory 40.86 GiB is allocated by PyTorch, and 73.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x12_y12_sh3_k6_l6_s12001.pddl,generation_error,,0.483,Safety-gen/benchmark_problems/grid/llm_results/grid_x12_y12_sh3_k6_l6_s12001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 26.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.38 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 52.23 GiB memory in use. Of the allocated memory 51.53 GiB is allocated by PyTorch, and 52.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x13_y13_sh3_k6_l6_s13001.pddl,generation_error,,0.295,Safety-gen/benchmark_problems/grid/llm_results/grid_x13_y13_sh3_k6_l6_s13001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 35.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.65 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 30.96 GiB memory in use. Of the allocated memory 30.24 GiB is allocated by PyTorch, and 74.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x14_y14_sh3_k6_l6_s14001.pddl,generation_error,,0.349,Safety-gen/benchmark_problems/grid/llm_results/grid_x14_y14_sh3_k6_l6_s14001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 46.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 19.93 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 36.68 GiB memory in use. Of the allocated memory 35.97 GiB is allocated by PyTorch, and 61.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x15_y15_sh4_k8_l8_s15001.pddl,generation_error,,0.395,Safety-gen/benchmark_problems/grid/llm_results/grid_x15_y15_sh4_k8_l8_s15001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 61.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 12.09 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 44.51 GiB memory in use. Of the allocated memory 43.78 GiB is allocated by PyTorch, and 86.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x16_y16_sh4_k8_l8_s16001.pddl,generation_error,,0.453,Safety-gen/benchmark_problems/grid/llm_results/grid_x16_y16_sh4_k8_l8_s16001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 78.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.31 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 53.30 GiB memory in use. Of the allocated memory 52.62 GiB is allocated by PyTorch, and 34.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x17_y17_sh4_k8_l8_s17001.pddl,generation_error,,0.311,Safety-gen/benchmark_problems/grid/llm_results/grid_x17_y17_sh4_k8_l8_s17001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 49.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.90 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 14.71 GiB memory in use. Of the allocated memory 14.01 GiB is allocated by PyTorch, and 50.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x18_y18_sh4_k8_l8_s18001.pddl,generation_error,,0.307,Safety-gen/benchmark_problems/grid/llm_results/grid_x18_y18_sh4_k8_l8_s18001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 61.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.39 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 15.21 GiB memory in use. Of the allocated memory 14.47 GiB is allocated by PyTorch, and 103.74 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x19_y19_sh4_k8_l8_s19001.pddl,generation_error,,0.310,Safety-gen/benchmark_problems/grid/llm_results/grid_x19_y19_sh4_k8_l8_s19001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 76.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.86 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 15.74 GiB memory in use. Of the allocated memory 15.01 GiB is allocated by PyTorch, and 89.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x20_y20_sh5_k10_l10_s20001.pddl,generation_error,,0.324,Safety-gen/benchmark_problems/grid/llm_results/grid_x20_y20_sh5_k10_l10_s20001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 92.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.24 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 16.37 GiB memory in use. Of the allocated memory 15.64 GiB is allocated by PyTorch, and 86.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x21_y21_sh5_k10_l10_s21001.pddl,generation_error,,0.329,Safety-gen/benchmark_problems/grid/llm_results/grid_x21_y21_sh5_k10_l10_s21001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 112.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 39.55 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 17.05 GiB memory in use. Of the allocated memory 16.33 GiB is allocated by PyTorch, and 78.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x22_y22_sh5_k10_l10_s22001.pddl,generation_error,,0.336,Safety-gen/benchmark_problems/grid/llm_results/grid_x22_y22_sh5_k10_l10_s22001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 132.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.75 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 17.85 GiB memory in use. Of the allocated memory 17.13 GiB is allocated by PyTorch, and 77.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x23_y23_sh5_k10_l10_s23001.pddl,generation_error,,0.451,Safety-gen/benchmark_problems/grid/llm_results/grid_x23_y23_sh5_k10_l10_s23001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 160.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 37.84 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 18.77 GiB memory in use. Of the allocated memory 18.05 GiB is allocated by PyTorch, and 73.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x24_y24_sh5_k10_l10_s24001.pddl,generation_error,,0.348,Safety-gen/benchmark_problems/grid/llm_results/grid_x24_y24_sh5_k10_l10_s24001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 188.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 36.84 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 19.77 GiB memory in use. Of the allocated memory 19.04 GiB is allocated by PyTorch, and 84.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x25_y25_sh6_k12_l12_s25001.pddl,generation_error,,0.355,Safety-gen/benchmark_problems/grid/llm_results/grid_x25_y25_sh6_k12_l12_s25001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 220.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 35.69 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 20.92 GiB memory in use. Of the allocated memory 20.21 GiB is allocated by PyTorch, and 59.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x26_y26_sh6_k12_l12_s26001.pddl,generation_error,,0.368,Safety-gen/benchmark_problems/grid/llm_results/grid_x26_y26_sh6_k12_l12_s26001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 256.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 34.36 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 22.25 GiB memory in use. Of the allocated memory 21.54 GiB is allocated by PyTorch, and 62.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x27_y27_sh6_k12_l12_s27001.pddl,generation_error,,0.378,Safety-gen/benchmark_problems/grid/llm_results/grid_x27_y27_sh6_k12_l12_s27001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 296.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 32.97 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 23.63 GiB memory in use. Of the allocated memory 22.92 GiB is allocated by PyTorch, and 71.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x28_y28_sh6_k12_l12_s28001.pddl,generation_error,,0.390,Safety-gen/benchmark_problems/grid/llm_results/grid_x28_y28_sh6_k12_l12_s28001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 344.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 31.35 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 25.25 GiB memory in use. Of the allocated memory 24.55 GiB is allocated by PyTorch, and 59.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x29_y29_sh6_k12_l12_s29001.pddl,generation_error,,0.415,Safety-gen/benchmark_problems/grid/llm_results/grid_x29_y29_sh6_k12_l12_s29001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 392.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 29.71 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 26.89 GiB memory in use. Of the allocated memory 26.17 GiB is allocated by PyTorch, and 75.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x30_y30_sh6_k12_l12_s30001.pddl,generation_error,,0.441,Safety-gen/benchmark_problems/grid/llm_results/grid_x30_y30_sh6_k12_l12_s30001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 448.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.82 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 28.79 GiB memory in use. Of the allocated memory 28.07 GiB is allocated by PyTorch, and 71.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x31_y31_sh6_k12_l12_s31001.pddl,generation_error,,0.453,Safety-gen/benchmark_problems/grid/llm_results/grid_x31_y31_sh6_k12_l12_s31001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 512.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.53 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 31.07 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 98.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x32_y32_sh6_k12_l12_s32001.pddl,generation_error,,0.480,Safety-gen/benchmark_problems/grid/llm_results/grid_x32_y32_sh6_k12_l12_s32001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 592.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 23.17 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 33.44 GiB memory in use. Of the allocated memory 32.73 GiB is allocated by PyTorch, and 63.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x33_y33_sh6_k12_l12_s33001.pddl,generation_error,,0.521,Safety-gen/benchmark_problems/grid/llm_results/grid_x33_y33_sh6_k12_l12_s33001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 656.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.68 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 35.92 GiB memory in use. Of the allocated memory 35.18 GiB is allocated by PyTorch, and 98.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x34_y34_sh6_k12_l12_s34001.pddl,generation_error,,0.505,Safety-gen/benchmark_problems/grid/llm_results/grid_x34_y34_sh6_k12_l12_s34001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 736.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.05 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 38.56 GiB memory in use. Of the allocated memory 37.83 GiB is allocated by PyTorch, and 84.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x35_y35_sh6_k12_l12_s35001.pddl,generation_error,,0.536,Safety-gen/benchmark_problems/grid/llm_results/grid_x35_y35_sh6_k12_l12_s35001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 832.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 15.16 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 41.45 GiB memory in use. Of the allocated memory 40.74 GiB is allocated by PyTorch, and 58.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x36_y36_sh6_k12_l12_s36001.pddl,generation_error,,0.604,Safety-gen/benchmark_problems/grid/llm_results/grid_x36_y36_sh6_k12_l12_s36001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 928.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.99 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 44.61 GiB memory in use. Of the allocated memory 43.89 GiB is allocated by PyTorch, and 72.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x37_y37_sh6_k12_l12_s37001.pddl,generation_error,,0.664,Safety-gen/benchmark_problems/grid/llm_results/grid_x37_y37_sh6_k12_l12_s37001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 1056.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.81 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 48.79 GiB memory in use. Of the allocated memory 48.09 GiB is allocated by PyTorch, and 54.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x38_y38_sh6_k12_l12_s38001.pddl,generation_error,,0.711,Safety-gen/benchmark_problems/grid/llm_results/grid_x38_y38_sh6_k12_l12_s38001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.15 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 39.46 GiB memory in use. Of the allocated memory 38.75 GiB is allocated by PyTorch, and 62.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x39_y39_sh6_k12_l12_s39001.pddl,generation_error,,0.723,Safety-gen/benchmark_problems/grid/llm_results/grid_x39_y39_sh6_k12_l12_s39001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 42.42 GiB memory in use. Of the allocated memory 41.75 GiB is allocated by PyTorch, and 30.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x3_y3_sh2_k4_l4_s3001.pddl,invalid,invalid,36.706,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x3_y3_sh2_k4_l4_s3001.plan"
grid,grid_x40_y40_sh6_k12_l12_s40001.pddl,generation_error,,0.753,Safety-gen/benchmark_problems/grid/llm_results/grid_x40_y40_sh6_k12_l12_s40001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 22.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.15 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 45.45 GiB memory in use. Of the allocated memory 44.75 GiB is allocated by PyTorch, and 58.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x41_y41_sh6_k12_l12_s41001.pddl,generation_error,,0.654,Safety-gen/benchmark_problems/grid/llm_results/grid_x41_y41_sh6_k12_l12_s41001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 12.25 GiB. GPU 0 has a total capacity of 79.11 GiB of which 7.40 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 49.20 GiB memory in use. Of the allocated memory 48.50 GiB is allocated by PyTorch, and 58.82 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x42_y42_sh6_k12_l12_s42001.pddl,generation_error,,0.617,Safety-gen/benchmark_problems/grid/llm_results/grid_x42_y42_sh6_k12_l12_s42001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 13.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.65 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 52.95 GiB memory in use. Of the allocated memory 52.25 GiB is allocated by PyTorch, and 58.50 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x43_y43_sh6_k12_l12_s43001.pddl,generation_error,,0.440,Safety-gen/benchmark_problems/grid/llm_results/grid_x43_y43_sh6_k12_l12_s43001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 14.75 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.65 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 41.96 GiB memory in use. Of the allocated memory 41.25 GiB is allocated by PyTorch, and 62.30 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x44_y44_sh6_k12_l12_s44001.pddl,generation_error,,0.427,Safety-gen/benchmark_problems/grid/llm_results/grid_x44_y44_sh6_k12_l12_s44001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 16.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 12.17 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 44.44 GiB memory in use. Of the allocated memory 43.75 GiB is allocated by PyTorch, and 43.98 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x45_y45_sh6_k12_l12_s45001.pddl,generation_error,,0.444,Safety-gen/benchmark_problems/grid/llm_results/grid_x45_y45_sh6_k12_l12_s45001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 17.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 47.42 GiB memory in use. Of the allocated memory 46.75 GiB is allocated by PyTorch, and 23.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x46_y46_sh6_k12_l12_s46001.pddl,generation_error,,0.255,Safety-gen/benchmark_problems/grid/llm_results/grid_x46_y46_sh6_k12_l12_s46001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 19.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 5.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 51.42 GiB memory in use. Of the allocated memory 50.75 GiB is allocated by PyTorch, and 27.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x47_y47_sh6_k12_l12_s47001.pddl,generation_error,,0.264,Safety-gen/benchmark_problems/grid/llm_results/grid_x47_y47_sh6_k12_l12_s47001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 21.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 2.17 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 54.43 GiB memory in use. Of the allocated memory 53.75 GiB is allocated by PyTorch, and 34.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x48_y48_sh6_k12_l12_s48001.pddl,generation_error,,0.500,Safety-gen/benchmark_problems/grid/llm_results/grid_x48_y48_sh6_k12_l12_s48001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 23.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 21.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 35.43 GiB memory in use. Of the allocated memory 34.75 GiB is allocated by PyTorch, and 30.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x49_y49_sh6_k12_l12_s49001.pddl,generation_error,,0.330,Safety-gen/benchmark_problems/grid/llm_results/grid_x49_y49_sh6_k12_l12_s49001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 25.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 19.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 37.42 GiB memory in use. Of the allocated memory 36.75 GiB is allocated by PyTorch, and 22.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x4_y4_sh2_k4_l4_s4001.pddl,invalid,invalid,36.231,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x4_y4_sh2_k4_l4_s4001.plan"
grid,grid_x50_y50_sh6_k12_l12_s50001.pddl,generation_error,,0.324,Safety-gen/benchmark_problems/grid/llm_results/grid_x50_y50_sh6_k12_l12_s50001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 27.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.17 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 39.43 GiB memory in use. Of the allocated memory 38.75 GiB is allocated by PyTorch, and 33.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
grid,grid_x5_y5_sh2_k4_l4_s5001.pddl,invalid,invalid,36.408,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x5_y5_sh2_k4_l4_s5001.plan"
grid,grid_x6_y6_sh2_k4_l4_s6001.pddl,invalid,invalid,37.233,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x6_y6_sh2_k4_l4_s6001.plan"
grid,grid_x7_y7_sh2_k4_l4_s7001.pddl,invalid,invalid,37.230,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x7_y7_sh2_k4_l4_s7001.plan"
grid,grid_x8_y8_sh2_k4_l4_s8001.pddl,invalid,invalid,39.335,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x8_y8_sh2_k4_l4_s8001.plan"
grid,grid_x9_y9_sh2_k4_l4_s9001.pddl,invalid,invalid,40.535,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/grid/llm_results/grid_x9_y9_sh2_k4_l4_s9001.plan"
delivery,delivery_size10_packages1_seed10001.pddl,invalid,invalid,40.200,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size10_packages1_seed10001.plan"
delivery,delivery_size11_packages1_seed11001.pddl,invalid,invalid,41.893,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size11_packages1_seed11001.plan"
delivery,delivery_size12_packages1_seed12001.pddl,generation_error,,0.303,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size12_packages1_seed12001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 21.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.21 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 45.39 GiB memory in use. Of the allocated memory 44.68 GiB is allocated by PyTorch, and 69.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size13_packages1_seed13001.pddl,generation_error,,0.297,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size13_packages1_seed13001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 29.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 28.83 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 27.77 GiB memory in use. Of the allocated memory 27.09 GiB is allocated by PyTorch, and 37.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size14_packages1_seed14001.pddl,generation_error,,0.335,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size14_packages1_seed14001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 39.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 23.56 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 33.05 GiB memory in use. Of the allocated memory 32.31 GiB is allocated by PyTorch, and 89.21 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size15_packages1_seed15001.pddl,generation_error,,0.378,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size15_packages1_seed15001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 51.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.31 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 39.30 GiB memory in use. Of the allocated memory 38.58 GiB is allocated by PyTorch, and 75.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size16_packages1_seed16001.pddl,generation_error,,0.401,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size16_packages1_seed16001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 66.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.52 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 47.09 GiB memory in use. Of the allocated memory 46.38 GiB is allocated by PyTorch, and 66.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size17_packages1_seed17001.pddl,generation_error,,0.472,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size17_packages1_seed17001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 84.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 165.38 MiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 56.44 GiB memory in use. Of the allocated memory 55.74 GiB is allocated by PyTorch, and 63.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size18_packages1_seed18001.pddl,generation_error,,0.306,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size18_packages1_seed18001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 52.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.74 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 14.86 GiB memory in use. Of the allocated memory 14.14 GiB is allocated by PyTorch, and 71.66 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size19_packages1_seed19001.pddl,generation_error,,0.300,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size19_packages1_seed19001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 64.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 41.29 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 15.31 GiB memory in use. Of the allocated memory 14.60 GiB is allocated by PyTorch, and 70.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size20_packages1_seed20001.pddl,generation_error,,0.304,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size20_packages1_seed20001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 80.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.75 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 15.86 GiB memory in use. Of the allocated memory 15.16 GiB is allocated by PyTorch, and 56.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size21_packages1_seed21001.pddl,generation_error,,0.321,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size21_packages1_seed21001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 96.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 40.10 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 16.50 GiB memory in use. Of the allocated memory 15.78 GiB is allocated by PyTorch, and 79.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size22_packages1_seed22001.pddl,generation_error,,0.323,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size22_packages1_seed22001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 116.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 39.36 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 17.25 GiB memory in use. Of the allocated memory 16.51 GiB is allocated by PyTorch, and 96.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size23_packages1_seed23001.pddl,generation_error,,0.337,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size23_packages1_seed23001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 136.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 38.60 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 18.01 GiB memory in use. Of the allocated memory 17.26 GiB is allocated by PyTorch, and 102.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size24_packages1_seed24001.pddl,generation_error,,0.341,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size24_packages1_seed24001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 164.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 37.62 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 18.98 GiB memory in use. Of the allocated memory 18.27 GiB is allocated by PyTorch, and 69.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size25_packages1_seed25001.pddl,generation_error,,0.350,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size25_packages1_seed25001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 192.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 36.64 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 19.96 GiB memory in use. Of the allocated memory 19.23 GiB is allocated by PyTorch, and 86.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size26_packages1_seed26001.pddl,generation_error,,0.473,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size26_packages1_seed26001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 224.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 35.55 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 21.05 GiB memory in use. Of the allocated memory 20.37 GiB is allocated by PyTorch, and 43.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size27_packages1_seed27001.pddl,generation_error,,0.374,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size27_packages1_seed27001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 264.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 34.24 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 22.36 GiB memory in use. Of the allocated memory 21.67 GiB is allocated by PyTorch, and 51.36 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size28_packages1_seed28001.pddl,generation_error,,0.380,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size28_packages1_seed28001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 304.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 32.85 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 23.75 GiB memory in use. Of the allocated memory 23.04 GiB is allocated by PyTorch, and 63.22 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size29_packages1_seed29001.pddl,generation_error,,0.401,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size29_packages1_seed29001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 344.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 31.35 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 25.25 GiB memory in use. Of the allocated memory 24.55 GiB is allocated by PyTorch, and 59.37 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size30_packages1_seed30001.pddl,generation_error,,0.419,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size30_packages1_seed30001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 400.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 29.57 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 27.03 GiB memory in use. Of the allocated memory 26.32 GiB is allocated by PyTorch, and 63.26 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size31_packages1_seed31001.pddl,generation_error,,0.437,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size31_packages1_seed31001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 456.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 27.70 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 28.91 GiB memory in use. Of the allocated memory 28.20 GiB is allocated by PyTorch, and 63.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size32_packages1_seed32001.pddl,generation_error,,0.467,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size32_packages1_seed32001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 512.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 25.55 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 31.05 GiB memory in use. Of the allocated memory 30.33 GiB is allocated by PyTorch, and 78.49 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size33_packages1_seed33001.pddl,generation_error,,0.460,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size33_packages1_seed33001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 592.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 23.13 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 33.48 GiB memory in use. Of the allocated memory 32.78 GiB is allocated by PyTorch, and 54.79 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size34_packages1_seed34001.pddl,generation_error,,0.519,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size34_packages1_seed34001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 656.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.96 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 35.65 GiB memory in use. Of the allocated memory 34.93 GiB is allocated by PyTorch, and 74.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size35_packages1_seed35001.pddl,generation_error,,0.532,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size35_packages1_seed35001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 736.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 18.32 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 38.28 GiB memory in use. Of the allocated memory 37.58 GiB is allocated by PyTorch, and 61.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size36_packages1_seed36001.pddl,generation_error,,0.614,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size36_packages1_seed36001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 832.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 15.16 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 41.45 GiB memory in use. Of the allocated memory 40.73 GiB is allocated by PyTorch, and 75.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size37_packages1_seed37001.pddl,generation_error,,0.537,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size37_packages1_seed37001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 928.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.99 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 44.61 GiB memory in use. Of the allocated memory 43.89 GiB is allocated by PyTorch, and 73.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size38_packages1_seed38001.pddl,generation_error,,0.668,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size38_packages1_seed38001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 1024.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 8.30 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 48.30 GiB memory in use. Of the allocated memory 47.59 GiB is allocated by PyTorch, and 67.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size39_packages1_seed39001.pddl,generation_error,,0.751,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size39_packages1_seed39001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 18.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 17.17 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 39.44 GiB memory in use. Of the allocated memory 38.75 GiB is allocated by PyTorch, and 42.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size3_packages1_seed3001.pddl,invalid,invalid,35.914,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size3_packages1_seed3001.plan"
delivery,delivery_size40_packages1_seed40001.pddl,generation_error,,0.640,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size40_packages1_seed40001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 20.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 14.16 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 42.44 GiB memory in use. Of the allocated memory 41.75 GiB is allocated by PyTorch, and 50.45 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size41_packages1_seed41001.pddl,generation_error,,0.689,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size41_packages1_seed41001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 22.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 11.15 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 45.45 GiB memory in use. Of the allocated memory 44.75 GiB is allocated by PyTorch, and 58.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size42_packages1_seed42001.pddl,generation_error,,0.595,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size42_packages1_seed42001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 12.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 8.16 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 48.44 GiB memory in use. Of the allocated memory 47.75 GiB is allocated by PyTorch, and 46.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size43_packages1_seed43001.pddl,generation_error,,0.627,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size43_packages1_seed43001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 13.25 GiB. GPU 0 has a total capacity of 79.11 GiB of which 4.41 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 52.19 GiB memory in use. Of the allocated memory 51.50 GiB is allocated by PyTorch, and 46.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size44_packages1_seed44001.pddl,generation_error,,0.655,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size44_packages1_seed44001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 14.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 679.38 MiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 55.94 GiB memory in use. Of the allocated memory 55.25 GiB is allocated by PyTorch, and 46.24 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size45_packages1_seed45001.pddl,generation_error,,0.445,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size45_packages1_seed45001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 15.75 GiB. GPU 0 has a total capacity of 79.11 GiB of which 12.65 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 43.95 GiB memory in use. Of the allocated memory 43.25 GiB is allocated by PyTorch, and 56.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size46_packages1_seed46001.pddl,generation_error,,0.421,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size46_packages1_seed46001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 17.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 9.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 47.42 GiB memory in use. Of the allocated memory 46.75 GiB is allocated by PyTorch, and 23.73 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size47_packages1_seed47001.pddl,generation_error,,0.227,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size47_packages1_seed47001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 19.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 6.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 50.43 GiB memory in use. Of the allocated memory 49.75 GiB is allocated by PyTorch, and 31.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size48_packages1_seed48001.pddl,generation_error,,0.232,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size48_packages1_seed48001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 20.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 3.17 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 53.44 GiB memory in use. Of the allocated memory 52.75 GiB is allocated by PyTorch, and 39.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size49_packages1_seed49001.pddl,generation_error,,0.440,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size49_packages1_seed49001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 22.50 GiB. GPU 0 has a total capacity of 79.11 GiB of which 21.68 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 34.92 GiB memory in use. Of the allocated memory 34.25 GiB is allocated by PyTorch, and 22.56 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size4_packages1_seed4001.pddl,invalid,invalid,35.889,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size4_packages1_seed4001.plan"
delivery,delivery_size50_packages1_seed50001.pddl,generation_error,,0.317,Safety-gen/benchmark_problems/delivery/llm_results/delivery_size50_packages1_seed50001.plan,"CUDA OOM: CUDA out of memory. Tried to allocate 24.00 GiB. GPU 0 has a total capacity of 79.11 GiB of which 20.18 GiB is free. Process 840034 has 22.49 GiB memory in use. Including non-PyTorch memory, this process has 36.42 GiB memory in use. Of the allocated memory 35.75 GiB is allocated by PyTorch, and 26.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
delivery,delivery_size5_packages1_seed5001.pddl,invalid,invalid,35.668,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size5_packages1_seed5001.plan"
delivery,delivery_size6_packages1_seed6001.pddl,invalid,invalid,39.711,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size6_packages1_seed6001.plan"
delivery,delivery_size7_packages1_seed7001.pddl,invalid,invalid,41.342,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size7_packages1_seed7001.plan"
delivery,delivery_size8_packages1_seed8001.pddl,invalid,invalid,39.089,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size8_packages1_seed8001.plan"
delivery,delivery_size9_packages1_seed9001.pddl,invalid,invalid,39.135,,"Checking plan: /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 /home/ubuntu/Safety-gen/benchmark_problems/delivery/llm_results/delivery_size9_packages1_seed9001.plan"
spanner,spanner-s10-n9-l15-s10001.pddl,invalid,invalid,95.138,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s10-n9-l15-s10001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s10-n9-l15-s10001.plan"
spanner,spanner-s11-n10-l16-s11001.pddl,invalid,invalid,83.030,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s11-n10-l16-s11001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s11-n10-l16-s11001.plan"
spanner,spanner-s12-n11-l18-s12001.pddl,invalid,invalid,84.159,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s12-n11-l18-s12001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s12-n11-l18-s12001.plan"
spanner,spanner-s13-n12-l19-s13001.pddl,invalid,invalid,79.210,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s13-n12-l19-s13001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s13-n12-l19-s13001.plan"
spanner,spanner-s14-n13-l21-s14001.pddl,invalid,invalid,78.504,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s14-n13-l21-s14001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s14-n13-l21-s14001.plan"
spanner,spanner-s15-n14-l22-s15001.pddl,invalid,invalid,74.856,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s15-n14-l22-s15001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s15-n14-l22-s15001.plan"
spanner,spanner-s16-n15-l24-s16001.pddl,invalid,invalid,76.775,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s16-n15-l24-s16001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s16-n15-l24-s16001.plan"
spanner,spanner-s17-n16-l25-s17001.pddl,invalid,invalid,70.438,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s17-n16-l25-s17001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s17-n16-l25-s17001.plan"
spanner,spanner-s18-n17-l27-s18001.pddl,invalid,invalid,58.565,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s18-n17-l27-s18001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s18-n17-l27-s18001.plan"
spanner,spanner-s19-n18-l28-s19001.pddl,invalid,invalid,53.601,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s19-n18-l28-s19001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s19-n18-l28-s19001.plan"
spanner,spanner-s20-n19-l30-s20001.pddl,invalid,invalid,55.978,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s20-n19-l30-s20001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s20-n19-l30-s20001.plan"
spanner,spanner-s21-n20-l31-s21001.pddl,invalid,invalid,54.901,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s21-n20-l31-s21001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s21-n20-l31-s21001.plan"
spanner,spanner-s22-n21-l33-s22001.pddl,invalid,invalid,57.520,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s22-n21-l33-s22001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s22-n21-l33-s22001.plan"
spanner,spanner-s23-n22-l34-s23001.pddl,invalid,invalid,55.997,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s23-n22-l34-s23001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s23-n22-l34-s23001.plan"
spanner,spanner-s24-n23-l36-s24001.pddl,invalid,invalid,60.110,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s24-n23-l36-s24001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s24-n23-l36-s24001.plan"
spanner,spanner-s25-n24-l37-s25001.pddl,invalid,invalid,56.714,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s25-n24-l37-s25001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s25-n24-l37-s25001.plan"
spanner,spanner-s26-n25-l39-s26001.pddl,invalid,invalid,55.168,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s26-n25-l39-s26001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s26-n25-l39-s26001.plan"
spanner,spanner-s27-n26-l40-s27001.pddl,invalid,invalid,56.788,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s27-n26-l40-s27001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s27-n26-l40-s27001.plan"
spanner,spanner-s28-n27-l42-s28001.pddl,invalid,invalid,56.275,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s28-n27-l42-s28001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s28-n27-l42-s28001.plan"
spanner,spanner-s29-n28-l43-s29001.pddl,invalid,invalid,57.337,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s29-n28-l43-s29001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s29-n28-l43-s29001.plan"
spanner,spanner-s3-n2-l5-s3001.pddl,invalid,invalid,57.600,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s3-n2-l5-s3001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s3-n2-l5-s3001.plan"
spanner,spanner-s30-n29-l45-s30001.pddl,invalid,invalid,59.941,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s30-n29-l45-s30001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s30-n29-l45-s30001.plan"
spanner,spanner-s4-n3-l6-s4001.pddl,invalid,invalid,56.146,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s4-n3-l6-s4001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s4-n3-l6-s4001.plan"
spanner,spanner-s5-n4-l7-s5001.pddl,invalid,invalid,59.278,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s5-n4-l7-s5001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s5-n4-l7-s5001.plan"
spanner,spanner-s6-n5-l9-s6001.pddl,invalid,invalid,59.301,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s6-n5-l9-s6001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s6-n5-l9-s6001.plan"
spanner,spanner-s7-n6-l10-s7001.pddl,invalid,invalid,57.604,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s7-n6-l10-s7001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s7-n6-l10-s7001.plan"
spanner,spanner-s8-n7-l12-s8001.pddl,invalid,invalid,58.178,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s8-n7-l12-s8001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s8-n7-l12-s8001.plan"
spanner,spanner-s9-n8-l13-s9001.pddl,invalid,invalid,58.729,,"Checking plan: benchmark_problems/spanner/llm_results/spanner-s9-n8-l13-s9001.plan
Plan executed successfully - checking goal
Goal not satisfied
Plan invalid


Failed plans:
 benchmark_problems/spanner/llm_results/spanner-s9-n8-l13-s9001.plan"

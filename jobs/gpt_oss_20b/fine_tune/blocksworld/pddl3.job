#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/fine_tune/gpt_oss_20b/blocksworld/pddl3.o
#$ -pe smp 8
#$ -N fine_tune_gpt_oss_20b_blocksworld_pddl3

set -euo pipefail

# Ensure we are at the repo root so relative paths below work
cd /home/ubuntu/Safety-gen

conda activate llmstl

# Fine-tune GPT-OSS-20B on blocksworld scenario (PDDL3)
python3 pddl_finetune.py \
  --mode train \
  --model "unsloth/gpt-oss-20b-unsloth-bnb-4bit" \
  --output "gpt_oss_20b/blocksworld/pddl3" \
  --dataset "/groups/fkong/jfan5/data/sft/blocksworld/pddl3.hf" \
  --family gpt \
  --max-seq-length 2048 \
  --per-device-train-batch-size 4 \
  --gradient-accumulation-steps 4 \
  --load-in-4bit \
  --scenarios blocksworld

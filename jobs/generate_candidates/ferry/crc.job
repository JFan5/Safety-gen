#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/generate_candidates_ferry.o
#$ -pe smp 28         # Request 28 CPU cores to match Slurm configuration
#$ -N generate_candidates_ferry

set -euo pipefail

conda activate llmstl

SCENARIO="ferry"

echo ">>> Generating DPO candidates for ${SCENARIO} (PDDL2)"
mkdir -p "data/dpo/mistral_7b/${SCENARIO}/pddl2"
python3 script/generate_score_candidate.py \
  --model "sft_model/mistral_7b/${SCENARIO}/pddl2" \
  --family mistral \
  --domain-file "${SCENARIO}/domain.pddl" \
  --problems-dir "${SCENARIO}/all_problems" \
  --prompt-template "prompt_pddl2.txt" \
  --out "data/dpo/mistral_7b/${SCENARIO}/pddl2/scored.jsonl"

echo ">>> Generating DPO candidates for ${SCENARIO} (PDDL3)"
mkdir -p "data/dpo/mistral_7b/${SCENARIO}/pddl3"
python3 script/generate_score_candidate.py \
  --model "sft_model/mistral_7b/${SCENARIO}/pddl3" \
  --family mistral \
  --domain-file "${SCENARIO}/domain3.pddl" \
  --problems-dir "${SCENARIO}/all_problems3" \
  --prompt-template "prompt_pddl3.txt" \
  --out "data/dpo/mistral_7b/${SCENARIO}/pddl3/scored.jsonl"

echo "Ferry scenario processed."

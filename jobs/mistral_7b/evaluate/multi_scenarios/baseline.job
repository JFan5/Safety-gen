#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/evaluate/mistral/multi_scenarios/baseline-30.o
#$ -pe smp 8          # Specify parallel environment and legal core size
#$ -N evaluate_mistral_multi_baseline-30     # Specify job name
#$ -t 1-5               # Specify number of tasks in array (5 scenarios)

conda activate llmstl

# Define scenario configurations for evaluation
scenarios=( 
    "blocksworld"
    "delivery" 
    "ferry"
    "grippers"
    "spanner"
)
scenario_name="${scenarios[$SGE_TASK_ID-1]}"

echo "=========================================="
echo "Starting evaluation for scenario: $scenario_name"
echo "Task ID: $SGE_TASK_ID"
echo "=========================================="

BASE_MODEL="unsloth/mistral-7b-instruct-v0.3-bnb-4bit"

# Map scenario to problems dir and domain file
case "$scenario_name" in
  "blocksworld")
    PROBLEMS_DIR="blocksworld/all_problems3/testing"
    DOMAIN_FILE="blocksworld/domain3.pddl"
    RESULTS_DIR="planning_results/mistral_7b/blocksworld/baseline-30"
    OUTPUT_NAME="blocksworld_test_results.json"
    ;;
  "delivery")
    PROBLEMS_DIR="delivery/all_problems3/testing"
    DOMAIN_FILE="delivery/domain3.pddl"
    RESULTS_DIR="planning_results/mistral_7b/delivery/baseline-30"
    OUTPUT_NAME="delivery_test_results.json"
    ;;
  "ferry")
    PROBLEMS_DIR="ferry/all_problems3/testing"
    DOMAIN_FILE="ferry/domain3.pddl"
    RESULTS_DIR="planning_results/mistral_7b/ferry/baseline-30"
    OUTPUT_NAME="ferry_test_results.json"
    ;;
  "grippers")
    PROBLEMS_DIR="grippers/all_problems3/testing"
    DOMAIN_FILE="grippers/domain3.pddl"
    RESULTS_DIR="planning_results/mistral_7b/grippers/baseline-30"
    OUTPUT_NAME="grippers_test_results.json"
    ;;
  "spanner")
    PROBLEMS_DIR="spanner/all_problems3/testing"
    DOMAIN_FILE="spanner/domain3.pddl"
    RESULTS_DIR="planning_results/mistral_7b/spanner/baseline-30"
    OUTPUT_NAME="spanner_test_results.json"
    ;;
  *)
    echo "Unknown scenario: $scenario_name"; exit 1
    ;;  
esac

python3 script/evaluate_llm_solver.py \
  --model ${BASE_MODEL} \
  --problems-dir ${PROBLEMS_DIR} \
  --domain-file ${DOMAIN_FILE} \
  --max-problems 30 \
  --output ${OUTPUT_NAME} \
  --results-dir ${RESULTS_DIR}

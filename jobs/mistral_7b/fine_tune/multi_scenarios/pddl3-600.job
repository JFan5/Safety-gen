#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/fine_tune/mistral/multi_scenarios/pddl3-500.o
#$ -pe smp 8
#$ -N fine_tune_mistral_multi

set -euo pipefail

# Ensure we are at the repo root so relative paths below work
cd /home/ubuntu/Safety-gen
conda activate llmstl

# Aggregated multi-scenario fine-tune for Mistral-7B (PDDL3 dataset).
# Generate the dataset via:
#   python3 script/collect_finetuned_dataset_together.py --pddl PDDL3 --output /groups/fkong/jfan5/data/sft/multi_scenarios/pddl3.hf
MODEL_NAME="unsloth/mistral-7b-instruct-v0.3-bnb-4bit"
OUTPUT_NAME="/groups/fkong/jfan5/sft_models/mistral_7b/multi_scenarios600/pddl3"
DATASET_PATH="/groups/fkong/jfan5/data/sft/multi_scenarios600/pddl3.hf"

python3 pddl_finetune.py \
  --mode train \
  --model "unsloth/mistral-7b-instruct-v0.3-bnb-4bit" \
  --output ""mistral_7b/multi_scenarios/pddl3"" \
  --dataset "$DATASET_PATH" \
  --scenarios all

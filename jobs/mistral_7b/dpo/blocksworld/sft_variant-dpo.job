#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/dpo/mistral_7b/blocksworld/sft_variant-dpo.o
#$ -pe smp 28
#$ -N dpo_mistral_blocksworld_sft_variant

set -euo pipefail

# Ensure we are at the repo root so relative paths below work
cd /home/ubuntu/Safety-gen

conda activate llmstl

# DPO training for Mistral-7B on blocksworld scenario (SFT variant)
mkdir -p "/groups/fkong/jfan5/dpo_models/mistral_7b/blocksworld/dpo-variant-V2"

python3 script/train_dpo_unsloth.py \
  --base_model "/groups/fkong/jfan5/sft_models/mistral_7b/blocksworld/sft-variant" \
  --dataset "/home/ubuntu/Safety-gen/data/dpo/classical/blocksworld_500-variant-5.jsonl" \
  --output_dir "/groups/fkong/jfan5/dpo_models/mistral_7b/blocksworld/dpo-variant-V2" \
  --num_epochs 1 \
  --batch_size 4 \
  --gradient_accumulation_steps 8 \
  --learning_rate 5e-6 \
  --save_steps 30 \
  --eval_steps 30 \
  --logging_steps 10 \
  --beta 0.1 \
  --run_name "dpo-mistral-blocksworld-dpo-variant-V2" \
  --dataloader_num_workers 4

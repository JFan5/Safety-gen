#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/dpo/mistral_7b/spanner/pddl3.o
#$ -pe smp 28
#$ -N dpo_mistral_spanner_pddl3

set -euo pipefail

# Ensure we are at the repo root so relative paths below work
cd /home/ubuntu/Safety-gen

conda activate llmstl

# DPO training for Mistral-7B on spanner scenario (PDDL3)
mkdir -p "/groups/fkong/jfan5/dpo_models/mistral_7b/spanner/pddl3"

python3 script/train_dpo_unsloth.py \
  --base_model "/groups/fkong/jfan5/sft_models/mistral_7b/spanner/pddl3" \
  --dataset "/home/ubuntu/Safety-gen/data/dpo/datasets/spanner/pddl3_dpo.jsonl" \
  --output_dir "/groups/fkong/jfan5/dpo_models/mistral_7b/spanner/pddl3" \
  --num_epochs 3 \
  --batch_size 1 \
  --gradient_accumulation_steps 8 \
  --learning_rate 1e-5 \
  --save_steps 500 \
  --eval_steps 500 \
  --logging_steps 25 \
  --beta 0.1 \
  --memory_efficient \
  --run_name "dpo-mistral-spanner-pddl3" \
  --dataloader_num_workers 0

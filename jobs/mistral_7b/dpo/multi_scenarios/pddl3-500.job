#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/dpo/mistral_7b/multi_scenarios/pddl3-500.o
#$ -pe smp 8
#$ -N dpo_mistral_multi_pddl3-500

set -euo pipefail

# Ensure we are at the repo root so relative paths below work
cd /home/ubuntu/Safety-gen
conda activate llmstl

# DPO training for Mistral-7B on multiple scenarios (PDDL3-500)
mkdir -p "/groups/fkong/jfan5/dpo_models/mistral_7b/multi_scenarios500/pddl3"

python3 script/train_dpo_unsloth.py \
  --base_model "/groups/fkong/jfan5/sft_models/mistral_7b/multi_scenarios500/pddl3" \
  --dataset "/groups/fkong/jfan5/data/dpo/mistral_unsloth/multi_scenarios/pddl3_dpo.jsonl" \
  --output_dir "/groups/fkong/jfan5/dpo_models/mistral_7b/multi_scenarios500/pddl3" \
  --num_epochs 3 \
  --batch_size 2 \
  --gradient_accumulation_steps 4 \
  --run_name "dpo-mistral-multi-pddl3-500" \
  --lora_r 16 \
  --lora_alpha 32 \
  --lora_dropout 0.05 \
  --reference_free \
  --use_gradient_checkpointing \
  --memory_efficient

#!/bin/bash

#$ -M jfan5@nd.edu
#$ -m abe
#$ -q gpu
#$ -l gpu_card=1
#$ -o job_outputs/dpo/mistral_7b/multi_scenarios/pddl3_crc.o
#$ -pe smp 8
#$ -N dpo_mistral_multi_pddl3_crc

set -euo pipefail

# Ensure we are at the repo root so relative paths below work
cd /home/ubuntu/Safety-gen

conda activate llmstl

# DPO training for Mistral-7B on multiple scenarios (PDDL3)
mkdir -p "/groups/fkong/jfan5/dpo_models/mistral_7b/multi_scenarios/pddl3"

python3 script/train_dpo_unsloth.py \
  --base_model "/groups/fkong/jfan5/sft_models/mistral_7b/multi_scenarios/pddl3" \
  --dataset "/home/ubuntu/Safety-gen/data/dpo/datasets/all_dpo-500.jsonl" \
  --output_dir "/groups/fkong/jfan5/dpo_models/mistral_7b/multi_scenarios/pddl3" \
  --num_epochs 3 \
  --batch_size 1 \
  --gradient_accumulation_steps 8 \
  --learning_rate 1e-5 \
  --save_steps 500 \
  --eval_steps 500 \
  --logging_steps 25 \
  --beta 0.1 \
  --memory_efficient \
  --run_name "dpo-mistral-multi-pddl3" \
  --dataloader_num_workers 0

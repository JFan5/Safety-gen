
CondaError: Run 'conda init' before 'conda activate'

[torchao|WARNING]Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA A100 80GB PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.10.12: Fast Gpt_Oss patching. Transformers: 4.56.2.
   \\   /|    NVIDIA A100 80GB PCIe. Num GPUs = 1. Max memory: 79.151 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 8.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:00<00:02,  1.00it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.11s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.03s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.47it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.23it/s]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from data/sft/grippers/pddl2.hf...
Loading HuggingFace dataset...
Dataset loaded with 2000 entries
Scenario distribution:
  grippers: 2000

Filtering scenarios to: ['grippers']
Filter:   0%|          | 0/2000 [00:00<?, ? examples/s]Filter: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2000/2000 [00:00<00:00, 63259.16 examples/s]
Filtered dataset size: 2000
Processing dataset format (chat template)...
Map:   0%|          | 0/1900 [00:00<?, ? examples/s]Map:  34%|â–ˆâ–ˆâ–ˆâ–      | 651/1900 [00:00<00:00, 6459.26 examples/s]Map:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 1453/1900 [00:00<00:00, 6569.09 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:00<00:00, 6450.87 examples/s]
Map:   0%|          | 0/100 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 5597.18 examples/s]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: setting up run jz1oz3gy
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251031_042906-jz1oz3gy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_pddl2
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/jz1oz3gy
wandb: Detected [huggingface_hub.inference] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Testing initial model performance...
Initial model output:
analysisWe need to produce a valid plan for the given problem. Let's analyze the problem.

Domain: gripper domain, typical.

Objects: robot1, rgripper1, lgripper1, room1, room2, room3, room4. Objects: ball1, ball2, ball3.

Predicates: at-robby robot at room; at object at room; free robot gripper; carry robot object gripper.

Robot has two grippers.

Goal: all three balls at room2.

Initial: robot at room1; both grippers free; balls: ball1 at room4, ball2 at room4, ball3 at room2.

So ball3 is al...

Resolved training arguments:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-05
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 2048
  load_in_4bit: True

Creating trainer...
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/1900 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   3%|â–Ž         | 60/1900 [00:02<01:11, 25.61 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   9%|â–‰         | 180/1900 [00:02<00:21, 81.27 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 300/1900 [00:02<00:10, 145.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 360/1900 [00:03<00:09, 154.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 480/1900 [00:03<00:07, 202.00 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 600/1900 [00:03<00:04, 276.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 660/1900 [00:04<00:05, 241.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 719/1900 [00:04<00:04, 257.07 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 838/1900 [00:04<00:03, 342.80 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 897/1900 [00:04<00:03, 278.36 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1015/1900 [00:05<00:02, 295.36 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1133/1900 [00:05<00:02, 370.02 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1192/1900 [00:05<00:01, 360.09 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1251/1900 [00:05<00:01, 355.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1310/1900 [00:05<00:01, 348.57 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1369/1900 [00:06<00:01, 340.44 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1428/1900 [00:06<00:01, 332.02 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1487/1900 [00:06<00:01, 339.95 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1546/1900 [00:06<00:01, 339.03 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1605/1900 [00:06<00:00, 339.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1664/1900 [00:07<00:00, 272.96 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1723/1900 [00:07<00:00, 314.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 1841/1900 [00:07<00:00, 424.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:07<00:00, 401.54 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1900/1900 [00:07<00:00, 239.20 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/100 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   4%|â–         | 4/100 [00:02<01:00,  1.59 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  12%|â–ˆâ–        | 12/100 [00:02<00:16,  5.33 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 19/100 [00:03<00:09,  8.25 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 22/100 [00:03<00:09,  8.09 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 25/100 [00:03<00:08,  8.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 31/100 [00:04<00:06, 10.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 34/100 [00:04<00:06, 10.57 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 37/100 [00:04<00:06,  9.61 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 40/100 [00:05<00:05, 10.37 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 43/100 [00:05<00:05, 11.17 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 46/100 [00:05<00:05, 10.28 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 49/100 [00:05<00:04, 10.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 55/100 [00:06<00:02, 15.33 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 58/100 [00:06<00:02, 14.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 61/100 [00:06<00:02, 13.27 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/100 [00:07<00:03, 10.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 70/100 [00:07<00:02, 13.59 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 73/100 [00:07<00:02, 12.91 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 76/100 [00:08<00:02, 10.28 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 82/100 [00:08<00:01, 13.40 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 85/100 [00:08<00:01, 12.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 88/100 [00:09<00:01, 10.27 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/100 [00:09<00:00, 13.96 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 97/100 [00:09<00:00, 13.16 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:09<00:00, 13.77 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:10<00:00,  9.86 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 1,900 | Num Epochs = 3 | Total steps = 357
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)

Starting training...
  0%|          | 0/357 [00:00<?, ?it/s]  0%|          | 1/357 [00:14<1:26:09, 14.52s/it]  1%|          | 2/357 [00:21<58:28,  9.88s/it]    1%|          | 3/357 [00:27<49:33,  8.40s/it]  1%|          | 4/357 [00:34<45:19,  7.70s/it]  1%|â–         | 5/357 [00:41<42:55,  7.32s/it]  2%|â–         | 6/357 [00:47<41:27,  7.09s/it]  2%|â–         | 7/357 [00:54<40:26,  6.93s/it]  2%|â–         | 8/357 [01:00<39:45,  6.83s/it]  3%|â–Ž         | 9/357 [01:07<39:18,  6.78s/it]  3%|â–Ž         | 10/357 [01:14<38:54,  6.73s/it]                                                  3%|â–Ž         | 10/357 [01:14<38:54,  6.73s/it]  3%|â–Ž         | 11/357 [01:20<38:38,  6.70s/it]  3%|â–Ž         | 12/357 [01:27<38:23,  6.68s/it]  4%|â–Ž         | 13/357 [01:34<38:10,  6.66s/it]  4%|â–         | 14/357 [01:40<38:01,  6.65s/it]  4%|â–         | 15/357 [01:47<37:51,  6.64s/it]  4%|â–         | 16/357 [01:53<37:44,  6.64s/it]  5%|â–         | 17/357 [02:00<37:37,  6.64s/it]  5%|â–Œ         | 18/357 [02:07<37:31,  6.64s/it]  5%|â–Œ         | 19/357 [02:13<37:24,  6.64s/it]  6%|â–Œ         | 20/357 [02:20<37:18,  6.64s/it]                                                  6%|â–Œ         | 20/357 [02:20<37:18,  6.64s/it]  6%|â–Œ         | 21/357 [02:27<37:12,  6.64s/it]  6%|â–Œ         | 22/357 [02:33<37:05,  6.64s/it]  6%|â–‹         | 23/357 [02:40<36:58,  6.64s/it]  7%|â–‹         | 24/357 [02:47<36:50,  6.64s/it]  7%|â–‹         | 25/357 [02:53<36:42,  6.64s/it]  7%|â–‹         | 26/357 [03:00<36:36,  6.63s/it]  8%|â–Š         | 27/357 [03:06<36:28,  6.63s/it]  8%|â–Š         | 28/357 [03:13<36:21,  6.63s/it]  8%|â–Š         | 29/357 [03:20<36:16,  6.63s/it]  8%|â–Š         | 30/357 [03:26<36:10,  6.64s/it]                                                  8%|â–Š         | 30/357 [03:26<36:10,  6.64s/it]  9%|â–Š         | 31/357 [03:33<36:04,  6.64s/it]  9%|â–‰         | 32/357 [03:40<35:59,  6.64s/it]  9%|â–‰         | 33/357 [03:46<35:50,  6.64s/it] 10%|â–‰         | 34/357 [03:53<36:25,  6.77s/it] 10%|â–‰         | 35/357 [04:00<36:08,  6.73s/it] 10%|â–ˆ         | 36/357 [04:07<35:55,  6.71s/it] 10%|â–ˆ         | 37/357 [04:13<35:43,  6.70s/it] 11%|â–ˆ         | 38/357 [04:20<35:31,  6.68s/it] 11%|â–ˆ         | 39/357 [04:27<35:21,  6.67s/it] 11%|â–ˆ         | 40/357 [04:33<35:13,  6.67s/it]                                                 11%|â–ˆ         | 40/357 [04:33<35:13,  6.67s/it] 11%|â–ˆâ–        | 41/357 [04:40<35:04,  6.66s/it] 12%|â–ˆâ–        | 42/357 [04:47<34:55,  6.65s/it] 12%|â–ˆâ–        | 43/357 [04:53<34:47,  6.65s/it] 12%|â–ˆâ–        | 44/357 [05:00<34:41,  6.65s/it] 13%|â–ˆâ–Ž        | 45/357 [05:07<34:34,  6.65s/it] 13%|â–ˆâ–Ž        | 46/357 [05:13<34:27,  6.65s/it] 13%|â–ˆâ–Ž        | 47/357 [05:20<34:20,  6.65s/it] 13%|â–ˆâ–Ž        | 48/357 [05:26<34:14,  6.65s/it] 14%|â–ˆâ–Ž        | 49/357 [05:33<34:07,  6.65s/it] 14%|â–ˆâ–        | 50/357 [05:40<34:01,  6.65s/it]                                                 14%|â–ˆâ–        | 50/357 [05:40<34:01,  6.65s/it] 14%|â–ˆâ–        | 51/357 [05:46<33:57,  6.66s/it] 15%|â–ˆâ–        | 52/357 [05:53<33:51,  6.66s/it] 15%|â–ˆâ–        | 53/357 [06:00<33:44,  6.66s/it] 15%|â–ˆâ–Œ        | 54/357 [06:06<33:36,  6.66s/it] 15%|â–ˆâ–Œ        | 55/357 [06:13<33:29,  6.65s/it] 16%|â–ˆâ–Œ        | 56/357 [06:20<33:24,  6.66s/it] 16%|â–ˆâ–Œ        | 57/357 [06:26<33:17,  6.66s/it] 16%|â–ˆâ–Œ        | 58/357 [06:33<33:10,  6.66s/it] 17%|â–ˆâ–‹        | 59/357 [06:40<33:03,  6.66s/it] 17%|â–ˆâ–‹        | 60/357 [06:46<32:57,  6.66s/it]                                                 17%|â–ˆâ–‹        | 60/357 [06:46<32:57,  6.66s/it] 17%|â–ˆâ–‹        | 61/357 [06:53<32:49,  6.65s/it] 17%|â–ˆâ–‹        | 62/357 [07:00<32:43,  6.66s/it] 18%|â–ˆâ–Š        | 63/357 [07:06<32:36,  6.66s/it] 18%|â–ˆâ–Š        | 64/357 [07:13<32:30,  6.66s/it] 18%|â–ˆâ–Š        | 65/357 [07:20<32:23,  6.65s/it] 18%|â–ˆâ–Š        | 66/357 [07:26<32:16,  6.66s/it] 19%|â–ˆâ–‰        | 67/357 [07:33<32:47,  6.78s/it] 19%|â–ˆâ–‰        | 68/357 [07:40<32:30,  6.75s/it] 19%|â–ˆâ–‰        | 69/357 [07:47<32:14,  6.72s/it] 20%|â–ˆâ–‰        | 70/357 [07:53<32:04,  6.71s/it]                                                 20%|â–ˆâ–‰        | 70/357 [07:53<32:04,  6.71s/it] 20%|â–ˆâ–‰        | 71/357 [08:00<31:54,  6.69s/it] 20%|â–ˆâ–ˆ        | 72/357 [08:07<31:44,  6.68s/it] 20%|â–ˆâ–ˆ        | 73/357 [08:13<31:34,  6.67s/it] 21%|â–ˆâ–ˆ        | 74/357 [08:20<31:25,  6.66s/it] 21%|â–ˆâ–ˆ        | 75/357 [08:27<31:17,  6.66s/it] 21%|â–ˆâ–ˆâ–       | 76/357 [08:33<31:11,  6.66s/it] 22%|â–ˆâ–ˆâ–       | 77/357 [08:40<31:03,  6.65s/it] 22%|â–ˆâ–ˆâ–       | 78/357 [08:47<30:56,  6.65s/it] 22%|â–ˆâ–ˆâ–       | 79/357 [08:53<30:49,  6.65s/it] 22%|â–ˆâ–ˆâ–       | 80/357 [09:00<30:43,  6.65s/it]                                                 22%|â–ˆâ–ˆâ–       | 80/357 [09:00<30:43,  6.65s/it] 23%|â–ˆâ–ˆâ–Ž       | 81/357 [09:07<30:36,  6.65s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/357 [09:13<30:29,  6.65s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/357 [09:20<30:23,  6.65s/it] 24%|â–ˆâ–ˆâ–Ž       | 84/357 [09:27<30:16,  6.65s/it] 24%|â–ˆâ–ˆâ–       | 85/357 [09:33<30:08,  6.65s/it] 24%|â–ˆâ–ˆâ–       | 86/357 [09:40<30:02,  6.65s/it] 24%|â–ˆâ–ˆâ–       | 87/357 [09:46<29:55,  6.65s/it] 25%|â–ˆâ–ˆâ–       | 88/357 [09:53<29:49,  6.65s/it] 25%|â–ˆâ–ˆâ–       | 89/357 [10:00<29:42,  6.65s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:06<29:36,  6.66s/it]                                                 25%|â–ˆâ–ˆâ–Œ       | 90/357 [10:06<29:36,  6.66s/it] 25%|â–ˆâ–ˆâ–Œ       | 91/357 [10:13<29:30,  6.66s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/357 [10:20<29:23,  6.66s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/357 [10:26<29:17,  6.66s/it] 26%|â–ˆâ–ˆâ–‹       | 94/357 [10:33<29:11,  6.66s/it] 27%|â–ˆâ–ˆâ–‹       | 95/357 [10:40<29:04,  6.66s/it] 27%|â–ˆâ–ˆâ–‹       | 96/357 [10:46<28:56,  6.65s/it] 27%|â–ˆâ–ˆâ–‹       | 97/357 [10:53<28:49,  6.65s/it] 27%|â–ˆâ–ˆâ–‹       | 98/357 [11:00<28:43,  6.65s/it] 28%|â–ˆâ–ˆâ–Š       | 99/357 [11:06<28:35,  6.65s/it] 28%|â–ˆâ–ˆâ–Š       | 100/357 [11:13<28:29,  6.65s/it]                                                  28%|â–ˆâ–ˆâ–Š       | 100/357 [11:13<28:29,  6.65s/it] 28%|â–ˆâ–ˆâ–Š       | 101/357 [11:20<28:55,  6.78s/it] 29%|â–ˆâ–ˆâ–Š       | 102/357 [11:27<28:40,  6.75s/it] 29%|â–ˆâ–ˆâ–‰       | 103/357 [11:33<28:26,  6.72s/it] 29%|â–ˆâ–ˆâ–‰       | 104/357 [11:40<28:16,  6.70s/it] 29%|â–ˆâ–ˆâ–‰       | 105/357 [11:47<28:05,  6.69s/it] 30%|â–ˆâ–ˆâ–‰       | 106/357 [11:53<27:56,  6.68s/it] 30%|â–ˆâ–ˆâ–‰       | 107/357 [12:00<27:47,  6.67s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/357 [12:07<27:39,  6.67s/it] 31%|â–ˆâ–ˆâ–ˆ       | 109/357 [12:13<27:32,  6.66s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:20<27:26,  6.67s/it]                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [12:20<27:26,  6.67s/it] 31%|â–ˆâ–ˆâ–ˆ       | 111/357 [12:27<27:20,  6.67s/it] 31%|â–ˆâ–ˆâ–ˆâ–      | 112/357 [12:33<27:13,  6.67s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 113/357 [12:40<27:06,  6.67s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 114/357 [12:47<26:59,  6.67s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 115/357 [12:53<26:52,  6.66s/it] 32%|â–ˆâ–ˆâ–ˆâ–      | 116/357 [13:00<26:44,  6.66s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 117/357 [13:07<26:37,  6.66s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 118/357 [13:13<26:30,  6.66s/it] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [13:18<24:24,  6.15s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 4.5929, 'grad_norm': 46.13552474975586, 'learning_rate': 5e-06, 'epoch': 0.08}
{'loss': 3.7159, 'grad_norm': 24.121614456176758, 'learning_rate': 1.0555555555555557e-05, 'epoch': 0.17}
{'loss': 2.3252, 'grad_norm': 7.344805717468262, 'learning_rate': 1.6111111111111115e-05, 'epoch': 0.25}
{'loss': 1.3882, 'grad_norm': 2.1476314067840576, 'learning_rate': 1.9995690062269985e-05, 'epoch': 0.34}
{'loss': 1.0987, 'grad_norm': 1.8933311700820923, 'learning_rate': 1.9919172253651637e-05, 'epoch': 0.42}
{'loss': 0.7922, 'grad_norm': 2.1098225116729736, 'learning_rate': 1.974772117649135e-05, 'epoch': 0.51}
{'loss': 0.4613, 'grad_norm': 2.3237433433532715, 'learning_rate': 1.9482977734962753e-05, 'epoch': 0.59}
{'loss': 0.1889, 'grad_norm': 1.4388196468353271, 'learning_rate': 1.9127475705028864e-05, 'epoch': 0.67}
{'loss': 0.0587, 'grad_norm': 0.5184571146965027, 'learning_rate': 1.8684617484471662e-05, 'epoch': 0.76}
{'loss': 0.0281, 'grad_norm': 0.24267977476119995, 'learning_rate': 1.815864152961624e-05, 'epoch': 0.84}
{'loss': 0.0218, 'grad_norm': 0.1760093867778778, 'learning_rate': 1.7554581790402372e-05, 'epoch': 0.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:13,  1.66it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:20,  1.06it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:23,  1.11s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:05<00:25,  1.28s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:25,  1.33s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:24,  1.35s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:09<00:23,  1.37s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.44s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:12<00:21,  1.43s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:19,  1.43s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:15<00:18,  1.42s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.47s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:18<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.44s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:21<00:12,  1.43s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.48s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:24<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:25<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:28<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:31<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:34<00:00,  1.49s/it][A                                                 
                                               [A 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 119/357 [13:55<24:24,  6.15s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:21<1:31:13, 23.10s/it]                                                    34%|â–ˆâ–ˆâ–ˆâ–Ž      | 120/357 [14:21<1:31:13, 23.10s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 121/357 [14:26<1:09:26, 17.66s/it] 34%|â–ˆâ–ˆâ–ˆâ–      | 122/357 [14:30<53:42, 13.71s/it]   34%|â–ˆâ–ˆâ–ˆâ–      | 123/357 [14:35<42:43, 10.95s/it] 35%|â–ˆâ–ˆâ–ˆâ–      | 124/357 [14:39<35:02,  9.03s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 125/357 [14:44<30:06,  7.79s/it] 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 126/357 [14:49<26:11,  6.80s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 127/357 [14:53<23:26,  6.11s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 128/357 [14:58<21:31,  5.64s/it] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 129/357 [15:02<20:08,  5.30s/it] 36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:07<19:39,  5.19s/it]                                                  36%|â–ˆâ–ˆâ–ˆâ–‹      | 130/357 [15:07<19:39,  5.19s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 131/357 [15:12<18:47,  4.99s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 132/357 [15:16<18:10,  4.85s/it] 37%|â–ˆâ–ˆâ–ˆâ–‹      | 133/357 [15:21<17:42,  4.74s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 134/357 [15:25<17:21,  4.67s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 135/357 [15:30<17:31,  4.74s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 136/357 [15:35<17:11,  4.67s/it] 38%|â–ˆâ–ˆâ–ˆâ–Š      | 137/357 [15:39<16:56,  4.62s/it] 39%|â–ˆâ–ˆâ–ˆâ–Š      | 138/357 [15:44<16:44,  4.59s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 139/357 [15:49<16:59,  4.68s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [15:53<16:44,  4.63s/it]                                                  39%|â–ˆâ–ˆâ–ˆâ–‰      | 140/357 [15:53<16:44,  4.63s/it] 39%|â–ˆâ–ˆâ–ˆâ–‰      | 141/357 [15:58<16:32,  4.59s/it] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 142/357 [16:02<16:21,  4.57s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 143/357 [16:07<16:13,  4.55s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 144/357 [16:12<16:31,  4.65s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 145/357 [16:16<16:16,  4.61s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 146/357 [16:21<16:05,  4.58s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 147/357 [16:25<15:56,  4.55s/it] 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 148/357 [16:30<16:13,  4.66s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 149/357 [16:34<15:58,  4.61s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [16:39<15:47,  4.58s/it]                                                  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 150/357 [16:39<15:47,  4.58s/it] 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 151/357 [16:43<15:39,  4.56s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 152/357 [16:48<15:31,  4.55s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 153/357 [16:53<15:48,  4.65s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 154/357 [16:57<15:35,  4.61s/it] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 155/357 [17:02<15:26,  4.58s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 156/357 [17:06<15:16,  4.56s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 157/357 [17:11<15:09,  4.55s/it] 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 158/357 [17:16<15:29,  4.67s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 159/357 [17:20<15:15,  4.62s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:25<15:03,  4.59s/it]                                                  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 160/357 [17:25<15:03,  4.59s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 161/357 [17:29<14:54,  4.57s/it] 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 162/357 [17:34<15:09,  4.66s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 163/357 [17:39<14:55,  4.62s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 164/357 [17:43<14:44,  4.58s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 165/357 [17:48<14:35,  4.56s/it] 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 166/357 [17:52<14:28,  4.55s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 167/357 [17:57<14:44,  4.65s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 168/357 [18:02<14:30,  4.61s/it] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 169/357 [18:06<14:20,  4.58s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:11<14:12,  4.56s/it]                                                  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 170/357 [18:11<14:12,  4.56s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 171/357 [18:15<14:04,  4.54s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 172/357 [18:20<14:19,  4.65s/it] 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 173/357 [18:25<14:08,  4.61s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 174/357 [18:29<13:57,  4.58s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 175/357 [18:34<13:50,  4.56s/it] 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 176/357 [18:39<14:04,  4.66s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 177/357 [18:43<13:51,  4.62s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 178/357 [18:48<13:41,  4.59s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 179/357 [18:52<13:32,  4.56s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [18:57<13:24,  4.55s/it]                                                  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 180/357 [18:57<13:24,  4.55s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 181/357 [19:02<13:38,  4.65s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 182/357 [19:06<13:27,  4.61s/it] 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 183/357 [19:11<13:17,  4.58s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 184/357 [19:15<13:08,  4.56s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 185/357 [19:20<13:03,  4.55s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 186/357 [19:25<13:19,  4.68s/it] 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 187/357 [19:29<13:06,  4.63s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 188/357 [19:34<12:56,  4.59s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 189/357 [19:38<12:47,  4.57s/it] 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [19:43<12:59,  4.67s/it]                                                  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 190/357 [19:43<12:59,  4.67s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 191/357 [19:48<12:46,  4.62s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 192/357 [19:52<12:36,  4.58s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 193/357 [19:57<12:28,  4.56s/it] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 194/357 [20:01<12:21,  4.55s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 195/357 [20:06<12:33,  4.65s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 196/357 [20:10<12:22,  4.61s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 197/357 [20:15<12:12,  4.58s/it] 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 198/357 [20:20<12:04,  4.56s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 199/357 [20:24<11:57,  4.54s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [20:29<12:09,  4.65s/it]                                                  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 200/357 [20:29<12:09,  4.65s/it] 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 201/357 [20:33<11:58,  4.61s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 202/357 [20:38<11:49,  4.58s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 203/357 [20:42<11:41,  4.55s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 204/357 [20:47<11:52,  4.66s/it] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 205/357 [20:52<11:41,  4.61s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 206/357 [20:56<11:31,  4.58s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 207/357 [21:01<11:23,  4.56s/it] 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 208/357 [21:05<11:17,  4.54s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 209/357 [21:10<11:28,  4.65s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:15<11:17,  4.61s/it]                                                  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 210/357 [21:15<11:17,  4.61s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 211/357 [21:19<11:08,  4.58s/it] 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 212/357 [21:24<11:00,  4.56s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 213/357 [21:28<10:53,  4.54s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 214/357 [21:33<11:04,  4.64s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 215/357 [21:38<10:54,  4.61s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 216/357 [21:42<10:45,  4.58s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 217/357 [21:47<10:37,  4.55s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 218/357 [21:51<10:30,  4.54s/it] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 219/357 [21:56<10:41,  4.65s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:01<10:30,  4.60s/it]                                                  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 220/357 [22:01<10:30,  4.60s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 221/357 [22:05<10:22,  4.58s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 222/357 [22:10<10:15,  4.56s/it] 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 223/357 [22:15<10:25,  4.67s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 224/357 [22:19<10:13,  4.62s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 225/357 [22:24<10:04,  4.58s/it] 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 226/357 [22:28<09:57,  4.56s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 227/357 [22:33<09:50,  4.54s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 228/357 [22:37<09:59,  4.65s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 229/357 [22:42<09:49,  4.61s/it] 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [22:46<09:41,  4.57s/it]                                                  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 230/357 [22:46<09:41,  4.57s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 231/357 [22:51<09:33,  4.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 232/357 [22:55<09:28,  4.55s/it] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 233/357 [23:00<09:37,  4.66s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 234/357 [23:05<09:27,  4.61s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 235/357 [23:09<09:18,  4.58s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 236/357 [23:14<09:11,  4.56s/it] 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 237/357 [23:19<09:19,  4.66s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [23:22<08:28,  4.28s/it]{'eval_loss': 0.01716107316315174, 'eval_runtime': 36.7432, 'eval_samples_per_second': 2.722, 'eval_steps_per_second': 0.68, 'epoch': 1.0}

==================================================
Testing model performance...
==================================================
Generated solution:
(pick robot1 ball1 room4 rgripper1)
(move robot1 room4 room2)
(drop robot1 ball1 room2 lgripper1)
(pick robot1 ball2 room4 rgripper1)
(move robot1 room4 room2)
(drop robot1 ball2 room2 lgripper1)
==================================================
{'loss': 0.0188, 'grad_norm': 0.1806354969739914, 'learning_rate': 1.687821953203765e-05, 'epoch': 1.01}
{'loss': 0.0166, 'grad_norm': 0.19316382706165314, 'learning_rate': 1.613602800433194e-05, 'epoch': 1.09}
{'loss': 0.0152, 'grad_norm': 0.1890936642885208, 'learning_rate': 1.5335110488265497e-05, 'epoch': 1.18}
{'loss': 0.0137, 'grad_norm': 0.16388189792633057, 'learning_rate': 1.4483132312727501e-05, 'epoch': 1.26}
{'loss': 0.0121, 'grad_norm': 0.1380869597196579, 'learning_rate': 1.358824749207136e-05, 'epoch': 1.35}
{'loss': 0.0117, 'grad_norm': 0.09190742671489716, 'learning_rate': 1.2659020686615602e-05, 'epoch': 1.43}
{'loss': 0.0115, 'grad_norm': 0.14141221344470978, 'learning_rate': 1.170434523298175e-05, 'epoch': 1.51}
{'loss': 0.0112, 'grad_norm': 0.08100376278162003, 'learning_rate': 1.073335802877504e-05, 'epoch': 1.6}
{'loss': 0.0113, 'grad_norm': 0.06977918744087219, 'learning_rate': 9.755352086219733e-06, 'epoch': 1.68}
{'loss': 0.0113, 'grad_norm': 0.08120846003293991, 'learning_rate': 8.779687591670687e-06, 'epoch': 1.77}
{'loss': 0.011, 'grad_norm': 0.11121483892202377, 'learning_rate': 7.815702322222539e-06, 'epoch': 1.85}
{'loss': 0.0113, 'grad_norm': 0.11139121651649475, 'learning_rate': 6.872622276790804e-06, 'epoch': 1.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:21,  1.00it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.40s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 238/357 [23:59<08:28,  4.28s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 239/357 [24:35<48:35, 24.71s/it] 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [24:39<36:21, 18.65s/it]                                                  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 240/357 [24:39<36:21, 18.65s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 241/357 [24:44<28:05, 14.53s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 242/357 [24:49<22:05, 11.52s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 243/357 [24:53<17:54,  9.42s/it] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 244/357 [24:58<14:58,  7.95s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 245/357 [25:02<12:54,  6.92s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 246/357 [25:07<11:42,  6.33s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 247/357 [25:12<10:35,  5.78s/it] 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 248/357 [25:16<09:48,  5.40s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 249/357 [25:21<09:13,  5.13s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [25:25<08:48,  4.94s/it]                                                  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 250/357 [25:25<08:48,  4.94s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 251/357 [25:30<08:42,  4.93s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 252/357 [25:34<08:24,  4.80s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 253/357 [25:39<08:10,  4.71s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 254/357 [25:43<07:59,  4.65s/it] 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 255/357 [25:48<07:50,  4.61s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 256/357 [25:53<07:54,  4.69s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 257/357 [25:57<07:43,  4.64s/it] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 258/357 [26:02<07:35,  4.60s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 259/357 [26:06<07:27,  4.57s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:11<07:33,  4.67s/it]                                                  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 260/357 [26:11<07:33,  4.67s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 261/357 [26:16<07:23,  4.62s/it] 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 262/357 [26:20<07:15,  4.59s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 263/357 [26:25<07:09,  4.57s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 264/357 [26:29<07:02,  4.55s/it] 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 265/357 [26:34<07:07,  4.65s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 266/357 [26:39<06:59,  4.61s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 267/357 [26:43<06:51,  4.58s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 268/357 [26:48<06:45,  4.55s/it] 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 269/357 [26:52<06:39,  4.54s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [26:57<06:44,  4.65s/it]                                                  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 270/357 [26:57<06:44,  4.65s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 271/357 [27:02<06:36,  4.61s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 272/357 [27:06<06:28,  4.58s/it] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 273/357 [27:11<06:22,  4.56s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 274/357 [27:15<06:16,  4.54s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 275/357 [27:20<06:21,  4.65s/it] 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 276/357 [27:25<06:12,  4.60s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 277/357 [27:29<06:06,  4.58s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 278/357 [27:34<05:59,  4.56s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 279/357 [27:38<06:03,  4.66s/it] 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [27:43<05:55,  4.62s/it]                                                  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 280/357 [27:43<05:55,  4.62s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 281/357 [27:47<05:48,  4.58s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 282/357 [27:52<05:42,  4.56s/it] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 283/357 [27:57<05:36,  4.55s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 284/357 [28:01<05:39,  4.65s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 285/357 [28:06<05:31,  4.61s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 286/357 [28:10<05:25,  4.58s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 287/357 [28:15<05:19,  4.56s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 288/357 [28:19<05:13,  4.54s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 289/357 [28:24<05:16,  4.65s/it] 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [28:29<05:08,  4.61s/it]                                                  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 290/357 [28:29<05:08,  4.61s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 291/357 [28:33<05:02,  4.58s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 292/357 [28:38<04:56,  4.56s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 293/357 [28:42<04:50,  4.54s/it] 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 294/357 [28:47<04:53,  4.67s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 295/357 [28:52<04:46,  4.62s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 296/357 [28:56<04:39,  4.58s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 297/357 [29:01<04:33,  4.56s/it] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 298/357 [29:06<04:35,  4.68s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 299/357 [29:10<04:28,  4.63s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:15<04:21,  4.59s/it]                                                  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 300/357 [29:15<04:21,  4.59s/it] 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 301/357 [29:19<04:15,  4.57s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 302/357 [29:24<04:10,  4.55s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 303/357 [29:29<04:11,  4.66s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 304/357 [29:33<04:04,  4.62s/it] 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 305/357 [29:38<03:58,  4.59s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 306/357 [29:42<03:52,  4.56s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 307/357 [29:47<03:47,  4.55s/it] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 308/357 [29:52<03:48,  4.66s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 309/357 [29:56<03:41,  4.62s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:01<03:35,  4.58s/it]                                                  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 310/357 [30:01<03:35,  4.58s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 311/357 [30:05<03:29,  4.56s/it] 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 312/357 [30:10<03:24,  4.55s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 313/357 [30:15<03:24,  4.66s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 314/357 [30:19<03:18,  4.61s/it] 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 315/357 [30:24<03:12,  4.59s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 316/357 [30:28<03:07,  4.56s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 317/357 [30:33<03:01,  4.55s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 318/357 [30:38<03:01,  4.66s/it] 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 319/357 [30:42<02:55,  4.62s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [30:47<02:49,  4.59s/it]                                                  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 320/357 [30:47<02:49,  4.59s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 321/357 [30:51<02:44,  4.56s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 322/357 [30:56<02:43,  4.67s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 323/357 [31:01<02:37,  4.62s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 324/357 [31:05<02:31,  4.59s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 325/357 [31:10<02:26,  4.56s/it] 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 326/357 [31:14<02:20,  4.55s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 327/357 [31:19<02:19,  4.65s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 328/357 [31:24<02:13,  4.61s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 329/357 [31:28<02:08,  4.58s/it] 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [31:33<02:03,  4.56s/it]                                                  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 330/357 [31:33<02:03,  4.56s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 331/357 [31:37<01:58,  4.54s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 332/357 [31:42<01:56,  4.65s/it] 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 333/357 [31:47<01:50,  4.61s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 334/357 [31:51<01:45,  4.58s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 335/357 [31:56<01:40,  4.56s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 336/357 [32:00<01:35,  4.54s/it] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 337/357 [32:05<01:33,  4.65s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 338/357 [32:09<01:27,  4.61s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 339/357 [32:14<01:22,  4.58s/it] 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [32:18<01:17,  4.56s/it]                                                  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 340/357 [32:18<01:17,  4.56s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 341/357 [32:23<01:14,  4.66s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 342/357 [32:28<01:09,  4.62s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 343/357 [32:32<01:04,  4.59s/it] 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 344/357 [32:37<00:59,  4.56s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 345/357 [32:41<00:54,  4.55s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 346/357 [32:46<00:51,  4.66s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 347/357 [32:51<00:46,  4.61s/it] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 348/357 [32:55<00:41,  4.58s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 349/357 [33:00<00:36,  4.56s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:04<00:31,  4.55s/it]                                                  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 350/357 [33:04<00:31,  4.55s/it] 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 351/357 [33:09<00:28,  4.67s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 352/357 [33:14<00:23,  4.62s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 353/357 [33:18<00:18,  4.59s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 354/357 [33:23<00:13,  4.57s/it] 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 355/357 [33:27<00:09,  4.55s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 356/357 [33:32<00:04,  4.67s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [33:36<00:00,  4.28s/it]{'eval_loss': 0.010994014330208302, 'eval_runtime': 36.7206, 'eval_samples_per_second': 2.723, 'eval_steps_per_second': 0.681, 'epoch': 2.0}

==================================================
Testing model performance...
==================================================
Generated solution:
should not produce any explanation, just the plan lines. Must adhere to regex: `^\(\w+(?:\s+\w+)*\)$` per line. So each line starts with '(' and ends with ')', action name and object names separated by single spaces, no extra characters. No empty lines, no trailing spaces, no leading spaces, no punctuation beyond parentheses and words.

Also must handle constraints: domain includes :requirements :strips :typing, so no :durations, no :probabilities, so it's a PDDL2 task. Problem includes no :constraints shown, so assume none. So if initial state satisfies goals and no constraints, output nothing. But here initial goals are not satisfied: initial has ball1 room4, ball2 room4, ball3 room2. Goals require ball1 room2, ball2 room2, ball3 room2. So need to plan moves to get ball1 and ball2 to room2, ball3 already at room2. Robot at room1.

We must plan using only PDDL actions, no derived predicates, no constraints. Just a goal-directed plan.

We need to produce the steps. Let's manually think.

Initial state:
- robot1 at room1
- free grippers: rgripper1, lgripper1
- ball1 at room4
- ball2 at room4
- ball3 at room2

Goal:
- ball1 at room2
- ball2 at room2
- ball3 at room2

So ball3 already at room2, good. ball1 and ball2 need to room2.

Robots at room1, can move to rooms.

Rooms: room1,2,3,4.

Movement: move robot from from to to, free grippers remain.

Pick: robot at room, ball at room, free gripper.

Drop: robot at room, ball at room.

We
==================================================
{'loss': 0.0111, 'grad_norm': 0.11271223425865173, 'learning_rate': 5.959473376986686e-06, 'epoch': 2.02}
{'loss': 0.0111, 'grad_norm': 0.10524483770132065, 'learning_rate': 5.084995082868658e-06, 'epoch': 2.1}
{'loss': 0.011, 'grad_norm': 0.06414394825696945, 'learning_rate': 4.257556750327176e-06, 'epoch': 2.19}
{'loss': 0.011, 'grad_norm': 0.0637669786810875, 'learning_rate': 3.485077530619664e-06, 'epoch': 2.27}
{'loss': 0.0109, 'grad_norm': 0.07118778675794601, 'learning_rate': 2.77495057867198e-06, 'epoch': 2.35}
{'loss': 0.011, 'grad_norm': 0.1456853151321411, 'learning_rate': 2.133972295524875e-06, 'epoch': 2.44}
{'loss': 0.0109, 'grad_norm': 0.14748086035251617, 'learning_rate': 1.5682772821236192e-06, 'epoch': 2.52}
{'loss': 0.0108, 'grad_norm': 0.06342726200819016, 'learning_rate': 1.0832796269875757e-06, 'epoch': 2.61}
{'loss': 0.0109, 'grad_norm': 0.10389414429664612, 'learning_rate': 6.836210896769014e-07, 'epoch': 2.69}
{'loss': 0.0109, 'grad_norm': 0.0932689681649208, 'learning_rate': 3.731266759760854e-07, 'epoch': 2.77}
{'loss': 0.0111, 'grad_norm': 0.05137017369270325, 'learning_rate': 1.5476802997022812e-07, 'epoch': 2.86}
{'loss': 0.011, 'grad_norm': 0.06536740809679031, 'learning_rate': 3.063499337692788e-08, 'epoch': 2.94}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.42it/s][A
 12%|â–ˆâ–        | 3/25 [00:02<00:21,  1.00it/s][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:24,  1.15s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.40s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:26,  1.41s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:08<00:25,  1.41s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:10<00:23,  1.41s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:11<00:23,  1.47s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:13<00:21,  1.45s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:14<00:20,  1.44s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:16<00:18,  1.43s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:17<00:17,  1.48s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:19<00:16,  1.46s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:20<00:14,  1.45s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:22<00:12,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:23<00:11,  1.49s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:25<00:10,  1.46s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:26<00:08,  1.45s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:27<00:07,  1.44s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:29<00:05,  1.49s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:30<00:04,  1.47s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:32<00:02,  1.45s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:33<00:01,  1.44s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A                                                 
                                               [A100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:12<00:00,  4.28s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:35<00:00,  1.49s/it][A
                                               [A                                                 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:44<00:00,  4.28s/it]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 357/357 [34:44<00:00,  5.84s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–â–
wandb:            eval/runtime â–ˆâ–‚â–
wandb: eval/samples_per_second â–â–ˆâ–ˆ
wandb:   eval/steps_per_second â–â–ˆâ–ˆ
wandb:             train/epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/learning_rate â–ƒâ–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–
wandb:              train/loss â–ˆâ–‡â–…â–ƒâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.01087
wandb:            eval/runtime 36.718
wandb: eval/samples_per_second 2.723
wandb:   eval/steps_per_second 0.681
wandb:              total_flos 7.127275269390336e+17
wandb:             train/epoch 3
wandb:       train/global_step 357
wandb:         train/grad_norm 0.06537
wandb:     train/learning_rate 0.0
wandb:              train/loss 0.011
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_pddl2 at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/jz1oz3gy
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251031_042906-jz1oz3gy/logs
{'eval_loss': 0.010872740298509598, 'eval_runtime': 36.718, 'eval_samples_per_second': 2.723, 'eval_steps_per_second': 0.681, 'epoch': 3.0}

==================================================
Testing model performance...
==================================================
Generated solution:
commentary,functionsprompt=promptcommentary# The user is requesting the final plan only, no reasoning, no headers, no footers, no empty lines, no trailing spaces.
# We must first internally determine if a valid plan exists, considering all DOMAIN/PROBLEM constraints, typing, etc.
# If none, emit (NO-PLAN) as a single line.
# If a plan exists, generate each action as a grounded tuple, one per line.
# Ensure no constraints: If constraints in PROBLEM, still ignore them in output; just produce plan that satisfies them.
# So compute plan here in commentary.
# Let's analyze the DOMAIN and PROBLEM.

# DOMAIN: gripper-strips
# Requirements: :strips :typing
# TYPES: room, object, robot, gripper
# PREDICATES: at-robby ?r - robot ?x - room
#              at ?o - object ?x - room
#              free ?r - robot ?g - gripper
#              carry ?r - robot ?o - object ?g - gripper
# Actions:
# move: params ?r - robot ?from ?to - room
# pre: at-robby ?r ?from
# effect: at-robby ?r ?to, not at-robby ?r ?from
# pick: params ?r - robot ?obj - object ?room - room ?g - gripper
# pre: at ?obj ?room, at-robby ?r ?room, free ?r ?g
# effect: carry ?r ?obj ?g, not at ?obj ?room, not free ?r ?g
# drop: params ?r - robot ?obj - object ?room - room ?g - gripper
# pre: carry ?r ?obj ?g, at-robby ?r ?room
# effect: at ?obj ?room, free ?r ?g, not carry ?r ?obj ?g

# PROBLEM: gripper-1-4-3
# :domain gripper-strips
# :objects robot1 - robot
#               rgripper1 lgripper1 - gripper
#               room1 room2 room3 room4 - room
#               ball1 ball2 ball3 - object
# :initial
# at-robby robot1 room1
# free robot1 rgripper1
# free robot1
==================================================
{'train_runtime': 2084.0913, 'train_samples_per_second': 2.735, 'train_steps_per_second': 0.171, 'train_loss': 0.4192463634561758, 'epoch': 3.0}

Saving model to sft_models/gpt_oss_20b/grippers/pddl2 ...
Training completed!

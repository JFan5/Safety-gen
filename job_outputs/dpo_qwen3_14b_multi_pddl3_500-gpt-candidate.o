
CondaError: Run 'conda init' before 'conda activate'

[torchao|WARNING]Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.10.12: Fast Qwen3 patching. Transformers: 4.56.2.
   \\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 1/3 [00:01<00:02,  1.43s/it]Loading checkpoint shards:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 2/3 [00:08<00:04,  4.46s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.81s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.41s/it]
Unsloth 2025.10.12 patched 40 layers with 0 QKV layers, 0 O layers and 0 MLP layers.
unsloth/Qwen3-14B-unsloth-bnb-4bit does not have a padding token! Will use pad_token = <|vision_pad|>.
Extracting prompt in train dataset (num_proc=32):   0%|          | 0/2152 [00:00<?, ? examples/s]Extracting prompt in train dataset (num_proc=32):   3%|â–Ž         | 68/2152 [00:01<00:35, 58.26 examples/s]Extracting prompt in train dataset (num_proc=32):   6%|â–‹         | 136/2152 [00:01<00:16, 119.45 examples/s]Extracting prompt in train dataset (num_proc=32):   9%|â–‰         | 204/2152 [00:01<00:10, 186.11 examples/s]Extracting prompt in train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 340/2152 [00:01<00:05, 323.40 examples/s]Extracting prompt in train dataset (num_proc=32):  19%|â–ˆâ–‰        | 408/2152 [00:01<00:04, 373.17 examples/s]Extracting prompt in train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 476/2152 [00:01<00:04, 405.94 examples/s]Extracting prompt in train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 544/2152 [00:01<00:03, 447.46 examples/s]Extracting prompt in train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 678/2152 [00:02<00:02, 533.65 examples/s]Extracting prompt in train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 745/2152 [00:02<00:02, 546.60 examples/s]Extracting prompt in train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 812/2152 [00:02<00:02, 552.30 examples/s]Extracting prompt in train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 879/2152 [00:02<00:02, 557.99 examples/s]Extracting prompt in train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 946/2152 [00:02<00:02, 525.14 examples/s]Extracting prompt in train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1080/2152 [00:02<00:01, 589.74 examples/s]Extracting prompt in train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1147/2152 [00:02<00:01, 567.61 examples/s]Extracting prompt in train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1281/2152 [00:03<00:01, 644.61 examples/s]Extracting prompt in train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1348/2152 [00:03<00:01, 581.82 examples/s]Extracting prompt in train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1415/2152 [00:03<00:01, 568.70 examples/s]Extracting prompt in train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1482/2152 [00:03<00:01, 575.67 examples/s]Extracting prompt in train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1549/2152 [00:03<00:01, 561.89 examples/s]Extracting prompt in train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1683/2152 [00:03<00:00, 598.87 examples/s]Extracting prompt in train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1750/2152 [00:03<00:00, 607.66 examples/s]Extracting prompt in train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1817/2152 [00:04<00:00, 579.95 examples/s]Extracting prompt in train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1884/2152 [00:04<00:00, 578.20 examples/s]Extracting prompt in train dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 1951/2152 [00:04<00:00, 569.25 examples/s]Extracting prompt in train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2018/2152 [00:04<00:00, 536.93 examples/s]Extracting prompt in train dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2085/2152 [00:04<00:00, 564.67 examples/s]Extracting prompt in train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2152/2152 [00:04<00:00, 567.81 examples/s]Extracting prompt in train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2152/2152 [00:05<00:00, 420.94 examples/s]
Applying chat template to train dataset (num_proc=32):   0%|          | 0/2152 [00:00<?, ? examples/s]Applying chat template to train dataset (num_proc=32):   3%|â–Ž         | 68/2152 [00:01<00:55, 37.56 examples/s]Applying chat template to train dataset (num_proc=32):   6%|â–‹         | 136/2152 [00:01<00:24, 81.44 examples/s]Applying chat template to train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 272/2152 [00:02<00:10, 174.12 examples/s]Applying chat template to train dataset (num_proc=32):  16%|â–ˆâ–Œ        | 340/2152 [00:02<00:08, 219.46 examples/s]Applying chat template to train dataset (num_proc=32):  19%|â–ˆâ–‰        | 408/2152 [00:02<00:06, 266.43 examples/s]Applying chat template to train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 476/2152 [00:02<00:05, 308.58 examples/s]Applying chat template to train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 544/2152 [00:02<00:04, 355.33 examples/s]Applying chat template to train dataset (num_proc=32):  32%|â–ˆâ–ˆâ–ˆâ–      | 678/2152 [00:02<00:02, 497.73 examples/s]Applying chat template to train dataset (num_proc=32):  35%|â–ˆâ–ˆâ–ˆâ–      | 745/2152 [00:03<00:02, 482.62 examples/s]Applying chat template to train dataset (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 812/2152 [00:03<00:02, 473.95 examples/s]Applying chat template to train dataset (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 879/2152 [00:03<00:02, 475.61 examples/s]Applying chat template to train dataset (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 946/2152 [00:03<00:02, 488.11 examples/s]Applying chat template to train dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1013/2152 [00:03<00:02, 478.17 examples/s]Applying chat template to train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1080/2152 [00:03<00:02, 484.53 examples/s]Applying chat template to train dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1147/2152 [00:03<00:02, 465.19 examples/s]Applying chat template to train dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1214/2152 [00:04<00:02, 460.49 examples/s]Applying chat template to train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1281/2152 [00:04<00:01, 475.08 examples/s]Applying chat template to train dataset (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1348/2152 [00:04<00:02, 319.50 examples/s]Applying chat template to train dataset (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1415/2152 [00:04<00:02, 354.53 examples/s]Applying chat template to train dataset (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1482/2152 [00:04<00:01, 373.93 examples/s]Applying chat template to train dataset (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1549/2152 [00:04<00:01, 404.57 examples/s]Applying chat template to train dataset (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 1616/2152 [00:05<00:01, 434.16 examples/s]Applying chat template to train dataset (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 1683/2152 [00:05<00:00, 480.48 examples/s]Applying chat template to train dataset (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1750/2152 [00:05<00:00, 405.93 examples/s]Applying chat template to train dataset (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1817/2152 [00:05<00:00, 421.92 examples/s]Applying chat template to train dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 1884/2152 [00:05<00:00, 428.10 examples/s]Applying chat template to train dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2018/2152 [00:06<00:00, 409.48 examples/s]Applying chat template to train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2152/2152 [00:06<00:00, 508.97 examples/s]Applying chat template to train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2152/2152 [00:06<00:00, 321.39 examples/s]
Tokenizing train dataset (num_proc=32):   0%|          | 0/2152 [00:00<?, ? examples/s]Tokenizing train dataset (num_proc=32):   1%|          | 20/2152 [00:01<03:28, 10.23 examples/s]Tokenizing train dataset (num_proc=32):   3%|â–Ž         | 65/2152 [00:02<00:53, 39.36 examples/s]Tokenizing train dataset (num_proc=32):   4%|â–         | 88/2152 [00:02<00:38, 53.76 examples/s]Tokenizing train dataset (num_proc=32):   7%|â–‹         | 155/2152 [00:02<00:18, 110.55 examples/s]Tokenizing train dataset (num_proc=32):   9%|â–‰         | 194/2152 [00:02<00:14, 137.01 examples/s]Tokenizing train dataset (num_proc=32):  13%|â–ˆâ–Ž        | 271/2152 [00:02<00:08, 210.74 examples/s]Tokenizing train dataset (num_proc=32):  14%|â–ˆâ–        | 310/2152 [00:02<00:08, 225.02 examples/s]Tokenizing train dataset (num_proc=32):  20%|â–ˆâ–‰        | 425/2152 [00:03<00:04, 355.59 examples/s]Tokenizing train dataset (num_proc=32):  22%|â–ˆâ–ˆâ–       | 476/2152 [00:03<00:04, 355.79 examples/s]Tokenizing train dataset (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 541/2152 [00:03<00:04, 371.58 examples/s]Tokenizing train dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 589/2152 [00:03<00:04, 345.87 examples/s]Tokenizing train dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 652/2152 [00:03<00:04, 362.89 examples/s]Tokenizing train dataset (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 723/2152 [00:03<00:03, 385.95 examples/s]Tokenizing train dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 790/2152 [00:03<00:03, 401.44 examples/s]Tokenizing train dataset (num_proc=32):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 850/2152 [00:04<00:03, 402.14 examples/s]Tokenizing train dataset (num_proc=32):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 899/2152 [00:04<00:03, 345.81 examples/s]Tokenizing train dataset (num_proc=32):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 966/2152 [00:04<00:04, 279.64 examples/s]Tokenizing train dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1075/2152 [00:04<00:03, 338.64 examples/s]Tokenizing train dataset (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1122/2152 [00:05<00:03, 323.72 examples/s]Tokenizing train dataset (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1186/2152 [00:05<00:02, 325.68 examples/s]Tokenizing train dataset (num_proc=32):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1234/2152 [00:05<00:02, 309.06 examples/s]Tokenizing train dataset (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1301/2152 [00:05<00:02, 320.75 examples/s]Tokenizing train dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1402/2152 [00:05<00:01, 390.68 examples/s]Tokenizing train dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1455/2152 [00:05<00:01, 354.93 examples/s]Tokenizing train dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1522/2152 [00:06<00:01, 348.21 examples/s]Tokenizing train dataset (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1568/2152 [00:06<00:01, 321.44 examples/s]Tokenizing train dataset (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 1703/2152 [00:06<00:01, 313.01 examples/s]Tokenizing train dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 1770/2152 [00:06<00:01, 338.04 examples/s]Tokenizing train dataset (num_proc=32):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 1926/2152 [00:07<00:00, 446.30 examples/s]Tokenizing train dataset (num_proc=32):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 1991/2152 [00:07<00:00, 460.53 examples/s]Tokenizing train dataset (num_proc=32):  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2048/2152 [00:07<00:00, 427.50 examples/s]Tokenizing train dataset (num_proc=32):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2127/2152 [00:07<00:00, 485.22 examples/s]Tokenizing train dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2152/2152 [00:08<00:00, 266.13 examples/s]
Extracting prompt in eval dataset (num_proc=32):   0%|          | 0/240 [00:00<?, ? examples/s]Extracting prompt in eval dataset (num_proc=32):   3%|â–Ž         | 8/240 [00:01<00:38,  6.03 examples/s]Extracting prompt in eval dataset (num_proc=32):   7%|â–‹         | 16/240 [00:01<00:16, 13.20 examples/s]Extracting prompt in eval dataset (num_proc=32):  10%|â–ˆ         | 24/240 [00:01<00:10, 21.01 examples/s]Extracting prompt in eval dataset (num_proc=32):  17%|â–ˆâ–‹        | 40/240 [00:01<00:05, 35.35 examples/s]Extracting prompt in eval dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 48/240 [00:01<00:04, 41.51 examples/s]Extracting prompt in eval dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 56/240 [00:01<00:03, 46.37 examples/s]Extracting prompt in eval dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 72/240 [00:02<00:02, 58.93 examples/s]Extracting prompt in eval dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 80/240 [00:02<00:02, 61.44 examples/s]Extracting prompt in eval dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 88/240 [00:02<00:02, 63.85 examples/s]Extracting prompt in eval dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 96/240 [00:02<00:02, 67.49 examples/s]Extracting prompt in eval dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 104/240 [00:02<00:01, 68.55 examples/s]Extracting prompt in eval dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 120/240 [00:02<00:01, 73.50 examples/s]Extracting prompt in eval dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 128/240 [00:02<00:01, 74.27 examples/s]Extracting prompt in eval dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 142/240 [00:03<00:01, 67.72 examples/s]Extracting prompt in eval dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 156/240 [00:03<00:01, 66.40 examples/s]Extracting prompt in eval dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 170/240 [00:03<00:01, 67.55 examples/s]Extracting prompt in eval dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 184/240 [00:03<00:00, 66.54 examples/s]Extracting prompt in eval dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 198/240 [00:03<00:00, 67.86 examples/s]Extracting prompt in eval dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 212/240 [00:04<00:00, 68.78 examples/s]Extracting prompt in eval dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 219/240 [00:04<00:00, 66.86 examples/s]Extracting prompt in eval dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 233/240 [00:04<00:00, 66.82 examples/s]Extracting prompt in eval dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:04<00:00, 48.48 examples/s]
Applying chat template to eval dataset (num_proc=32):   0%|          | 0/240 [00:00<?, ? examples/s]Applying chat template to eval dataset (num_proc=32):   3%|â–Ž         | 8/240 [00:01<00:48,  4.76 examples/s]Applying chat template to eval dataset (num_proc=32):   7%|â–‹         | 16/240 [00:01<00:21, 10.50 examples/s]Applying chat template to eval dataset (num_proc=32):  13%|â–ˆâ–Ž        | 32/240 [00:01<00:08, 23.14 examples/s]Applying chat template to eval dataset (num_proc=32):  17%|â–ˆâ–‹        | 40/240 [00:02<00:06, 29.37 examples/s]Applying chat template to eval dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 48/240 [00:02<00:05, 35.21 examples/s]Applying chat template to eval dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 56/240 [00:02<00:04, 40.33 examples/s]Applying chat template to eval dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 72/240 [00:02<00:02, 58.09 examples/s]Applying chat template to eval dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 88/240 [00:02<00:02, 56.77 examples/s]Applying chat template to eval dataset (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 96/240 [00:02<00:02, 56.91 examples/s]Applying chat template to eval dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 104/240 [00:03<00:02, 59.80 examples/s]Applying chat template to eval dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 112/240 [00:03<00:02, 61.81 examples/s]Applying chat template to eval dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 120/240 [00:03<00:02, 54.61 examples/s]Applying chat template to eval dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 128/240 [00:03<00:01, 59.61 examples/s]Applying chat template to eval dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 135/240 [00:03<00:01, 60.02 examples/s]Applying chat template to eval dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 142/240 [00:03<00:01, 59.28 examples/s]Applying chat template to eval dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 149/240 [00:03<00:01, 58.09 examples/s]Applying chat template to eval dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 156/240 [00:03<00:01, 58.72 examples/s]Applying chat template to eval dataset (num_proc=32):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 170/240 [00:04<00:01, 58.73 examples/s]Applying chat template to eval dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 184/240 [00:04<00:01, 54.53 examples/s]Applying chat template to eval dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 198/240 [00:04<00:00, 64.29 examples/s]Applying chat template to eval dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 205/240 [00:04<00:00, 63.92 examples/s]Applying chat template to eval dataset (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 212/240 [00:04<00:00, 62.31 examples/s]Applying chat template to eval dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 219/240 [00:04<00:00, 60.58 examples/s]Applying chat template to eval dataset (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 226/240 [00:05<00:00, 56.96 examples/s]Applying chat template to eval dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:05<00:00, 63.24 examples/s]Applying chat template to eval dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:05<00:00, 42.07 examples/s]
Tokenizing eval dataset (num_proc=32):   0%|          | 0/240 [00:00<?, ? examples/s]Tokenizing eval dataset (num_proc=32):   3%|â–Ž         | 8/240 [00:01<00:51,  4.47 examples/s]Tokenizing eval dataset (num_proc=32):   7%|â–‹         | 16/240 [00:01<00:22,  9.96 examples/s]Tokenizing eval dataset (num_proc=32):  10%|â–ˆ         | 24/240 [00:02<00:13, 16.31 examples/s]Tokenizing eval dataset (num_proc=32):  13%|â–ˆâ–Ž        | 32/240 [00:02<00:08, 23.70 examples/s]Tokenizing eval dataset (num_proc=32):  17%|â–ˆâ–‹        | 40/240 [00:02<00:06, 31.10 examples/s]Tokenizing eval dataset (num_proc=32):  20%|â–ˆâ–ˆ        | 48/240 [00:02<00:04, 39.10 examples/s]Tokenizing eval dataset (num_proc=32):  23%|â–ˆâ–ˆâ–Ž       | 56/240 [00:02<00:04, 45.83 examples/s]Tokenizing eval dataset (num_proc=32):  27%|â–ˆâ–ˆâ–‹       | 64/240 [00:02<00:03, 51.93 examples/s]Tokenizing eval dataset (num_proc=32):  30%|â–ˆâ–ˆâ–ˆ       | 72/240 [00:02<00:03, 55.09 examples/s]Tokenizing eval dataset (num_proc=32):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 80/240 [00:02<00:02, 59.24 examples/s]Tokenizing eval dataset (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 88/240 [00:03<00:02, 50.90 examples/s]Tokenizing eval dataset (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 104/240 [00:03<00:01, 68.67 examples/s]Tokenizing eval dataset (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 112/240 [00:03<00:01, 68.93 examples/s]Tokenizing eval dataset (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 120/240 [00:03<00:01, 66.21 examples/s]Tokenizing eval dataset (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 128/240 [00:03<00:01, 65.89 examples/s]Tokenizing eval dataset (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 135/240 [00:03<00:01, 54.55 examples/s]Tokenizing eval dataset (num_proc=32):  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 142/240 [00:03<00:01, 56.37 examples/s]Tokenizing eval dataset (num_proc=32):  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 149/240 [00:03<00:01, 59.18 examples/s]Tokenizing eval dataset (num_proc=32):  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 156/240 [00:04<00:01, 61.52 examples/s]Tokenizing eval dataset (num_proc=32):  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 163/240 [00:04<00:01, 54.40 examples/s]Tokenizing eval dataset (num_proc=32):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 177/240 [00:04<00:00, 67.64 examples/s]Tokenizing eval dataset (num_proc=32):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 184/240 [00:04<00:00, 56.93 examples/s]Tokenizing eval dataset (num_proc=32):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 191/240 [00:04<00:00, 52.20 examples/s]Tokenizing eval dataset (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 198/240 [00:04<00:00, 51.41 examples/s]Tokenizing eval dataset (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 205/240 [00:04<00:00, 52.68 examples/s]Tokenizing eval dataset (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 219/240 [00:05<00:00, 72.22 examples/s]Tokenizing eval dataset (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 233/240 [00:05<00:00, 63.70 examples/s]Tokenizing eval dataset (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [00:05<00:00, 40.80 examples/s]
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 2,152 | Num Epochs = 4 | Total steps = 4,304
O^O/ \_/ \    Batch size per device = 1 | Gradient accumulation steps = 2
\        /    Data Parallel GPUs = 1 | Total batch size (1 x 2 x 1) = 2
 "-____-"     Trainable parameters = 128,450,560 of 14,896,757,760 (0.86% trained)
eval steps:  60
  0%|          | 0/4304 [00:00<?, ?it/s]  0%|          | 1/4304 [00:04<5:25:37,  4.54s/it]  0%|          | 2/4304 [00:06<3:28:19,  2.91s/it]  0%|          | 3/4304 [00:09<3:29:37,  2.92s/it]  0%|          | 4/4304 [00:12<3:25:55,  2.87s/it]  0%|          | 5/4304 [00:13<2:57:26,  2.48s/it]  0%|          | 6/4304 [00:15<2:39:10,  2.22s/it]  0%|          | 7/4304 [00:17<2:31:00,  2.11s/it]  0%|          | 8/4304 [00:19<2:21:38,  1.98s/it]  0%|          | 9/4304 [00:20<2:16:34,  1.91s/it]  0%|          | 10/4304 [00:22<2:16:28,  1.91s/it]                                                     0%|          | 10/4304 [00:22<2:16:28,  1.91s/it]  0%|          | 11/4304 [00:24<2:16:47,  1.91s/it]  0%|          | 12/4304 [00:26<2:12:51,  1.86s/it]  0%|          | 13/4304 [00:28<2:15:17,  1.89s/it]  0%|          | 14/4304 [00:30<2:17:00,  1.92s/it]  0%|          | 15/4304 [00:32<2:15:28,  1.90s/it]  0%|          | 16/4304 [00:34<2:14:27,  1.88s/it]  0%|          | 17/4304 [00:36<2:16:20,  1.91s/it]  0%|          | 18/4304 [00:37<2:16:21,  1.91s/it]  0%|          | 19/4304 [00:40<2:20:19,  1.96s/it]  0%|          | 20/4304 [00:41<2:15:10,  1.89s/it]                                                     0%|          | 20/4304 [00:41<2:15:10,  1.89s/it]  0%|          | 21/4304 [00:43<2:13:00,  1.86s/it]  1%|          | 22/4304 [00:45<2:10:06,  1.82s/it]  1%|          | 23/4304 [00:47<2:13:56,  1.88s/it]  1%|          | 24/4304 [00:49<2:14:27,  1.88s/it]  1%|          | 25/4304 [00:51<2:16:19,  1.91s/it]  1%|          | 26/4304 [00:53<2:17:29,  1.93s/it]  1%|          | 27/4304 [00:55<2:16:16,  1.91s/it]  1%|          | 28/4304 [00:56<2:12:53,  1.86s/it]  1%|          | 29/4304 [00:58<2:12:57,  1.87s/it]  1%|          | 30/4304 [01:00<2:14:27,  1.89s/it]                                                     1%|          | 30/4304 [01:00<2:14:27,  1.89s/it]  1%|          | 31/4304 [01:02<2:16:50,  1.92s/it]  1%|          | 32/4304 [01:04<2:18:17,  1.94s/it]  1%|          | 33/4304 [01:06<2:16:34,  1.92s/it]  1%|          | 34/4304 [01:08<2:12:55,  1.87s/it]  1%|          | 35/4304 [01:09<2:10:14,  1.83s/it]  1%|          | 36/4304 [01:11<2:08:37,  1.81s/it]  1%|          | 37/4304 [01:13<2:07:22,  1.79s/it]  1%|          | 38/4304 [03:44<55:11:40, 46.58s/it]  1%|          | 39/4304 [03:49<40:32:29, 34.22s/it]  1%|          | 40/4304 [04:18<38:30:51, 32.52s/it]                                                      1%|          | 40/4304 [04:20<38:30:51, 32.52s/it]  1%|          | 41/4304 [04:29<30:43:00, 25.94s/it]  1%|          | 42/4304 [04:54<30:34:03, 25.82s/it]  1%|          | 43/4304 [04:56<22:03:14, 18.63s/it]  1%|          | 44/4304 [04:58<16:03:19, 13.57s/it]  1%|          | 45/4304 [05:00<11:57:10, 10.10s/it]  1%|          | 46/4304 [06:03<30:39:51, 25.93s/it]  1%|          | 47/4304 [06:04<22:06:46, 18.70s/it]  1%|          | 48/4304 [06:06<16:06:11, 13.62s/it]  1%|          | 49/4304 [06:08<11:58:47, 10.14s/it]  1%|          | 50/4304 [06:10<9:00:39,  7.63s/it]                                                      1%|          | 50/4304 [06:10<9:00:39,  7.63s/it]  1%|          | 51/4304 [06:12<6:56:31,  5.88s/it]  1%|          | 52/4304 [06:14<5:29:19,  4.65s/it]  1%|          | 53/4304 [06:15<4:28:41,  3.79s/it]  1%|â–         | 54/4304 [06:17<3:46:03,  3.19s/it]  1%|â–         | 55/4304 [07:02<18:35:11, 15.75s/it]  1%|â–         | 56/4304 [07:05<13:58:42, 11.85s/it]  1%|â–         | 57/4304 [07:07<10:26:46,  8.85s/it]  1%|â–         | 58/4304 [07:09<8:00:41,  6.79s/it]   1%|â–         | 59/4304 [07:11<6:16:13,  5.32s/it]  1%|â–         | 60/4304 [07:12<5:02:36,  4.28s/it]                                                     1%|â–         | 60/4304 [07:12<5:02:36,  4.28s/it]Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.9398, 'grad_norm': 112.69718170166016, 'learning_rate': 1.0440835266821346e-07, 'rewards/chosen': 4.076178550720215, 'rewards/rejected': 4.081119060516357, 'rewards/accuracies': 0.44999998807907104, 'rewards/margins': -0.004940641112625599, 'logps/chosen': -27.14691162109375, 'logps/rejected': -63.056861877441406, 'logits/chosen': -2.542595386505127, 'logits/rejected': -2.2696309089660645, 'epoch': 0.01}
{'loss': 0.9753, 'grad_norm': 54.964962005615234, 'learning_rate': 2.2041763341067286e-07, 'rewards/chosen': 7.734889984130859, 'rewards/rejected': 3.9737389087677, 'rewards/accuracies': 0.6000000238418579, 'rewards/margins': 3.761151075363159, 'logps/chosen': -79.06369018554688, 'logps/rejected': -69.8782730102539, 'logits/chosen': -2.648416757583618, 'logits/rejected': -2.3669040203094482, 'epoch': 0.02}
{'loss': 0.3883, 'grad_norm': 44.67726516723633, 'learning_rate': 3.3642691415313226e-07, 'rewards/chosen': 4.689111709594727, 'rewards/rejected': 3.4251785278320312, 'rewards/accuracies': 0.8999999761581421, 'rewards/margins': 1.2639328241348267, 'logps/chosen': -33.66000747680664, 'logps/rejected': -72.16934204101562, 'logits/chosen': -2.7289958000183105, 'logits/rejected': -2.4791722297668457, 'epoch': 0.03}
{'loss': 0.2484, 'grad_norm': 3.1937503814697266, 'learning_rate': 4.5243619489559166e-07, 'rewards/chosen': 4.139008045196533, 'rewards/rejected': 1.4532588720321655, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 2.6857495307922363, 'logps/chosen': -24.801044464111328, 'logps/rejected': -85.3445053100586, 'logits/chosen': -2.7349305152893066, 'logits/rejected': -2.331188201904297, 'epoch': 0.04}
{'loss': 0.3579, 'grad_norm': 1.771221399307251, 'learning_rate': 5.684454756380511e-07, 'rewards/chosen': 3.067091464996338, 'rewards/rejected': -0.5180354714393616, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 3.5851268768310547, 'logps/chosen': -43.23275375366211, 'logps/rejected': -89.4716796875, 'logits/chosen': -2.789844274520874, 'logits/rejected': -2.509364128112793, 'epoch': 0.05}
{'loss': 0.3097, 'grad_norm': 17.923664093017578, 'learning_rate': 6.844547563805106e-07, 'rewards/chosen': 3.3210983276367188, 'rewards/rejected': -1.094731092453003, 'rewards/accuracies': 0.8500000238418579, 'rewards/margins': 4.415829658508301, 'logps/chosen': -40.61774444580078, 'logps/rejected': -88.54338073730469, 'logits/chosen': -2.6877171993255615, 'logits/rejected': -2.4390902519226074, 'epoch': 0.06}

  0%|          | 0/240 [00:00<?, ?it/s][A
  1%|          | 2/240 [00:00<00:49,  4.79it/s][A
  1%|â–         | 3/240 [00:00<01:14,  3.18it/s][A
  2%|â–         | 4/240 [00:01<01:22,  2.86it/s][A
  2%|â–         | 5/240 [00:01<01:35,  2.47it/s][A
  2%|â–Ž         | 6/240 [00:02<01:35,  2.45it/s][A
  3%|â–Ž         | 7/240 [00:02<01:35,  2.43it/s][A
  3%|â–Ž         | 8/240 [00:03<01:35,  2.44it/s][A
  4%|â–         | 9/240 [00:03<01:35,  2.41it/s][A
  4%|â–         | 10/240 [00:36<40:33, 10.58s/it][A
  5%|â–         | 11/240 [00:37<28:53,  7.57s/it][A
  5%|â–Œ         | 12/240 [00:38<20:31,  5.40s/it][A
  5%|â–Œ         | 13/240 [00:38<14:45,  3.90s/it][A
  6%|â–Œ         | 14/240 [00:38<10:41,  2.84s/it][A
  6%|â–‹         | 15/240 [00:39<08:00,  2.14s/it][A
  7%|â–‹         | 16/240 [00:39<06:01,  1.62s/it][A
  7%|â–‹         | 17/240 [00:40<04:46,  1.28s/it][A
  8%|â–Š         | 18/240 [00:40<03:45,  1.02s/it][A
  8%|â–Š         | 19/240 [00:41<03:04,  1.20it/s][A
  8%|â–Š         | 20/240 [00:41<02:38,  1.38it/s][A
  9%|â–‰         | 21/240 [00:42<02:18,  1.59it/s][A
  9%|â–‰         | 22/240 [00:42<02:02,  1.78it/s][A
 10%|â–‰         | 23/240 [00:42<01:54,  1.90it/s][A
 10%|â–ˆ         | 24/240 [00:43<01:50,  1.95it/s][A
 10%|â–ˆ         | 25/240 [00:43<01:48,  1.98it/s][A
 11%|â–ˆ         | 26/240 [00:44<01:51,  1.91it/s][A
 11%|â–ˆâ–        | 27/240 [00:44<01:44,  2.03it/s][A
 12%|â–ˆâ–        | 28/240 [00:45<01:43,  2.05it/s][A
 12%|â–ˆâ–        | 29/240 [00:45<01:43,  2.03it/s][A
 12%|â–ˆâ–Ž        | 30/240 [00:46<01:37,  2.15it/s][A
 13%|â–ˆâ–Ž        | 31/240 [00:46<01:34,  2.20it/s][A
 13%|â–ˆâ–Ž        | 32/240 [00:47<01:31,  2.26it/s][A
 14%|â–ˆâ–        | 33/240 [00:47<01:30,  2.30it/s][A
 14%|â–ˆâ–        | 34/240 [00:47<01:30,  2.29it/s][A
 15%|â–ˆâ–        | 35/240 [00:48<01:28,  2.31it/s][A
 15%|â–ˆâ–Œ        | 36/240 [00:48<01:25,  2.39it/s][A
 15%|â–ˆâ–Œ        | 37/240 [00:49<01:25,  2.39it/s][A
 16%|â–ˆâ–Œ        | 38/240 [00:49<01:28,  2.28it/s][A
 16%|â–ˆâ–‹        | 39/240 [00:50<01:26,  2.32it/s][A
 17%|â–ˆâ–‹        | 40/240 [00:50<01:28,  2.25it/s][A
 17%|â–ˆâ–‹        | 41/240 [00:50<01:25,  2.32it/s][A
 18%|â–ˆâ–Š        | 42/240 [00:51<01:23,  2.36it/s][A
 18%|â–ˆâ–Š        | 43/240 [00:51<01:22,  2.39it/s][A
 18%|â–ˆâ–Š        | 44/240 [00:52<01:26,  2.27it/s][A
 19%|â–ˆâ–‰        | 45/240 [01:37<45:01, 13.86s/it][A
 19%|â–ˆâ–‰        | 46/240 [01:37<31:54,  9.87s/it][A
 20%|â–ˆâ–‰        | 47/240 [01:38<22:38,  7.04s/it][A
 20%|â–ˆâ–ˆ        | 48/240 [01:38<16:10,  5.05s/it][A
 20%|â–ˆâ–ˆ        | 49/240 [01:39<11:42,  3.68s/it][A
 21%|â–ˆâ–ˆ        | 50/240 [01:39<08:41,  2.75s/it][A
 21%|â–ˆâ–ˆâ–       | 51/240 [01:40<06:27,  2.05s/it][A
 22%|â–ˆâ–ˆâ–       | 52/240 [01:40<04:52,  1.56s/it][A
 22%|â–ˆâ–ˆâ–       | 53/240 [01:41<03:47,  1.22s/it][A
 22%|â–ˆâ–ˆâ–Ž       | 54/240 [01:41<03:04,  1.01it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 55/240 [01:41<02:31,  1.22it/s][A
 23%|â–ˆâ–ˆâ–Ž       | 56/240 [01:42<02:07,  1.45it/s][A
 24%|â–ˆâ–ˆâ–       | 57/240 [01:42<01:52,  1.63it/s][A
 24%|â–ˆâ–ˆâ–       | 58/240 [01:43<01:40,  1.81it/s][A
 25%|â–ˆâ–ˆâ–       | 59/240 [01:43<01:32,  1.96it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 60/240 [01:44<01:25,  2.11it/s][A
 25%|â–ˆâ–ˆâ–Œ       | 61/240 [01:44<01:22,  2.17it/s][A
 26%|â–ˆâ–ˆâ–Œ       | 62/240 [01:44<01:22,  2.14it/s][A
 26%|â–ˆâ–ˆâ–‹       | 63/240 [01:45<01:21,  2.18it/s][A
 27%|â–ˆâ–ˆâ–‹       | 64/240 [01:45<01:17,  2.26it/s][A
 27%|â–ˆâ–ˆâ–‹       | 65/240 [01:46<01:16,  2.29it/s][A
 28%|â–ˆâ–ˆâ–Š       | 66/240 [01:46<01:17,  2.24it/s][A
 28%|â–ˆâ–ˆâ–Š       | 67/240 [01:47<01:19,  2.16it/s][A
 28%|â–ˆâ–ˆâ–Š       | 68/240 [01:47<01:16,  2.25it/s][A
 29%|â–ˆâ–ˆâ–‰       | 69/240 [01:48<01:18,  2.18it/s][A
 29%|â–ˆâ–ˆâ–‰       | 70/240 [01:48<01:14,  2.28it/s][A
 30%|â–ˆâ–ˆâ–‰       | 71/240 [01:48<01:13,  2.31it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 72/240 [01:49<01:15,  2.24it/s][A
 30%|â–ˆâ–ˆâ–ˆ       | 73/240 [01:49<01:13,  2.27it/s][A
 31%|â–ˆâ–ˆâ–ˆ       | 74/240 [01:50<01:11,  2.34it/s][A
 31%|â–ˆâ–ˆâ–ˆâ–      | 75/240 [01:50<01:10,  2.34it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 76/240 [01:50<01:07,  2.42it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 77/240 [01:51<01:06,  2.44it/s][A
 32%|â–ˆâ–ˆâ–ˆâ–Ž      | 78/240 [01:51<01:09,  2.32it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 79/240 [01:52<01:08,  2.34it/s][A
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 80/240 [02:07<13:05,  4.91s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 81/240 [02:08<09:36,  3.63s/it][A
 34%|â–ˆâ–ˆâ–ˆâ–      | 82/240 [02:08<06:59,  2.65s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–      | 83/240 [02:09<05:11,  1.98s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 84/240 [02:09<03:59,  1.53s/it][A
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 85/240 [02:09<03:05,  1.20s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 86/240 [02:10<02:26,  1.05it/s][A
 36%|â–ˆâ–ˆâ–ˆâ–‹      | 87/240 [02:10<02:05,  1.22it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 88/240 [02:11<01:45,  1.44it/s][A
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 89/240 [02:11<01:32,  1.63it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 90/240 [02:12<01:22,  1.82it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 91/240 [02:12<01:22,  1.80it/s][A
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 92/240 [02:13<01:16,  1.94it/s][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 93/240 [02:13<01:15,  1.95it/s][A
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 94/240 [02:13<01:09,  2.10it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–‰      | 95/240 [02:14<01:20,  1.81it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 96/240 [02:15<01:24,  1.70it/s][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 97/240 [02:16<01:26,  1.64it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 98/240 [02:16<01:22,  1.72it/s][A
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 99/240 [02:16<01:14,  1.88it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 100/240 [02:17<01:12,  1.94it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 101/240 [02:17<01:07,  2.05it/s][A
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 102/240 [02:18<01:04,  2.14it/s][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 103/240 [02:18<01:05,  2.11it/s][A
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 104/240 [02:19<01:00,  2.24it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 105/240 [02:19<01:05,  2.07it/s][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 106/240 [02:20<01:01,  2.18it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 107/240 [02:20<00:59,  2.22it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 108/240 [02:20<00:57,  2.31it/s][A
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 109/240 [02:21<00:56,  2.31it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 110/240 [02:21<00:54,  2.38it/s][A
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 111/240 [02:29<05:41,  2.65s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 112/240 [02:30<04:17,  2.02s/it][A
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 113/240 [02:30<03:16,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 114/240 [02:31<02:34,  1.22s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 115/240 [02:31<02:05,  1.01s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 116/240 [02:31<01:41,  1.22it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 117/240 [02:32<01:27,  1.41it/s][A
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 118/240 [02:32<01:17,  1.56it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 119/240 [02:33<01:09,  1.73it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 120/240 [02:33<01:05,  1.83it/s][A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 121/240 [02:34<00:59,  1.99it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 122/240 [02:34<00:55,  2.11it/s][A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 123/240 [02:35<00:54,  2.16it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 124/240 [02:35<00:54,  2.15it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 125/240 [02:35<00:51,  2.22it/s][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 126/240 [02:36<00:49,  2.32it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 127/240 [02:36<00:49,  2.29it/s][A
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 128/240 [02:37<00:48,  2.31it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 129/240 [02:37<00:50,  2.20it/s][A
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 130/240 [02:38<00:48,  2.29it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 131/240 [02:38<00:46,  2.32it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 132/240 [02:39<00:48,  2.25it/s][A
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 133/240 [02:39<00:49,  2.17it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 134/240 [02:39<00:48,  2.18it/s][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 135/240 [02:40<00:46,  2.27it/s][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 136/240 [02:40<00:44,  2.34it/s][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 137/240 [02:41<00:43,  2.35it/s][A
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 138/240 [02:41<00:45,  2.26it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 139/240 [02:42<00:44,  2.28it/s][A
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 140/240 [02:42<00:42,  2.38it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 141/240 [02:42<00:41,  2.37it/s][A
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 142/240 [02:43<00:40,  2.40it/s][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 143/240 [03:05<11:18,  6.99s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 144/240 [03:07<08:32,  5.34s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 145/240 [03:07<06:08,  3.88s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 146/240 [03:08<04:29,  2.86s/it][A
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 147/240 [03:08<03:18,  2.13s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 148/240 [03:08<02:30,  1.64s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 149/240 [03:09<01:56,  1.28s/it][A
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 150/240 [03:09<01:35,  1.06s/it][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 151/240 [03:10<01:19,  1.12it/s][A
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 152/240 [03:10<01:06,  1.33it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 153/240 [03:11<00:58,  1.48it/s][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 154/240 [03:11<00:51,  1.68it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 155/240 [03:12<00:45,  1.85it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 156/240 [03:12<00:41,  2.00it/s][A
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 157/240 [03:13<00:39,  2.09it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 158/240 [03:13<00:37,  2.21it/s][A
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 159/240 [03:13<00:36,  2.24it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 160/240 [03:14<00:34,  2.34it/s][A
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 161/240 [03:14<00:33,  2.36it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 162/240 [03:15<00:36,  2.13it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 163/240 [03:15<00:35,  2.19it/s][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 164/240 [03:16<00:33,  2.28it/s][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 165/240 [03:30<05:51,  4.68s/it][A
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 166/240 [03:31<04:15,  3.45s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 167/240 [03:31<03:07,  2.57s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 168/240 [03:32<02:18,  1.92s/it][A
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 169/240 [03:32<01:46,  1.49s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 170/240 [03:33<01:21,  1.17s/it][A
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 171/240 [03:33<01:07,  1.02it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 172/240 [03:34<01:00,  1.13it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 173/240 [03:34<00:51,  1.29it/s][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 174/240 [03:35<00:43,  1.52it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 175/240 [03:35<00:38,  1.70it/s][A
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 176/240 [03:36<00:35,  1.79it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 177/240 [03:36<00:32,  1.92it/s][A
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 178/240 [03:36<00:30,  2.04it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 179/240 [03:37<00:30,  2.03it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 180/240 [03:37<00:27,  2.15it/s][A
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 181/240 [03:38<00:27,  2.11it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 182/240 [03:38<00:26,  2.17it/s][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 183/240 [03:39<00:25,  2.24it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 184/240 [03:39<00:24,  2.29it/s][A
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 185/240 [03:40<00:23,  2.30it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 186/240 [03:40<00:23,  2.26it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 187/240 [03:40<00:24,  2.18it/s][A
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 188/240 [03:41<00:22,  2.27it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 189/240 [03:41<00:22,  2.27it/s][A
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 190/240 [03:42<00:21,  2.35it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 191/240 [03:42<00:20,  2.37it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 192/240 [03:43<00:20,  2.37it/s][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 193/240 [03:43<00:19,  2.36it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 194/240 [03:43<00:19,  2.39it/s][A
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 195/240 [03:44<00:19,  2.29it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 196/240 [03:44<00:18,  2.34it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 197/240 [03:45<00:20,  2.13it/s][A
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 198/240 [04:04<04:10,  5.96s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 199/240 [04:04<03:00,  4.41s/it][A
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 200/240 [04:05<02:08,  3.22s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 201/240 [04:05<01:33,  2.41s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 202/240 [04:06<01:08,  1.80s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 203/240 [04:06<00:51,  1.38s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 204/240 [04:07<00:40,  1.11s/it][A
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 205/240 [04:07<00:31,  1.11it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 206/240 [04:08<00:26,  1.29it/s][A
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 207/240 [04:08<00:21,  1.51it/s][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 208/240 [04:08<00:18,  1.71it/s][A
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 209/240 [04:09<00:18,  1.72it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 210/240 [04:09<00:15,  1.91it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 211/240 [04:10<00:14,  1.94it/s][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 212/240 [04:10<00:13,  2.10it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 213/240 [04:11<00:13,  2.08it/s][A
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 214/240 [04:11<00:11,  2.19it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 215/240 [04:12<00:11,  2.12it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 216/240 [04:12<00:10,  2.20it/s][A
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 217/240 [04:12<00:10,  2.23it/s][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 218/240 [04:13<00:09,  2.28it/s][A
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 219/240 [04:13<00:09,  2.33it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 220/240 [04:14<00:08,  2.39it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 221/240 [04:14<00:07,  2.40it/s][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 222/240 [04:15<00:08,  2.16it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 223/240 [04:15<00:07,  2.22it/s][A
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 224/240 [04:16<00:07,  2.17it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 225/240 [04:16<00:06,  2.23it/s][A
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 226/240 [04:16<00:06,  2.29it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 227/240 [04:17<00:05,  2.20it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 228/240 [04:17<00:05,  2.16it/s][A
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 229/240 [04:18<00:04,  2.22it/s][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 230/240 [04:26<00:27,  2.78s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 231/240 [04:26<00:18,  2.10s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 232/240 [04:27<00:12,  1.59s/it][A
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 233/240 [04:27<00:08,  1.25s/it][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 234/240 [04:28<00:05,  1.02it/s][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 235/240 [04:28<00:04,  1.23it/s][A
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 236/240 [04:29<00:02,  1.37it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 237/240 [04:29<00:01,  1.58it/s][A
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 238/240 [04:29<00:01,  1.76it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 239/240 [04:30<00:00,  1.81it/s][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [04:31<00:00,  1.80it/s][A                                                   
                                                 [A  1%|â–         | 60/4304 [11:44<5:02:36,  4.28s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 240/240 [04:31<00:00,  1.80it/s][A
                                                 [A  1%|â–         | 61/4304 [11:49<101:21:13, 85.99s/it]  1%|â–         | 62/4304 [11:51<71:35:50, 60.76s/it] /var/spool/slurmd/job00200/slurm_script: line 29: 326249 Killed                  python3 /home/ubuntu/Safety-gen/script/train_dpo_unsloth.py --base_model "/jfan5/sft_qwen3/bfgs-variant-500" --dataset "/home/ubuntu/Safety-gen/data/dpo/new_four/multi_pddl3_dpo.jsonl" --output_dir "${OUTPUT_DIR}" --num_epochs 4 --batch_size 4 --gradient_accumulation_steps 2 --learning_rate 5e-6 --save_steps 60 --eval_steps 60 --logging_steps 10 --beta 0.2 --memory_efficient --run_name "dpo-qwen3-bfgs" --dataloader_num_workers 4


CondaError: Run 'conda init' before 'conda activate'

[torchao|WARNING]Skipping import of cpp extensions due to incompatible torch version 2.8.0+cu128 for torchao version 0.14.1             Please see https://github.com/pytorch/ao/issues/2919 for more info
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA H100 PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.10.12: Fast Gpt_Oss patching. Transformers: 4.56.2.
   \\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.8.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.4.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.01s/it]
Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.12s/it]
Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:11<00:05,  5.05s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  4.21s/it]
Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:14<00:00,  3.71s/it]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251111_235926-kfug9f49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_bfgs-variant-500
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/kfug9f49
wandb: Detected [huggingface_hub.inference] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': 199998, 'pad_token_id': 200002}.
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 9,500 | Num Epochs = 2 | Total steps = 150
O^O/ \_/ \    Batch size per device = 8 | Gradient accumulation steps = 16
\        /    Data Parallel GPUs = 1 | Total batch size (8 x 16 x 1) = 128
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from /home/ubuntu/data/sft/bfgs-variant-500/combined.hf...
Loading HuggingFace dataset...
Dataset loaded with 10000 entries
Scenario distribution:
  blocksworld: 2500
  ferry: 2500
  grippers: 2500
  spanner: 2500
Validation ratio: 0.05
Processing dataset format (chat template)...

Testing initial model performance...
Initial model output:
analysisWe need to find a plan that satisfies goal, respecting constraints: anytime constraints: "sometime-before (at c1 l1) (at-ferry l0)" meaning: action at c1 at l1 must occur before the ferry arrives at l0? Wait check: constraints: (sometime-before (at c1 l1) (at-ferry l0)). Actually at-ferry l0 is a predicate. So we must ensure that (at-ferry l0) holds at some point after (at c1 l1) occurs; or that (at c1 l1) occurs before (at-ferry l0). i.e., we need to have at-ferry l0 after at-c1-l1? It'...

Resolved training arguments:
  num_train_epochs: 2.0
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 16
  learning_rate: 2e-05
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 4096
  load_in_4bit: True

Creating trainer...

Starting training...

  0%|          | 0/150 [00:00<?, ?it/s]
  1%|          | 1/150 [02:34<6:24:23, 154.79s/it]
  1%|â–         | 2/150 [03:37<4:08:35, 100.78s/it]
  2%|â–         | 3/150 [04:09<2:50:08, 69.45s/it] 
  3%|â–Ž         | 4/150 [04:41<2:12:32, 54.47s/it]
  3%|â–Ž         | 5/150 [05:12<1:51:28, 46.13s/it]
  4%|â–         | 6/150 [05:44<1:38:53, 41.21s/it]
  5%|â–         | 7/150 [06:15<1:30:34, 38.01s/it]
  5%|â–Œ         | 8/150 [06:47<1:25:31, 36.14s/it]
  6%|â–Œ         | 9/150 [07:19<1:21:29, 34.68s/it]
  7%|â–‹         | 10/150 [07:50<1:18:38, 33.70s/it]
                                                  

  7%|â–‹         | 10/150 [07:50<1:18:38, 33.70s/it]
  7%|â–‹         | 11/150 [08:22<1:16:29, 33.02s/it]
  8%|â–Š         | 12/150 [08:53<1:14:51, 32.55s/it]
  9%|â–Š         | 13/150 [09:25<1:13:33, 32.22s/it]
  9%|â–‰         | 14/150 [09:56<1:12:26, 31.96s/it]
 10%|â–ˆ         | 15/150 [10:28<1:11:30, 31.78s/it]
 11%|â–ˆ         | 16/150 [10:59<1:10:46, 31.69s/it]
 11%|â–ˆâ–        | 17/150 [11:30<1:09:55, 31.54s/it]
 12%|â–ˆâ–        | 18/150 [12:02<1:09:43, 31.69s/it]
 13%|â–ˆâ–Ž        | 19/150 [12:34<1:08:57, 31.58s/it]
 13%|â–ˆâ–Ž        | 20/150 [13:05<1:08:21, 31.55s/it]
                                                  

 13%|â–ˆâ–Ž        | 20/150 [13:05<1:08:21, 31.55s/it]
 14%|â–ˆâ–        | 21/150 [13:37<1:07:43, 31.50s/it]
 15%|â–ˆâ–        | 22/150 [14:08<1:07:04, 31.44s/it]
 15%|â–ˆâ–Œ        | 23/150 [14:39<1:06:32, 31.44s/it]
 16%|â–ˆâ–Œ        | 24/150 [15:11<1:06:03, 31.45s/it]
 17%|â–ˆâ–‹        | 25/150 [15:42<1:05:29, 31.44s/it]
 17%|â–ˆâ–‹        | 26/150 [16:13<1:04:54, 31.41s/it]
 18%|â–ˆâ–Š        | 27/150 [16:45<1:04:23, 31.41s/it]
 19%|â–ˆâ–Š        | 28/150 [17:17<1:04:16, 31.61s/it]
 19%|â–ˆâ–‰        | 29/150 [17:49<1:03:42, 31.59s/it]
 20%|â–ˆâ–ˆ        | 30/150 [18:20<1:03:09, 31.58s/it]
                                                  

 20%|â–ˆâ–ˆ        | 30/150 [18:20<1:03:09, 31.58s/it]
 21%|â–ˆâ–ˆ        | 31/150 [18:51<1:02:31, 31.53s/it]
 21%|â–ˆâ–ˆâ–       | 32/150 [19:23<1:02:07, 31.59s/it]
 22%|â–ˆâ–ˆâ–       | 33/150 [19:55<1:01:30, 31.55s/it]
 23%|â–ˆâ–ˆâ–Ž       | 34/150 [20:26<1:00:56, 31.52s/it]
 23%|â–ˆâ–ˆâ–Ž       | 35/150 [20:57<1:00:10, 31.39s/it]
 24%|â–ˆâ–ˆâ–       | 36/150 [21:29<59:35, 31.37s/it]  
 25%|â–ˆâ–ˆâ–       | 37/150 [22:00<59:10, 31.42s/it]
 25%|â–ˆâ–ˆâ–Œ       | 38/150 [22:32<58:57, 31.59s/it]
 26%|â–ˆâ–ˆâ–Œ       | 39/150 [23:04<58:22, 31.56s/it]
 27%|â–ˆâ–ˆâ–‹       | 40/150 [23:35<57:50, 31.55s/it]
                                                

 27%|â–ˆâ–ˆâ–‹       | 40/150 [23:35<57:50, 31.55s/it]
 27%|â–ˆâ–ˆâ–‹       | 41/150 [24:06<57:11, 31.48s/it]
 28%|â–ˆâ–ˆâ–Š       | 42/150 [24:38<56:35, 31.44s/it]
 29%|â–ˆâ–ˆâ–Š       | 43/150 [25:09<56:04, 31.44s/it]
 29%|â–ˆâ–ˆâ–‰       | 44/150 [25:41<55:29, 31.41s/it]
 30%|â–ˆâ–ˆâ–ˆ       | 45/150 [26:12<55:00, 31.44s/it]
 31%|â–ˆâ–ˆâ–ˆ       | 46/150 [26:44<54:31, 31.46s/it]
 31%|â–ˆâ–ˆâ–ˆâ–      | 47/150 [27:15<53:50, 31.36s/it]
 32%|â–ˆâ–ˆâ–ˆâ–      | 48/150 [27:47<53:36, 31.53s/it]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 49/150 [28:18<52:58, 31.47s/it]
 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 50/150 [28:49<52:22, 31.43s/it]
                                                

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 50/150 [28:49<52:22, 31.43s/it]
 34%|â–ˆâ–ˆâ–ˆâ–      | 51/150 [29:21<51:49, 31.41s/it]
 35%|â–ˆâ–ˆâ–ˆâ–      | 52/150 [29:52<51:16, 31.39s/it]
 35%|â–ˆâ–ˆâ–ˆâ–Œ      | 53/150 [30:23<50:45, 31.39s/it]
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 54/150 [30:55<50:09, 31.35s/it]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 55/150 [31:26<49:38, 31.35s/it]
 37%|â–ˆâ–ˆâ–ˆâ–‹      | 56/150 [31:57<49:01, 31.29s/it]
 38%|â–ˆâ–ˆâ–ˆâ–Š      | 57/150 [32:28<48:28, 31.27s/it]
 39%|â–ˆâ–ˆâ–ˆâ–Š      | 58/150 [33:00<47:59, 31.30s/it]
 39%|â–ˆâ–ˆâ–ˆâ–‰      | 59/150 [33:32<47:48, 31.52s/it]
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 60/150 [34:03<47:13, 31.48s/it]
                                                

 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 60/150 [34:03<47:13, 31.48s/it]
 41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 61/150 [34:35<46:58, 31.67s/it]
 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 62/150 [35:07<46:18, 31.57s/it]
 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 63/150 [35:38<45:41, 31.52s/it]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 64/150 [36:09<45:05, 31.46s/it]
 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 65/150 [36:41<44:33, 31.46s/it]
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 66/150 [37:12<43:54, 31.36s/it]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 67/150 [37:43<43:19, 31.32s/it]
 45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 68/150 [38:14<42:48, 31.32s/it]
 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 69/150 [38:46<42:35, 31.55s/it]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 70/150 [39:18<42:03, 31.54s/it]
                                                

 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 70/150 [39:18<42:03, 31.54s/it]
 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 71/150 [39:49<41:26, 31.48s/it]
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 72/150 [40:21<40:52, 31.45s/it]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 73/150 [40:52<40:23, 31.47s/it]
 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 74/150 [41:24<39:48, 31.43s/it]
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 75/150 [41:52<38:14, 30.60s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 4.5793, 'grad_norm': 50.30875015258789, 'learning_rate': 1.2e-05, 'epoch': 0.13}
{'loss': 2.4921, 'grad_norm': 5.571842193603516, 'learning_rate': 1.9956707906498046e-05, 'epoch': 0.27}
{'loss': 1.4017, 'grad_norm': 2.3174126148223877, 'learning_rate': 1.9473966425143292e-05, 'epoch': 0.4}
{'loss': 1.1172, 'grad_norm': 1.357866883277893, 'learning_rate': 1.848048096156426e-05, 'epoch': 0.54}
{'loss': 0.922, 'grad_norm': 1.222319483757019, 'learning_rate': 1.702981057425662e-05, 'epoch': 0.67}
{'loss': 0.7434, 'grad_norm': 1.2704540491104126, 'learning_rate': 1.5200161279292154e-05, 'epoch': 0.81}
{'loss': 0.6024, 'grad_norm': 0.9619948863983154, 'learning_rate': 1.3090169943749475e-05, 'epoch': 0.94}


  0%|          | 0/63 [00:00<?, ?it/s][A

  3%|â–Ž         | 2/63 [00:01<01:00,  1.02it/s][A

  5%|â–         | 3/63 [00:03<01:12,  1.20s/it][A

  6%|â–‹         | 4/63 [00:05<01:19,  1.34s/it][A

  8%|â–Š         | 5/63 [00:06<01:18,  1.36s/it][A

 10%|â–‰         | 6/63 [00:08<01:21,  1.42s/it][A

 11%|â–ˆ         | 7/63 [00:09<01:21,  1.46s/it][A

 13%|â–ˆâ–Ž        | 8/63 [00:11<01:21,  1.48s/it][A

 14%|â–ˆâ–        | 9/63 [00:12<01:20,  1.49s/it][A

 16%|â–ˆâ–Œ        | 10/63 [00:14<01:19,  1.50s/it][A

 17%|â–ˆâ–‹        | 11/63 [00:15<01:19,  1.52s/it][A

 19%|â–ˆâ–‰        | 12/63 [00:17<01:17,  1.52s/it][A

 21%|â–ˆâ–ˆ        | 13/63 [00:18<01:16,  1.52s/it][A

 22%|â–ˆâ–ˆâ–       | 14/63 [00:20<01:12,  1.48s/it][A

 24%|â–ˆâ–ˆâ–       | 15/63 [00:21<01:10,  1.47s/it][A

 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:23<01:09,  1.48s/it][A

 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:24<01:09,  1.51s/it][A

 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:26<01:09,  1.53s/it][A

 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:27<01:07,  1.53s/it][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:29<01:05,  1.53s/it][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/63 [00:30<01:04,  1.53s/it][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:32<01:03,  1.54s/it][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:33<01:01,  1.54s/it][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:35<01:00,  1.56s/it][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:37<00:58,  1.55s/it][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [00:38<00:56,  1.53s/it][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 27/63 [00:40<00:55,  1.53s/it][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [00:41<00:53,  1.53s/it][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [00:43<00:51,  1.53s/it][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [00:44<00:50,  1.52s/it][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [00:46<00:48,  1.52s/it][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [00:47<00:47,  1.52s/it][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [00:49<00:46,  1.54s/it][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [00:50<00:44,  1.53s/it][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [00:52<00:43,  1.55s/it][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [00:53<00:41,  1.55s/it][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [00:55<00:38,  1.49s/it][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [00:56<00:37,  1.49s/it][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [00:58<00:35,  1.50s/it][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/63 [00:59<00:34,  1.50s/it][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:01<00:32,  1.50s/it][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:02<00:31,  1.50s/it][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:04<00:30,  1.50s/it][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:05<00:28,  1.51s/it][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:07<00:27,  1.53s/it][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 46/63 [01:08<00:26,  1.55s/it][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [01:10<00:24,  1.55s/it][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [01:11<00:22,  1.49s/it][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [01:13<00:21,  1.51s/it][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [01:14<00:19,  1.50s/it][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [01:16<00:18,  1.52s/it][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 52/63 [01:18<00:17,  1.55s/it][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [01:19<00:15,  1.55s/it][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [01:21<00:13,  1.54s/it][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [01:22<00:12,  1.53s/it][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [01:24<00:10,  1.53s/it][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [01:25<00:09,  1.53s/it][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [01:27<00:07,  1.53s/it][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 59/63 [01:28<00:06,  1.52s/it][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [01:30<00:04,  1.54s/it][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [01:31<00:03,  1.54s/it][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [01:33<00:01,  1.53s/it][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:34<00:00,  1.38s/it][A
                                                

                                               
[A
 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 75/150 [43:29<38:14, 30.60s/it]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [01:34<00:00,  1.38s/it][A

                                               [A
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 76/150 [43:55<1:11:54, 58.31s/it]
 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 77/150 [44:17<57:43, 47.44s/it]  
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 78/150 [44:39<47:47, 39.83s/it]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 79/150 [45:01<40:38, 34.34s/it]
 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 80/150 [45:23<35:47, 30.67s/it]
                                                

 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 80/150 [45:23<35:47, 30.67s/it]
 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 81/150 [45:45<32:20, 28.12s/it]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 82/150 [46:07<29:39, 26.17s/it]
 55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 83/150 [46:29<27:51, 24.95s/it]
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 84/150 [46:50<26:18, 23.92s/it]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 85/150 [47:13<25:21, 23.40s/it]
 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 86/150 [47:35<24:34, 23.03s/it]
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 87/150 [47:56<23:42, 22.58s/it]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 88/150 [48:18<23:12, 22.46s/it]
 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 89/150 [48:40<22:41, 22.32s/it]
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 90/150 [49:02<22:03, 22.06s/it]
                                                

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 90/150 [49:02<22:03, 22.06s/it]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 91/150 [49:24<21:44, 22.11s/it]
 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 92/150 [49:46<21:23, 22.13s/it]
 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 93/150 [50:08<20:49, 21.92s/it]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 94/150 [50:30<20:31, 21.99s/it]
 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 95/150 [50:52<20:11, 22.04s/it]
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 96/150 [51:14<19:44, 21.94s/it]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 97/150 [51:36<19:27, 22.03s/it]
 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 98/150 [51:58<19:07, 22.07s/it]
 66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 99/150 [52:20<18:37, 21.90s/it]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [52:42<18:17, 21.95s/it]
                                                 

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 100/150 [52:42<18:17, 21.95s/it]
 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 101/150 [53:04<17:58, 22.01s/it]
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 102/150 [53:25<17:28, 21.84s/it]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 103/150 [53:47<17:09, 21.91s/it]
 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 104/150 [54:09<16:50, 21.97s/it]
 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 105/150 [54:31<16:22, 21.82s/it]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 106/150 [54:53<16:04, 21.93s/it]
 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 107/150 [55:15<15:43, 21.95s/it]
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 108/150 [55:37<15:17, 21.85s/it]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 109/150 [55:59<15:00, 21.95s/it]
 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 110/150 [56:20<14:32, 21.82s/it]
                                                 

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 110/150 [56:20<14:32, 21.82s/it]
 74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 111/150 [56:42<14:12, 21.85s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 112/150 [57:05<13:54, 21.95s/it]
 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 113/150 [57:26<13:28, 21.84s/it]
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 114/150 [57:49<13:13, 22.03s/it]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 115/150 [58:11<12:52, 22.06s/it]
 77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 116/150 [58:32<12:25, 21.94s/it]
 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 117/150 [58:55<12:06, 22.01s/it]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 118/150 [59:17<11:45, 22.05s/it]
 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 119/150 [59:38<11:18, 21.88s/it]
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 120/150 [1:00:00<10:58, 21.95s/it]
                                                   

 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 120/150 [1:00:00<10:58, 21.95s/it]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 121/150 [1:00:22<10:37, 22.00s/it]
 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 122/150 [1:00:44<10:11, 21.84s/it]
 82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 123/150 [1:01:06<09:51, 21.90s/it]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 124/150 [1:01:28<09:27, 21.82s/it]
 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 125/150 [1:01:50<09:08, 21.92s/it]
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 126/150 [1:02:12<08:47, 21.96s/it]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 127/150 [1:02:33<08:22, 21.84s/it]
 85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 128/150 [1:02:56<08:02, 21.95s/it]
 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 129/150 [1:03:18<07:42, 22.01s/it]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 130/150 [1:03:39<07:17, 21.88s/it]
                                                   

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 130/150 [1:03:39<07:17, 21.88s/it]
 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 131/150 [1:04:01<06:57, 21.95s/it]
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 132/150 [1:04:24<06:36, 22.00s/it]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 133/150 [1:04:45<06:11, 21.87s/it]
 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 134/150 [1:05:07<05:51, 21.94s/it]
 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 135/150 [1:05:29<05:30, 22.03s/it]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 136/150 [1:05:51<05:05, 21.86s/it]
 91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 137/150 [1:06:13<04:45, 21.96s/it]
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 138/150 [1:06:35<04:22, 21.85s/it]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 139/150 [1:06:57<04:01, 21.98s/it]
 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 140/150 [1:07:19<03:39, 21.98s/it]
                                                   

 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 140/150 [1:07:19<03:39, 21.98s/it]
 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 141/150 [1:07:40<03:16, 21.85s/it]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 142/150 [1:08:03<02:55, 21.95s/it]
 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 143/150 [1:08:25<02:33, 21.99s/it]
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 144/150 [1:08:46<02:10, 21.83s/it]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 145/150 [1:09:09<01:50, 22.02s/it]
 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 146/150 [1:09:31<01:28, 22.20s/it]
 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 147/150 [1:09:53<01:05, 21.98s/it]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 148/150 [1:10:15<00:43, 21.98s/it]
 99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 149/150 [1:10:37<00:22, 22.21s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [1:10:43<00:00, 17.22s/it]
                                                   

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [1:10:43<00:00, 17.22s/it]{'eval_loss': 0.4919416904449463, 'eval_runtime': 96.5509, 'eval_samples_per_second': 5.179, 'eval_steps_per_second': 0.653, 'epoch': 1.0}

==================================================
Testing model performance...
==================================================
Generated solution:
(board c0 l0)
(board c2 l2)
(sail l2 l1)
(debark c2 l1)
(board c1 l2)
(sail l2 l0)
(debark c1 l0)
(sail l0 l2)
(debark c0 l2)
==================================================
{'loss': 0.4936, 'grad_norm': 0.868810772895813, 'learning_rate': 1.0813586746678584e-05, 'epoch': 1.07}
{'loss': 0.3989, 'grad_norm': 0.9711607098579407, 'learning_rate': 8.49314287750517e-06, 'epoch': 1.2}
{'loss': 0.3372, 'grad_norm': 0.8058085441589355, 'learning_rate': 6.25393406584088e-06, 'epoch': 1.34}
{'loss': 0.2852, 'grad_norm': 0.7886919975280762, 'learning_rate': 4.216676638320135e-06, 'epoch': 1.47}
{'loss': 0.2576, 'grad_norm': 0.7767852544784546, 'learning_rate': 2.4911996701850083e-06, 'epoch': 1.61}
{'loss': 0.241, 'grad_norm': 0.8261427283287048, 'learning_rate': 1.1705240714107301e-06, 'epoch': 1.74}
{'loss': 0.2354, 'grad_norm': 0.7590352892875671, 'learning_rate': 3.2584780537136206e-07, 'epoch': 1.88}
{'loss': 0.23, 'grad_norm': 1.277734637260437, 'learning_rate': 2.7075882053828605e-09, 'epoch': 2.0}


  0%|          | 0/63 [00:00<?, ?it/s][A

  3%|â–Ž         | 2/63 [00:01<00:45,  1.35it/s][A

  5%|â–         | 3/63 [00:03<01:04,  1.08s/it][A

  6%|â–‹         | 4/63 [00:04<01:15,  1.27s/it][A

  8%|â–Š         | 5/63 [00:06<01:16,  1.32s/it][A

 10%|â–‰         | 6/63 [00:07<01:19,  1.40s/it][A

 11%|â–ˆ         | 7/63 [00:09<01:22,  1.47s/it][A

 13%|â–ˆâ–Ž        | 8/63 [00:10<01:21,  1.49s/it][A

 14%|â–ˆâ–        | 9/63 [00:12<01:21,  1.51s/it][A

 16%|â–ˆâ–Œ        | 10/63 [00:13<01:20,  1.52s/it][A

 17%|â–ˆâ–‹        | 11/63 [00:16<01:36,  1.85s/it][A

 19%|â–ˆâ–‰        | 12/63 [00:19<01:52,  2.20s/it][A

 21%|â–ˆâ–ˆ        | 13/63 [00:22<02:01,  2.43s/it][A

 22%|â–ˆâ–ˆâ–       | 14/63 [00:25<02:02,  2.50s/it][A

 24%|â–ˆâ–ˆâ–       | 15/63 [00:27<02:03,  2.57s/it][A

 25%|â–ˆâ–ˆâ–Œ       | 16/63 [00:30<02:05,  2.67s/it][A

 27%|â–ˆâ–ˆâ–‹       | 17/63 [00:33<02:08,  2.79s/it][A

 29%|â–ˆâ–ˆâ–Š       | 18/63 [00:36<02:09,  2.88s/it][A

 30%|â–ˆâ–ˆâ–ˆ       | 19/63 [00:39<02:07,  2.91s/it][A

 32%|â–ˆâ–ˆâ–ˆâ–      | 20/63 [00:42<02:04,  2.91s/it][A

 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 21/63 [00:45<02:02,  2.91s/it][A

 35%|â–ˆâ–ˆâ–ˆâ–      | 22/63 [00:48<02:01,  2.97s/it][A

 37%|â–ˆâ–ˆâ–ˆâ–‹      | 23/63 [00:51<01:58,  2.97s/it][A

 38%|â–ˆâ–ˆâ–ˆâ–Š      | 24/63 [00:54<01:57,  3.01s/it][A

 40%|â–ˆâ–ˆâ–ˆâ–‰      | 25/63 [00:57<01:54,  3.01s/it][A

 41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 26/63 [01:00<01:49,  2.95s/it][A

 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 27/63 [01:03<01:46,  2.95s/it][A

 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/63 [01:06<01:42,  2.93s/it][A

 46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 29/63 [01:09<01:39,  2.94s/it][A

 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 30/63 [01:12<01:36,  2.92s/it][A

 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 31/63 [01:15<01:33,  2.91s/it][A

 51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 32/63 [01:18<01:30,  2.93s/it][A

 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 33/63 [01:21<01:27,  2.93s/it][A

 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 34/63 [01:24<01:25,  2.94s/it][A

 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 35/63 [01:27<01:23,  2.97s/it][A

 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 36/63 [01:30<01:20,  2.98s/it][A

 59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 37/63 [01:32<01:14,  2.86s/it][A

 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 38/63 [01:35<01:11,  2.88s/it][A

 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 39/63 [01:38<01:09,  2.90s/it][A

 63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 40/63 [01:41<01:06,  2.88s/it][A

 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 41/63 [01:44<01:03,  2.87s/it][A

 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 42/63 [01:47<01:00,  2.88s/it][A

 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 43/63 [01:50<00:57,  2.89s/it][A

 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 44/63 [01:53<00:55,  2.93s/it][A

 71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 45/63 [01:56<00:53,  2.95s/it][A

 73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 46/63 [01:59<00:50,  3.00s/it][A

 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 47/63 [02:02<00:47,  2.99s/it][A

 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 48/63 [02:04<00:43,  2.88s/it][A

 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 49/63 [02:07<00:40,  2.88s/it][A

 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 50/63 [02:09<00:34,  2.62s/it][A

 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 51/63 [02:11<00:27,  2.31s/it][A

 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 52/63 [02:12<00:23,  2.10s/it][A

 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 53/63 [02:14<00:19,  1.93s/it][A

 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 54/63 [02:15<00:16,  1.81s/it][A

 87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 55/63 [02:17<00:13,  1.72s/it][A

 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 56/63 [02:18<00:11,  1.66s/it][A

 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 57/63 [02:20<00:09,  1.62s/it][A

 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 58/63 [02:22<00:07,  1.59s/it][A

 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 59/63 [02:23<00:06,  1.57s/it][A

 95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 60/63 [02:25<00:04,  1.57s/it][A

 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 61/63 [02:26<00:03,  1.56s/it][A

 98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 62/63 [02:28<00:01,  1.54s/it][A

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [02:29<00:00,  1.36s/it][A
                                                   

                                               
[A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [1:13:13<00:00, 17.22s/it]

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63/63 [02:29<00:00,  1.36s/it][A

                                               [A
                                                   

100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [1:13:16<00:00, 17.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [1:13:16<00:00, 29.31s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–
wandb:            eval/runtime â–â–ˆ
wandb: eval/samples_per_second â–ˆâ–
wandb:   eval/steps_per_second â–ˆâ–
wandb:             train/epoch â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/learning_rate â–…â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–„â–ƒâ–‚â–‚â–â–â–
wandb:              train/loss â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.23188
wandb:            eval/runtime 150.3627
wandb: eval/samples_per_second 3.325
wandb:   eval/steps_per_second 0.419
wandb:              total_flos 2.197715257553283e+18
wandb:             train/epoch 2
wandb:       train/global_step 150
wandb:         train/grad_norm 1.27773
wandb:     train/learning_rate 0.0
wandb:              train/loss 0.23
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_bfgs-variant-500 at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/kfug9f49
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251111_235926-kfug9f49/logs
{'eval_loss': 0.23188365995883942, 'eval_runtime': 150.3627, 'eval_samples_per_second': 3.325, 'eval_steps_per_second': 0.419, 'epoch': 2.0}

==================================================
Testing model performance...
==================================================
Generated solution:
(sail l0 l1)
(board c1 l1)
(sail l1 l0)
(debark c1 l1)
==================================================
{'train_runtime': 4396.7664, 'train_samples_per_second': 4.321, 'train_steps_per_second': 0.034, 'train_loss': 0.9558021434148153, 'epoch': 2.0}

Saving model to /jfan5/sft_gpt/bfgs-variant-500 ...
Training completed!


CondaError: Run 'conda init' before 'conda activate'

==========================================
Fine-tuning GPT-OSS-20B on cross-domain (PDDL3 symbolized)
==========================================
Model: unsloth/gpt-oss-20b-unsloth-bnb-4bit
Dataset: /jfan5/sft_data/pddl3_symbolized_four_scenarios/combined.hf
Output: /jfan5/sft_models/gpt_oss_20b/cross_domain_pddl3_symbolized

Training parameters:
  Epochs: 3
  Batch size: 8
  Gradient accumulation: 4
  Learning rate: 2e-4
  Max sequence length: 4096
==========================================

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA H100 PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.11.6: Fast Gpt_Oss patching. Transformers: 4.56.2. vLLM: 0.12.0.
   \\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.9.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.5.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:03,  1.01s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:02<00:02,  1.34s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:03<00:01,  1.15s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.32it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:03<00:00,  1.09it/s]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from /jfan5/sft_data/pddl3_symbolized_four_scenarios/combined.hf...
Loading HuggingFace dataset...
Detected single Dataset
Dataset loaded with 4000 entries
Scenario distribution:
  cross_domain: 4000
Validation ratio: 0.05
Processing dataset format (chat template)...
Map:   0%|          | 0/3800 [00:00<?, ? examples/s]Map:  18%|â–ˆâ–Š        | 665/3800 [00:00<00:00, 6603.23 examples/s]Map:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1477/3800 [00:00<00:00, 7452.86 examples/s]Map:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 2322/3800 [00:00<00:00, 7904.38 examples/s]Map:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3191/3800 [00:00<00:00, 8209.43 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:00<00:00, 7966.00 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 7417.57 examples/s]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: setting up run tgei3gwy
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251212_153309-tgei3gwy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_cross_domain_pddl3_symbolized
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/tgei3gwy
wandb: Detected [huggingface_hub.inference, openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Testing initial model performance...
Initial model output:
analysisWe have a PDDL problem. We need to provide something: maybe a solution path? The user hasn't asked explicitly. Perhaps they want to find a plan? They present domain and problem. They haven't asked for anything explicit, maybe they want you to solve or determine whether it's solvable. The question: "Domain: ... Problem: ...". Maybe they want the plan? Provide a solution? So maybe we should provide a plan that satisfies goal.

We need to read domain: three actions: op_1 (transport?), op_3 ...

Resolved training arguments:
  num_train_epochs: 3.0
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 0.0002
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 4096
  load_in_4bit: True

Creating trainer...
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/3800 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   3%|â–Ž         | 119/3800 [00:02<01:29, 41.20 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 595/3800 [00:03<00:13, 242.35 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 714/3800 [00:03<00:11, 264.74 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 833/3800 [00:03<00:11, 256.60 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 1071/3800 [00:04<00:07, 342.74 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 1190/3800 [00:04<00:06, 377.16 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 1309/3800 [00:04<00:06, 368.23 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1428/3800 [00:05<00:06, 376.32 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1547/3800 [00:05<00:05, 390.82 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1666/3800 [00:05<00:05, 399.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1904/3800 [00:06<00:03, 535.76 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2142/3800 [00:06<00:03, 529.71 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 2261/3800 [00:06<00:03, 501.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2380/3800 [00:07<00:02, 476.87 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 2499/3800 [00:07<00:02, 474.13 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2618/3800 [00:07<00:02, 511.01 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2737/3800 [00:07<00:01, 544.87 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2856/3800 [00:08<00:02, 453.33 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2974/3800 [00:08<00:01, 487.72 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3092/3800 [00:08<00:01, 461.56 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3328/3800 [00:08<00:00, 589.68 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 3446/3800 [00:08<00:00, 598.84 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3682/3800 [00:09<00:00, 567.23 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:09<00:00, 613.47 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:09<00:00, 381.55 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/200 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   4%|â–Ž         | 7/200 [00:02<01:12,  2.65 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   7%|â–‹         | 14/200 [00:03<00:35,  5.19 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  14%|â–ˆâ–        | 28/200 [00:03<00:16, 10.74 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  21%|â–ˆâ–ˆ        | 42/200 [00:03<00:09, 17.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  24%|â–ˆâ–ˆâ–       | 49/200 [00:04<00:09, 16.76 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆ       | 62/200 [00:04<00:05, 23.23 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [00:04<00:06, 19.84 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [00:05<00:06, 20.90 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [00:05<00:05, 22.51 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [00:05<00:04, 23.12 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [00:06<00:04, 23.67 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 110/200 [00:06<00:03, 24.39 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [00:06<00:02, 30.21 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [00:07<00:02, 28.80 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [00:07<00:02, 23.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [00:07<00:02, 24.10 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 158/200 [00:08<00:01, 29.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [00:08<00:01, 28.19 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 170/200 [00:08<00:01, 28.23 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [00:08<00:00, 27.65 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [00:09<00:00, 24.62 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [00:09<00:00, 28.58 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 194/200 [00:09<00:00, 24.62 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:09<00:00, 29.12 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:10<00:00, 19.56 examples/s]
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 3,800 | Num Epochs = 3 | Total steps = 357
O^O/ \_/ \    Batch size per device = 8 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)

Starting training...
  0%|          | 0/357 [00:00<?, ?it/s]  0%|          | 1/357 [00:42<4:12:18, 42.52s/it]  1%|          | 2/357 [00:54<2:23:32, 24.26s/it]  1%|          | 3/357 [01:03<1:44:39, 17.74s/it]  1%|          | 4/357 [01:13<1:24:39, 14.39s/it]  1%|â–         | 5/357 [01:22<1:13:03, 12.45s/it]  2%|â–         | 6/357 [01:31<1:05:38, 11.22s/it]  2%|â–         | 7/357 [01:39<1:00:36, 10.39s/it]  2%|â–         | 8/357 [01:48<57:10,  9.83s/it]    3%|â–Ž         | 9/357 [01:56<54:32,  9.40s/it]  3%|â–Ž         | 10/357 [02:05<52:44,  9.12s/it]                                                  3%|â–Ž         | 10/357 [02:05<52:44,  9.12s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 4.5655, 'grad_norm': 12.90341854095459, 'learning_rate': 5e-05, 'epoch': 0.08}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:16,  1.38it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:24,  1.10s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:27,  1.32s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.40s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:07<00:28,  1.49s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:27,  1.54s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:25,  1.52s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.51s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.49s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:15<00:21,  1.53s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:18<00:18,  1.55s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.52s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:24<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:27<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:30<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:35<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A  3%|â–Ž         | 10/357 [02:45<52:44,  9.12s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A
                                               [A  3%|â–Ž         | 11/357 [02:53<2:01:41, 21.10s/it]  3%|â–Ž         | 12/357 [03:02<1:40:27, 17.47s/it]  4%|â–Ž         | 13/357 [03:11<1:24:39, 14.77s/it]  4%|â–         | 14/357 [03:19<1:13:31, 12.86s/it]  4%|â–         | 15/357 [03:28<1:05:44, 11.53s/it]  4%|â–         | 16/357 [03:36<1:00:25, 10.63s/it]  5%|â–         | 17/357 [03:45<56:34,  9.98s/it]    5%|â–Œ         | 18/357 [03:53<53:58,  9.55s/it]  5%|â–Œ         | 19/357 [04:02<52:07,  9.25s/it]  6%|â–Œ         | 20/357 [04:10<50:38,  9.01s/it]                                                  6%|â–Œ         | 20/357 [04:10<50:38,  9.01s/it]{'eval_loss': 1.505773663520813, 'eval_runtime': 39.7121, 'eval_samples_per_second': 5.036, 'eval_steps_per_second': 0.63, 'epoch': 0.08}
{'loss': 1.0392, 'grad_norm': 1.3606071472167969, 'learning_rate': 0.00010555555555555557, 'epoch': 0.17}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.24it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.16s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.44s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:28,  1.52s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.57s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.53s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:15<00:21,  1.53s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.55s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.52s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.44s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:24<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:27<00:09,  1.51s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.56s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.64s/it][A                                                
                                               [A  6%|â–Œ         | 20/357 [04:50<50:38,  9.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.64s/it][A
                                               [A  6%|â–Œ         | 21/357 [04:58<1:55:32, 20.63s/it]  6%|â–Œ         | 22/357 [05:06<1:34:37, 16.95s/it]  6%|â–‹         | 23/357 [05:15<1:20:10, 14.40s/it]  7%|â–‹         | 24/357 [05:23<1:10:00, 12.61s/it]  7%|â–‹         | 25/357 [05:32<1:02:47, 11.35s/it]  7%|â–‹         | 26/357 [05:40<57:50, 10.49s/it]    8%|â–Š         | 27/357 [05:49<54:18,  9.87s/it]  8%|â–Š         | 28/357 [05:57<51:27,  9.39s/it]  8%|â–Š         | 29/357 [06:05<49:39,  9.08s/it]  8%|â–Š         | 30/357 [06:14<49:32,  9.09s/it]                                                  8%|â–Š         | 30/357 [06:14<49:32,  9.09s/it]{'eval_loss': 0.7372916340827942, 'eval_runtime': 39.2723, 'eval_samples_per_second': 5.093, 'eval_steps_per_second': 0.637, 'epoch': 0.17}
{'loss': 0.5015, 'grad_norm': 1.0858739614486694, 'learning_rate': 0.0001611111111111111, 'epoch': 0.25}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.24it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.16s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:28,  1.44s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:28,  1.52s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.56s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:25,  1.53s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.51s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.49s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:15<00:21,  1.53s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.55s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.52s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:24<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:27<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A  8%|â–Š         | 30/357 [06:54<49:32,  9.09s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A  9%|â–Š         | 31/357 [07:18<2:18:28, 25.49s/it]  9%|â–‰         | 32/357 [07:24<1:46:08, 19.60s/it]  9%|â–‰         | 33/357 [07:30<1:23:31, 15.47s/it] 10%|â–‰         | 34/357 [07:36<1:07:39, 12.57s/it] 10%|â–‰         | 35/357 [07:41<56:31, 10.53s/it]   10%|â–ˆ         | 36/357 [07:48<50:02,  9.35s/it] 10%|â–ˆ         | 37/357 [07:54<44:11,  8.29s/it] 11%|â–ˆ         | 38/357 [07:59<39:59,  7.52s/it] 11%|â–ˆ         | 39/357 [08:05<37:06,  7.00s/it] 11%|â–ˆ         | 40/357 [08:11<35:04,  6.64s/it]                                                 11%|â–ˆ         | 40/357 [08:11<35:04,  6.64s/it]{'eval_loss': 0.32357272505760193, 'eval_runtime': 39.3239, 'eval_samples_per_second': 5.086, 'eval_steps_per_second': 0.636, 'epoch': 0.25}

==================================================
Testing model performance...
==================================================
Generated solution:
(op_1 obj_07 obj_02) (op_3 obj_06 obj_02) (op_1 obj_02 obj_07) (op_3 obj_01 obj_02) (op_1 obj_07 obj_04) (op_3 obj_03 obj_04) (op_1 obj_04 obj_07) (op_2 obj_03 obj_07) (op_1 obj_07 obj_02) (op_2 obj_01 obj_07) (op_1 obj_02 obj_05) (op_3 obj_06 obj_05) (op_1 obj_05 obj_02) (op_2 obj_06 obj_02) (op_1 obj_02 obj_07) (op_2 obj_06 obj_07) (op_1 obj_07 obj_05) (op_2 obj_03 obj_05) (op_1 obj_05 obj_04) (op_2 obj_06 obj_04) (op_1 obj_04 obj_07) (op_2 obj_06 obj_07) (op_1 obj_07 obj_04) (op_2 obj_01 obj_04) (op_1 obj_04 obj_07) (op_2 obj_01 obj_07)
==================================================
{'loss': 0.2046, 'grad_norm': 0.5671776533126831, 'learning_rate': 0.00019995690062269984, 'epoch': 0.34}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.16s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.48s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.54s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.59s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.55s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.53s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.58s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.56s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A 11%|â–ˆ         | 40/357 [08:51<35:04,  6.64s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 11%|â–ˆâ–        | 41/357 [08:56<1:36:09, 18.26s/it] 12%|â–ˆâ–        | 42/357 [09:02<1:15:59, 14.48s/it] 12%|â–ˆâ–        | 43/357 [09:09<1:03:15, 12.09s/it] 12%|â–ˆâ–        | 44/357 [09:14<52:59, 10.16s/it]   13%|â–ˆâ–Ž        | 45/357 [09:20<45:48,  8.81s/it] 13%|â–ˆâ–Ž        | 46/357 [09:26<40:45,  7.86s/it] 13%|â–ˆâ–Ž        | 47/357 [09:31<37:14,  7.21s/it] 13%|â–ˆâ–Ž        | 48/357 [09:37<34:42,  6.74s/it] 14%|â–ˆâ–Ž        | 49/357 [09:43<33:04,  6.44s/it] 14%|â–ˆâ–        | 50/357 [09:49<33:03,  6.46s/it]                                                 14%|â–ˆâ–        | 50/357 [09:49<33:03,  6.46s/it]{'eval_loss': 0.1039450466632843, 'eval_runtime': 39.4788, 'eval_samples_per_second': 5.066, 'eval_steps_per_second': 0.633, 'epoch': 0.34}
{'loss': 0.0838, 'grad_norm': 0.27976033091545105, 'learning_rate': 0.00019919172253651633, 'epoch': 0.42}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.17s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.47s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.54s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.58s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.54s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A 14%|â–ˆâ–        | 50/357 [10:29<33:03,  6.46s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 14%|â–ˆâ–        | 51/357 [10:34<1:32:21, 18.11s/it] 15%|â–ˆâ–        | 52/357 [10:40<1:13:02, 14.37s/it] 15%|â–ˆâ–        | 53/357 [10:46<59:23, 11.72s/it]   15%|â–ˆâ–Œ        | 54/357 [10:51<49:56,  9.89s/it] 15%|â–ˆâ–Œ        | 55/357 [10:57<43:26,  8.63s/it] 16%|â–ˆâ–Œ        | 56/357 [11:03<38:46,  7.73s/it] 16%|â–ˆâ–Œ        | 57/357 [11:10<37:36,  7.52s/it] 16%|â–ˆâ–Œ        | 58/357 [11:15<34:54,  7.00s/it] 17%|â–ˆâ–‹        | 59/357 [11:21<32:44,  6.59s/it] 17%|â–ˆâ–‹        | 60/357 [11:27<31:21,  6.34s/it]                                                 17%|â–ˆâ–‹        | 60/357 [11:27<31:21,  6.34s/it]{'eval_loss': 0.06807777285575867, 'eval_runtime': 39.4579, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 0.634, 'epoch': 0.42}
{'loss': 0.064, 'grad_norm': 0.2736005187034607, 'learning_rate': 0.0001974772117649135, 'epoch': 0.51}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.17s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.36s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.47s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.53s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.57s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.54s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:15<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.56s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A 17%|â–ˆâ–‹        | 60/357 [12:06<31:21,  6.34s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 17%|â–ˆâ–‹        | 61/357 [12:24<1:46:04, 21.50s/it] 17%|â–ˆâ–‹        | 62/357 [12:29<1:22:32, 16.79s/it] 18%|â–ˆâ–Š        | 63/357 [12:35<1:06:03, 13.48s/it] 18%|â–ˆâ–Š        | 64/357 [12:42<55:50, 11.44s/it]   18%|â–ˆâ–Š        | 65/357 [12:48<47:36,  9.78s/it] 18%|â–ˆâ–Š        | 66/357 [12:54<41:32,  8.57s/it] 19%|â–ˆâ–‰        | 67/357 [12:59<37:15,  7.71s/it] 19%|â–ˆâ–‰        | 68/357 [13:05<34:18,  7.12s/it] 19%|â–ˆâ–‰        | 69/357 [13:11<32:10,  6.70s/it] 20%|â–ˆâ–‰        | 70/357 [13:17<30:55,  6.47s/it]                                                 20%|â–ˆâ–‰        | 70/357 [13:17<30:55,  6.47s/it]{'eval_loss': 0.05906826630234718, 'eval_runtime': 39.4234, 'eval_samples_per_second': 5.073, 'eval_steps_per_second': 0.634, 'epoch': 0.51}

==================================================
Testing model performance...
==================================================
Generated solution:
(op_1 obj_05 obj_02)
(op_3 obj_01 obj_02)
(op_1 obj_02 obj_05)
(op_2 obj_01 obj_05)
(op_1 obj_05 obj_04)
(op_1 obj_04 obj_02)
(op_3 obj_06 obj_02)
(op_1 obj_02 obj_04)
(op_2 obj_06 obj_04)
(op_1 obj_04 obj_07)
(op_3 obj_03 obj_04)
(op_1 obj_04 obj_05)
(op_2 obj_03 obj_05)
(op_1 obj_05 obj_04)
(op_3 obj_01 obj_04)
(op_1 obj_04 obj_07)
(op_2 obj_01 obj_07)
==================================================
{'loss': 0.0556, 'grad_norm': 0.1958685964345932, 'learning_rate': 0.00019482977734962753, 'epoch': 0.59}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.17s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.48s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.54s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.58s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.54s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.56s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A 20%|â–ˆâ–‰        | 70/357 [13:56<30:55,  6.47s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 20%|â–ˆâ–‰        | 71/357 [14:02<1:26:17, 18.10s/it] 20%|â–ˆâ–ˆ        | 72/357 [14:08<1:08:16, 14.37s/it] 20%|â–ˆâ–ˆ        | 73/357 [14:14<56:58, 12.04s/it]   21%|â–ˆâ–ˆ        | 74/357 [14:20<47:51, 10.15s/it] 21%|â–ˆâ–ˆ        | 75/357 [14:26<41:25,  8.81s/it] 21%|â–ˆâ–ˆâ–       | 76/357 [14:31<36:55,  7.88s/it] 22%|â–ˆâ–ˆâ–       | 77/357 [14:37<33:44,  7.23s/it] 22%|â–ˆâ–ˆâ–       | 78/357 [14:43<31:32,  6.78s/it] 22%|â–ˆâ–ˆâ–       | 79/357 [14:48<29:53,  6.45s/it] 22%|â–ˆâ–ˆâ–       | 80/357 [14:54<28:42,  6.22s/it]                                                 22%|â–ˆâ–ˆâ–       | 80/357 [14:54<28:42,  6.22s/it]{'eval_loss': 0.054326657205820084, 'eval_runtime': 39.4575, 'eval_samples_per_second': 5.069, 'eval_steps_per_second': 0.634, 'epoch': 0.59}
{'loss': 0.0546, 'grad_norm': 0.1767684668302536, 'learning_rate': 0.00019127475705028863, 'epoch': 0.67}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.16s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.36s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.46s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.53s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.57s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.53s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:15<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A 22%|â–ˆâ–ˆâ–       | 80/357 [15:34<28:42,  6.22s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 23%|â–ˆâ–ˆâ–Ž       | 81/357 [15:40<1:23:47, 18.22s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/357 [15:46<1:06:11, 14.44s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/357 [15:52<53:49, 11.79s/it]   24%|â–ˆâ–ˆâ–Ž       | 84/357 [15:57<45:16,  9.95s/it] 24%|â–ˆâ–ˆâ–       | 85/357 [16:03<39:12,  8.65s/it] 24%|â–ˆâ–ˆâ–       | 86/357 [16:08<34:46,  7.70s/it] 24%|â–ˆâ–ˆâ–       | 87/357 [16:14<31:47,  7.07s/it] 25%|â–ˆâ–ˆâ–       | 88/357 [16:19<29:40,  6.62s/it] 25%|â–ˆâ–ˆâ–       | 89/357 [16:26<29:18,  6.56s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/357 [16:31<27:52,  6.26s/it]                                                 25%|â–ˆâ–ˆâ–Œ       | 90/357 [16:31<27:52,  6.26s/it]{'eval_loss': 0.05251987278461456, 'eval_runtime': 39.4079, 'eval_samples_per_second': 5.075, 'eval_steps_per_second': 0.634, 'epoch': 0.67}
{'loss': 0.0519, 'grad_norm': 0.15356068313121796, 'learning_rate': 0.00018684617484471662, 'epoch': 0.76}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.17s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.48s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.54s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.58s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.54s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.53s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                
                                               [A 25%|â–ˆâ–ˆâ–Œ       | 90/357 [17:11<27:52,  6.26s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 25%|â–ˆâ–ˆâ–Œ       | 91/357 [17:25<1:30:43, 20.46s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/357 [17:31<1:10:48, 16.03s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/357 [17:36<56:56, 12.94s/it]   26%|â–ˆâ–ˆâ–‹       | 94/357 [17:42<47:18, 10.79s/it] 27%|â–ˆâ–ˆâ–‹       | 95/357 [17:48<40:29,  9.27s/it] 27%|â–ˆâ–ˆâ–‹       | 96/357 [17:54<35:41,  8.20s/it] 27%|â–ˆâ–ˆâ–‹       | 97/357 [18:00<33:43,  7.78s/it] 27%|â–ˆâ–ˆâ–‹       | 98/357 [18:06<30:55,  7.16s/it] 28%|â–ˆâ–ˆâ–Š       | 99/357 [18:12<28:59,  6.74s/it] 28%|â–ˆâ–ˆâ–Š       | 100/357 [18:18<27:36,  6.45s/it]                                                  28%|â–ˆâ–ˆâ–Š       | 100/357 [18:18<27:36,  6.45s/it]{'eval_loss': 0.049913834780454636, 'eval_runtime': 39.4143, 'eval_samples_per_second': 5.074, 'eval_steps_per_second': 0.634, 'epoch': 0.76}

==================================================
Testing model performance...
==================================================
Generated solution:
(op_1 obj_05 obj_07)
(op_3 obj_01 obj_07)
(op_1 obj_07 obj_02)
(op_3 obj_06 obj_02)
(op_1 obj_02 obj_05)
(op_2 obj_06 obj_05)
(op_1 obj_05 obj_04)
(op_3 obj_03 obj_04)
(op_1 obj_04 obj_05)
(op_2 obj_03 obj_05)
(op_1 obj_05 obj_07)
(op_2 obj_01 obj_07)
==================================================
{'loss': 0.048, 'grad_norm': 0.14102739095687866, 'learning_rate': 0.0001815864152961624, 'epoch': 0.84}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.17s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.47s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.53s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.58s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.54s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.52s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                 
                                               [A 28%|â–ˆâ–ˆâ–Š       | 100/357 [18:57<27:36,  6.45s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A 28%|â–ˆâ–ˆâ–Š       | 101/357 [19:03<1:17:06, 18.07s/it] 29%|â–ˆâ–ˆâ–Š       | 102/357 [19:09<1:00:53, 14.33s/it] 29%|â–ˆâ–ˆâ–‰       | 103/357 [19:14<49:36, 11.72s/it]   29%|â–ˆâ–ˆâ–‰       | 104/357 [19:20<41:40,  9.88s/it] 29%|â–ˆâ–ˆâ–‰       | 105/357 [19:25<36:03,  8.59s/it] 30%|â–ˆâ–ˆâ–‰       | 106/357 [19:32<33:21,  7.97s/it] 30%|â–ˆâ–ˆâ–‰       | 107/357 [19:37<30:10,  7.24s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/357 [19:43<28:03,  6.76s/it] 31%|â–ˆâ–ˆâ–ˆ       | 109/357 [19:49<26:32,  6.42s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [19:54<25:27,  6.18s/it]                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [19:54<25:27,  6.18s/it]{'eval_loss': 0.049791764467954636, 'eval_runtime': 39.4418, 'eval_samples_per_second': 5.071, 'eval_steps_per_second': 0.634, 'epoch': 0.84}
{'loss': 0.0517, 'grad_norm': 0.49522387981414795, 'learning_rate': 0.0001755458179040237, 'epoch': 0.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:18,  1.23it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:25,  1.17s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.36s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.47s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.54s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.57s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.54s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:12<00:24,  1.52s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:22,  1.50s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:15<00:21,  1.54s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:17<00:20,  1.57s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:18,  1.56s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:20<00:16,  1.52s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:21<00:14,  1.46s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:23<00:13,  1.45s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.53s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:26<00:10,  1.52s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:28<00:09,  1.52s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:29<00:07,  1.55s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:31<00:06,  1.57s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:32<00:04,  1.55s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:34<00:03,  1.59s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:36<00:01,  1.62s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:37<00:00,  1.65s/it][A                                                 
                                               [A 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [20:34<25:27,  6.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:38<00:00,  1.65s/it][A
                                               [A                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [20:34<25:27,  6.18s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [20:34<46:11, 11.22s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–„â–‚â–â–â–â–â–â–â–â–
wandb:            eval/runtime â–ˆâ–â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒ
wandb: eval/samples_per_second â–â–ˆâ–‡â–…â–…â–†â–…â–†â–†â–…â–†
wandb:   eval/steps_per_second â–â–ˆâ–‡â–„â–…â–…â–…â–…â–…â–…â–…
wandb:             train/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–
wandb:     train/learning_rate â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:              train/loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.0506
wandb:            eval/runtime 39.4225
wandb: eval/samples_per_second 5.073
wandb:   eval/steps_per_second 0.634
wandb:              total_flos 4.253623526728581e+17
wandb:             train/epoch 0.92632
wandb:       train/global_step 110
wandb:         train/grad_norm 0.49522
wandb:     train/learning_rate 0.00018
wandb:              train/loss 0.0517
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_cross_domain_pddl3_symbolized at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/tgei3gwy
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251212_153309-tgei3gwy/logs
{'eval_loss': 0.050598982721567154, 'eval_runtime': 39.4225, 'eval_samples_per_second': 5.073, 'eval_steps_per_second': 0.634, 'epoch': 0.93}
{'train_runtime': 1234.3028, 'train_samples_per_second': 9.236, 'train_steps_per_second': 0.289, 'train_loss': 0.6109446335922588, 'epoch': 0.93}

Saving model to /jfan5/sft_models/gpt_oss_20b/cross_domain_pddl3_symbolized ...
Training completed!

==========================================
Fine-tuning completed!
==========================================
Model saved to: /jfan5/sft_models/gpt_oss_20b/cross_domain_pddl3_symbolized


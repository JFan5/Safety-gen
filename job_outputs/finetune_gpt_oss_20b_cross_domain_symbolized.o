
CondaError: Run 'conda init' before 'conda activate'

==========================================
Fine-tuning GPT-OSS-20B on cross-domain (PDDL3 symbolized)
==========================================
Model: unsloth/gpt-oss-20b-unsloth-bnb-4bit
Dataset: /jfan5/sft_data/pddl3_symbolized_four_scenarios/combined.hf
Output: /jfan5/sft_models/gpt_oss_20b/cross_domain_pddl3_symbolized

Training parameters:
  Epochs: 3
  Batch size: 8
  Gradient accumulation: 4
  Learning rate: 2e-4
  Max sequence length: 4096
==========================================

ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!
============================================================
PDDL Fine-tuning with unsloth/gpt-oss-20b-unsloth-bnb-4bit
============================================================
GPU count: 1
GPU 0: NVIDIA H100 PCIe

Loading model and tokenizer...
==((====))==  Unsloth 2025.11.6: Fast Gpt_Oss patching. Transformers: 4.56.2. vLLM: 0.12.0.
   \\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.9.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.5.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.90s/it]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 2/4 [00:03<00:03,  1.77s/it]Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:04<00:01,  1.55s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.01s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:05<00:00,  1.26s/it]
Unsloth: Dropout = 0 is supported for fast patching. You are using dropout = 0.05.
Unsloth will patch all other layers, except LoRA matrices, causing a performance hit.
Configuring LoRA...
Unsloth: Making `model.base_model.model.model` require gradients

Loading dataset from /jfan5/sft_data/pddl3_symbolized_four_scenarios/combined.hf...
Loading HuggingFace dataset...
Detected single Dataset
Dataset loaded with 4000 entries
Scenario distribution:
  blocksworld: 1000
  ferry: 1000
  grippers: 1000
  spanner: 1000
Validation ratio: 0.05
Using system prompt: Reasoning: high
Processing dataset format (chat template)...
Map:   0%|          | 0/3800 [00:00<?, ? examples/s]Map:   9%|â–‰         | 354/3800 [00:00<00:01, 3442.08 examples/s]Map:  29%|â–ˆâ–ˆâ–Š       | 1092/3800 [00:00<00:00, 5727.67 examples/s]Map:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2000/3800 [00:00<00:00, 6961.26 examples/s]Map:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2965/3800 [00:00<00:00, 7989.34 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:00<00:00, 7701.63 examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:00<00:00, 7182.82 examples/s]
Map:   0%|          | 0/200 [00:00<?, ? examples/s]Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:00<00:00, 7261.92 examples/s]
The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
wandb: WARNING Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to https://wandb.me/wandb-init.
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251217_163713-8e3qckj4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pddl_sft_cross_domain_pddl3_symbolized
wandb: â­ï¸ View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: ðŸš€ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/8e3qckj4
wandb: Detected [huggingface_hub.inference, openai] in use.
wandb: Use W&B Weave for improved LLM call tracing. Weave is installed but not imported. Add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/

Testing initial model performance...
Initial model output:
analysisWe need to solve planning problem using this domain, find sequence of actions achieving goal while satisfying constraints. Domain: predicates: not-eq? Actually "not-eq" is a predicate that expects two args? It's defined as predicate that maybe expresses inequality? But it's used as predicate to indicate not equal, but it's used as not-eq obj_03 obj_07 etc. That seems like a predicate not-eq(v4, v7). So we have not-eq predicate between objects. But we can treat as given facts: not-eq hold...

Resolved training arguments:
  num_train_epochs: 3.0
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 0.0002
  warmup_ratio: 0.1
  weight_decay: 0.05
  max_seq_length: 4096
  load_in_4bit: True

Creating trainer...
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/3800 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   3%|â–Ž         | 119/3800 [00:02<01:18, 46.89 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  13%|â–ˆâ–Ž        | 476/3800 [00:02<00:15, 213.83 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  16%|â–ˆâ–Œ        | 595/3800 [00:03<00:12, 254.86 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  19%|â–ˆâ–‰        | 714/3800 [00:03<00:10, 298.24 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  22%|â–ˆâ–ˆâ–       | 833/3800 [00:03<00:08, 341.92 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  25%|â–ˆâ–ˆâ–Œ       | 952/3800 [00:03<00:07, 372.54 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 1071/3800 [00:03<00:06, 410.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  31%|â–ˆâ–ˆâ–ˆâ–      | 1190/3800 [00:04<00:05, 438.82 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 1309/3800 [00:04<00:06, 363.36 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1547/3800 [00:05<00:05, 443.62 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1785/3800 [00:05<00:03, 589.93 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1904/3800 [00:05<00:03, 515.66 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 2023/3800 [00:05<00:03, 457.23 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 2142/3800 [00:06<00:03, 462.64 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 2380/3800 [00:06<00:02, 584.97 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 2618/3800 [00:06<00:01, 715.37 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2737/3800 [00:06<00:01, 640.74 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2856/3800 [00:07<00:01, 639.81 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2974/3800 [00:07<00:01, 648.26 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3092/3800 [00:07<00:01, 579.94 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 3210/3800 [00:07<00:01, 530.54 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 3328/3800 [00:08<00:00, 485.18 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 3564/3800 [00:08<00:00, 619.65 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 3682/3800 [00:08<00:00, 569.02 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:08<00:00, 532.06 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3800/3800 [00:09<00:00, 409.90 examples/s]
Unsloth: Tokenizing ["text"] (num_proc=32):   0%|          | 0/200 [00:00<?, ? examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   4%|â–Ž         | 7/200 [00:02<00:58,  3.33 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):   7%|â–‹         | 14/200 [00:02<00:28,  6.59 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  10%|â–ˆ         | 21/200 [00:02<00:16, 10.57 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  14%|â–ˆâ–        | 28/200 [00:02<00:11, 14.34 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  18%|â–ˆâ–Š        | 35/200 [00:03<00:08, 18.78 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  21%|â–ˆâ–ˆ        | 42/200 [00:03<00:06, 22.75 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  24%|â–ˆâ–ˆâ–       | 49/200 [00:03<00:05, 26.04 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  28%|â–ˆâ–ˆâ–Š       | 56/200 [00:03<00:06, 23.22 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  34%|â–ˆâ–ˆâ–ˆâ–      | 68/200 [00:03<00:04, 32.38 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 74/200 [00:04<00:03, 32.49 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 80/200 [00:04<00:03, 32.53 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 86/200 [00:04<00:03, 32.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 92/200 [00:04<00:03, 32.67 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 98/200 [00:05<00:04, 23.29 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 104/200 [00:05<00:04, 23.00 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 122/200 [00:05<00:02, 29.19 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 128/200 [00:06<00:02, 29.93 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 134/200 [00:06<00:02, 29.73 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 140/200 [00:06<00:01, 31.56 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 146/200 [00:06<00:02, 21.30 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 164/200 [00:07<00:01, 27.63 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 176/200 [00:07<00:00, 33.08 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 182/200 [00:08<00:00, 24.99 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 188/200 [00:08<00:00, 26.66 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:08<00:00, 35.38 examples/s]Unsloth: Tokenizing ["text"] (num_proc=32): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:08<00:00, 22.54 examples/s]
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 3,800 | Num Epochs = 3 | Total steps = 357
O^O/ \_/ \    Batch size per device = 8 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (8 x 4 x 1) = 32
 "-____-"     Trainable parameters = 15,925,248 of 20,930,682,432 (0.08% trained)

Starting training...
  0%|          | 0/357 [00:00<?, ?it/s]  0%|          | 1/357 [01:26<8:32:05, 86.31s/it]  1%|          | 2/357 [01:37<4:09:32, 42.17s/it]  1%|          | 3/357 [01:47<2:41:44, 27.41s/it]  1%|          | 4/357 [01:56<1:59:16, 20.27s/it]  1%|â–         | 5/357 [02:05<1:34:55, 16.18s/it]  2%|â–         | 6/357 [02:14<1:19:56, 13.67s/it]  2%|â–         | 7/357 [02:23<1:10:14, 12.04s/it]  2%|â–         | 8/357 [02:32<1:05:12, 11.21s/it]  3%|â–Ž         | 9/357 [02:41<1:00:11, 10.38s/it]  3%|â–Ž         | 10/357 [02:49<56:44,  9.81s/it]                                                   3%|â–Ž         | 10/357 [02:49<56:44,  9.81s/it]Unsloth: Not an error, but GptOssForCausalLM does not accept `num_items_in_batch`.
Using gradient accumulation will be very slightly less accurate.
Read more on gradient accumulation issues here: https://unsloth.ai/blog/gradient
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 3.8189, 'grad_norm': 7.544062614440918, 'learning_rate': 5e-05, 'epoch': 0.08}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:17,  1.35it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:24,  1.13s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:04<00:28,  1.33s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.46s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.53s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:09<00:28,  1.58s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.57s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:24,  1.65s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.60s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.63s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.60s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.61s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:25<00:12,  1.59s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:10,  1.57s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:30<00:08,  1.62s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:04,  1.66s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:35<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A                                                
                                               [A  3%|â–Ž         | 10/357 [03:32<56:44,  9.81s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A
                                               [A  3%|â–Ž         | 11/357 [03:40<2:09:14, 22.41s/it]  3%|â–Ž         | 12/357 [03:49<1:44:32, 18.18s/it]  4%|â–Ž         | 13/357 [03:57<1:27:22, 15.24s/it]  4%|â–         | 14/357 [04:06<1:15:33, 13.22s/it]  4%|â–         | 15/357 [04:14<1:07:11, 11.79s/it]  4%|â–         | 16/357 [04:23<1:01:17, 10.78s/it]  5%|â–         | 17/357 [04:31<57:11, 10.09s/it]    5%|â–Œ         | 18/357 [04:40<54:17,  9.61s/it]  5%|â–Œ         | 19/357 [04:48<52:09,  9.26s/it]  6%|â–Œ         | 20/357 [04:57<50:42,  9.03s/it]                                                  6%|â–Œ         | 20/357 [04:57<50:42,  9.03s/it]{'eval_loss': 1.4054255485534668, 'eval_runtime': 42.3586, 'eval_samples_per_second': 4.722, 'eval_steps_per_second': 0.59, 'epoch': 0.08}
{'loss': 1.0307, 'grad_norm': 1.2438268661499023, 'learning_rate': 0.00010555555555555557, 'epoch': 0.17}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.48s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.55s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.59s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.57s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.59s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.57s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:30<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:05,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                
                                               [A  6%|â–Œ         | 20/357 [05:38<50:42,  9.03s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A  6%|â–Œ         | 21/357 [05:46<1:58:55, 21.24s/it]  6%|â–Œ         | 22/357 [05:55<1:37:10, 17.41s/it]  6%|â–‹         | 23/357 [06:03<1:21:57, 14.72s/it]  7%|â–‹         | 24/357 [06:13<1:13:23, 13.23s/it]  7%|â–‹         | 25/357 [06:22<1:06:58, 12.10s/it]  7%|â–‹         | 26/357 [06:31<1:00:43, 11.01s/it]  8%|â–Š         | 27/357 [06:39<56:13, 10.22s/it]    8%|â–Š         | 28/357 [06:48<52:57,  9.66s/it]  8%|â–Š         | 29/357 [06:56<50:47,  9.29s/it]  8%|â–Š         | 30/357 [07:04<49:04,  9.01s/it]                                                  8%|â–Š         | 30/357 [07:04<49:04,  9.01s/it]{'eval_loss': 0.7480384111404419, 'eval_runtime': 41.1563, 'eval_samples_per_second': 4.86, 'eval_steps_per_second': 0.607, 'epoch': 0.17}
{'loss': 0.508, 'grad_norm': 0.7917298674583435, 'learning_rate': 0.0001611111111111111, 'epoch': 0.25}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.48s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.54s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.59s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.57s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.59s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.57s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:30<00:08,  1.62s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:04,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.68s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                
                                               [A  8%|â–Š         | 30/357 [07:45<49:04,  9.01s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A  9%|â–Š         | 31/357 [07:54<1:55:04, 21.18s/it]  9%|â–‰         | 32/357 [08:02<1:33:55, 17.34s/it]  9%|â–‰         | 33/357 [08:11<1:19:04, 14.64s/it] 10%|â–‰         | 34/357 [08:19<1:08:42, 12.76s/it] 10%|â–‰         | 35/357 [08:27<1:01:25, 11.45s/it] 10%|â–ˆ         | 36/357 [08:36<56:21, 10.53s/it]   10%|â–ˆ         | 37/357 [08:44<52:43,  9.89s/it] 11%|â–ˆ         | 38/357 [08:52<50:02,  9.41s/it] 11%|â–ˆ         | 39/357 [09:01<48:09,  9.09s/it] 11%|â–ˆ         | 40/357 [09:09<46:48,  8.86s/it]                                                 11%|â–ˆ         | 40/357 [09:09<46:48,  8.86s/it]{'eval_loss': 0.3208112418651581, 'eval_runtime': 41.1277, 'eval_samples_per_second': 4.863, 'eval_steps_per_second': 0.608, 'epoch': 0.25}
{'loss': 0.2031, 'grad_norm': 0.7250017523765564, 'learning_rate': 0.00019995690062269984, 'epoch': 0.34}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.48s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.55s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.59s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.58s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.59s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.57s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:30<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:05,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A                                                
                                               [A 11%|â–ˆ         | 40/357 [09:50<46:48,  8.86s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A
                                               [A 11%|â–ˆâ–        | 41/357 [09:59<1:51:00, 21.08s/it] 12%|â–ˆâ–        | 42/357 [10:07<1:30:36, 17.26s/it] 12%|â–ˆâ–        | 43/357 [10:15<1:16:21, 14.59s/it] 12%|â–ˆâ–        | 44/357 [10:24<1:06:20, 12.72s/it] 13%|â–ˆâ–Ž        | 45/357 [10:33<1:00:45, 11.68s/it] 13%|â–ˆâ–Ž        | 46/357 [10:41<55:25, 10.69s/it]   13%|â–ˆâ–Ž        | 47/357 [10:50<51:36,  9.99s/it] 13%|â–ˆâ–Ž        | 48/357 [10:58<48:58,  9.51s/it] 14%|â–ˆâ–Ž        | 49/357 [11:06<46:56,  9.15s/it] 14%|â–ˆâ–        | 50/357 [11:15<45:34,  8.91s/it]                                                 14%|â–ˆâ–        | 50/357 [11:15<45:34,  8.91s/it]{'eval_loss': 0.10524517297744751, 'eval_runtime': 41.1457, 'eval_samples_per_second': 4.861, 'eval_steps_per_second': 0.608, 'epoch': 0.34}
{'loss': 0.0777, 'grad_norm': 0.4048377275466919, 'learning_rate': 0.00019919172253651633, 'epoch': 0.42}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:29,  1.49s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.55s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.59s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.57s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.59s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:30<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:04,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                
                                               [A 14%|â–ˆâ–        | 50/357 [11:56<45:34,  8.91s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A 14%|â–ˆâ–        | 51/357 [12:12<1:59:00, 23.34s/it] 15%|â–ˆâ–        | 52/357 [12:17<1:31:40, 18.03s/it] 15%|â–ˆâ–        | 53/357 [12:23<1:12:30, 14.31s/it] 15%|â–ˆâ–Œ        | 54/357 [12:29<59:14, 11.73s/it]   15%|â–ˆâ–Œ        | 55/357 [12:35<49:58,  9.93s/it] 16%|â–ˆâ–Œ        | 56/357 [12:41<44:53,  8.95s/it] 16%|â–ˆâ–Œ        | 57/357 [12:47<39:49,  7.97s/it] 16%|â–ˆâ–Œ        | 58/357 [12:53<36:22,  7.30s/it] 17%|â–ˆâ–‹        | 59/357 [12:58<33:55,  6.83s/it] 17%|â–ˆâ–‹        | 60/357 [13:04<32:12,  6.51s/it]                                                 17%|â–ˆâ–‹        | 60/357 [13:04<32:12,  6.51s/it]{'eval_loss': 0.05898600444197655, 'eval_runtime': 41.1465, 'eval_samples_per_second': 4.861, 'eval_steps_per_second': 0.608, 'epoch': 0.42}

==================================================
Testing model performance...
==================================================
Generated solution:
(op_2 obj_04 obj_07)
(op_3 obj_07 obj_03)
(op_1 obj_04 obj_03)
(op_3 obj_03 obj_06)
(op_2 obj_01 obj_06)
(op_3 obj_06 obj_03)
(op_1 obj_01 obj_03)
(op_3 obj_03 obj_06)
(op_2 obj_02 obj_05)
(op_3 obj_05 obj_03)
(op_2 obj_02 obj_03)
(op_3 obj_03 obj_06)
(op_1 obj_02 obj_06)
==================================================
{'loss': 0.0551, 'grad_norm': 0.5356680750846863, 'learning_rate': 0.0001974772117649135, 'epoch': 0.51}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:30,  1.52s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.57s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.60s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.59s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.60s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:31<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:04,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                
                                               [A 17%|â–ˆâ–‹        | 60/357 [13:45<32:12,  6.51s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A 17%|â–ˆâ–‹        | 61/357 [13:51<1:32:07, 18.67s/it] 17%|â–ˆâ–‹        | 62/357 [13:57<1:12:34, 14.76s/it] 18%|â–ˆâ–Š        | 63/357 [14:02<58:49, 12.01s/it]   18%|â–ˆâ–Š        | 64/357 [14:08<49:12, 10.08s/it] 18%|â–ˆâ–Š        | 65/357 [14:15<44:01,  9.04s/it] 18%|â–ˆâ–Š        | 66/357 [14:20<38:51,  8.01s/it] 19%|â–ˆâ–‰        | 67/357 [14:26<35:13,  7.29s/it] 19%|â–ˆâ–‰        | 68/357 [14:31<32:40,  6.78s/it] 19%|â–ˆâ–‰        | 69/357 [14:37<30:50,  6.43s/it] 20%|â–ˆâ–‰        | 70/357 [14:43<29:32,  6.18s/it]                                                 20%|â–ˆâ–‰        | 70/357 [14:43<29:32,  6.18s/it]{'eval_loss': 0.05111067742109299, 'eval_runtime': 41.2609, 'eval_samples_per_second': 4.847, 'eval_steps_per_second': 0.606, 'epoch': 0.51}
{'loss': 0.0491, 'grad_norm': 0.20699161291122437, 'learning_rate': 0.00019482977734962753, 'epoch': 0.59}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:30,  1.52s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.57s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.61s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.59s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.60s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:31<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:05,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                
                                               [A 20%|â–ˆâ–‰        | 70/357 [15:24<29:32,  6.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A 20%|â–ˆâ–‰        | 71/357 [15:30<1:27:50, 18.43s/it] 20%|â–ˆâ–ˆ        | 72/357 [15:35<1:09:18, 14.59s/it] 20%|â–ˆâ–ˆ        | 73/357 [15:42<57:54, 12.23s/it]   21%|â–ˆâ–ˆ        | 74/357 [15:48<48:30, 10.28s/it] 21%|â–ˆâ–ˆ        | 75/357 [15:53<41:43,  8.88s/it] 21%|â–ˆâ–ˆâ–       | 76/357 [15:59<36:56,  7.89s/it] 22%|â–ˆâ–ˆâ–       | 77/357 [16:04<33:35,  7.20s/it] 22%|â–ˆâ–ˆâ–       | 78/357 [16:10<31:14,  6.72s/it] 22%|â–ˆâ–ˆâ–       | 79/357 [16:16<29:45,  6.42s/it] 22%|â–ˆâ–ˆâ–       | 80/357 [16:21<28:30,  6.18s/it]                                                 22%|â–ˆâ–ˆâ–       | 80/357 [16:21<28:30,  6.18s/it]{'eval_loss': 0.04838698357343674, 'eval_runtime': 41.2818, 'eval_samples_per_second': 4.845, 'eval_steps_per_second': 0.606, 'epoch': 0.59}
{'loss': 0.0479, 'grad_norm': 0.16607797145843506, 'learning_rate': 0.00019127475705028863, 'epoch': 0.67}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:30,  1.51s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.57s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.61s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.58s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.60s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.63s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:31<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:05,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A                                                
                                               [A 22%|â–ˆâ–ˆâ–       | 80/357 [17:03<28:30,  6.18s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A
                                               [A 23%|â–ˆâ–ˆâ–Ž       | 81/357 [17:09<1:25:01, 18.49s/it] 23%|â–ˆâ–ˆâ–Ž       | 82/357 [17:15<1:08:21, 14.91s/it] 23%|â–ˆâ–ˆâ–Ž       | 83/357 [17:21<55:26, 12.14s/it]   24%|â–ˆâ–ˆâ–Ž       | 84/357 [17:27<46:37, 10.25s/it] 24%|â–ˆâ–ˆâ–       | 85/357 [17:32<40:15,  8.88s/it] 24%|â–ˆâ–ˆâ–       | 86/357 [17:38<35:35,  7.88s/it] 24%|â–ˆâ–ˆâ–       | 87/357 [17:44<32:21,  7.19s/it] 25%|â–ˆâ–ˆâ–       | 88/357 [17:49<30:07,  6.72s/it] 25%|â–ˆâ–ˆâ–       | 89/357 [17:55<28:24,  6.36s/it] 25%|â–ˆâ–ˆâ–Œ       | 90/357 [18:00<27:13,  6.12s/it]                                                 25%|â–ˆâ–ˆâ–Œ       | 90/357 [18:00<27:13,  6.12s/it]{'eval_loss': 0.045758508145809174, 'eval_runtime': 41.2642, 'eval_samples_per_second': 4.847, 'eval_steps_per_second': 0.606, 'epoch': 0.67}
{'loss': 0.0457, 'grad_norm': 0.15329402685165405, 'learning_rate': 0.00018684617484471662, 'epoch': 0.76}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:30,  1.51s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.57s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.61s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.58s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.58s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:23,  1.60s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:31<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:04,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.67s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A                                                
                                               [A 25%|â–ˆâ–ˆâ–Œ       | 90/357 [18:41<27:13,  6.12s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.69s/it][A
                                               [A 25%|â–ˆâ–ˆâ–Œ       | 91/357 [18:48<1:22:39, 18.64s/it] 26%|â–ˆâ–ˆâ–Œ       | 92/357 [18:54<1:05:02, 14.73s/it] 26%|â–ˆâ–ˆâ–Œ       | 93/357 [18:59<52:44, 11.99s/it]   26%|â–ˆâ–ˆâ–‹       | 94/357 [19:05<44:07, 10.07s/it] 27%|â–ˆâ–ˆâ–‹       | 95/357 [19:10<38:04,  8.72s/it] 27%|â–ˆâ–ˆâ–‹       | 96/357 [19:16<33:49,  7.78s/it] 27%|â–ˆâ–ˆâ–‹       | 97/357 [19:22<30:52,  7.13s/it] 27%|â–ˆâ–ˆâ–‹       | 98/357 [19:27<28:43,  6.65s/it] 28%|â–ˆâ–ˆâ–Š       | 99/357 [19:33<27:13,  6.33s/it] 28%|â–ˆâ–ˆâ–Š       | 100/357 [19:38<26:11,  6.11s/it]                                                  28%|â–ˆâ–ˆâ–Š       | 100/357 [19:38<26:11,  6.11s/it]{'eval_loss': 0.04349822923541069, 'eval_runtime': 41.2421, 'eval_samples_per_second': 4.849, 'eval_steps_per_second': 0.606, 'epoch': 0.76}
{'loss': 0.0422, 'grad_norm': 0.17451359331607819, 'learning_rate': 0.0001815864152961624, 'epoch': 0.84}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.19it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.38s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:30,  1.52s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.57s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.60s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.59s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:24,  1.60s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.63s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:23<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:31<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:05,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                 
                                               [A 28%|â–ˆâ–ˆâ–Š       | 100/357 [20:20<26:11,  6.11s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A 28%|â–ˆâ–ˆâ–Š       | 101/357 [20:36<1:31:42, 21.50s/it] 29%|â–ˆâ–ˆâ–Š       | 102/357 [20:41<1:11:11, 16.75s/it] 29%|â–ˆâ–ˆâ–‰       | 103/357 [20:47<56:52, 13.43s/it]   29%|â–ˆâ–ˆâ–‰       | 104/357 [20:53<46:49, 11.10s/it] 29%|â–ˆâ–ˆâ–‰       | 105/357 [20:58<39:43,  9.46s/it] 30%|â–ˆâ–ˆâ–‰       | 106/357 [21:04<34:43,  8.30s/it] 30%|â–ˆâ–ˆâ–‰       | 107/357 [21:10<31:14,  7.50s/it] 30%|â–ˆâ–ˆâ–ˆ       | 108/357 [21:15<28:49,  6.94s/it] 31%|â–ˆâ–ˆâ–ˆ       | 109/357 [21:21<27:07,  6.56s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [21:27<25:55,  6.30s/it]                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [21:27<25:55,  6.30s/it]{'eval_loss': 0.04297483339905739, 'eval_runtime': 41.2778, 'eval_samples_per_second': 4.845, 'eval_steps_per_second': 0.606, 'epoch': 0.84}

==================================================
Testing model performance...
==================================================
Generated solution:
(op_3 obj_06 obj_05)
(op_2 obj_02 obj_05)
(op_3 obj_05 obj_07)
(op_1 obj_02 obj_07)
(op_3 obj_07 obj_03)
(op_2 obj_04 obj_03)
(op_1 obj_04 obj_03)
(op_3 obj_03 obj_07)
(op_2 obj_01 obj_07)
(op_3 obj_07 obj_06)
(op_1 obj_01 obj_06)
(op_2 obj_02 obj_07)
(op_3 obj_07 obj_06)
(op_1 obj_02 obj_06)
==================================================
{'loss': 0.0432, 'grad_norm': 0.13637638092041016, 'learning_rate': 0.0001755458179040237, 'epoch': 0.93}

  0%|          | 0/25 [00:00<?, ?it/s][A
  8%|â–Š         | 2/25 [00:01<00:19,  1.20it/s][A
 12%|â–ˆâ–        | 3/25 [00:03<00:26,  1.19s/it][A
 16%|â–ˆâ–Œ        | 4/25 [00:05<00:28,  1.37s/it][A
 20%|â–ˆâ–ˆ        | 5/25 [00:06<00:30,  1.51s/it][A
 24%|â–ˆâ–ˆâ–       | 6/25 [00:08<00:29,  1.57s/it][A
 28%|â–ˆâ–ˆâ–Š       | 7/25 [00:10<00:28,  1.61s/it][A
 32%|â–ˆâ–ˆâ–ˆâ–      | 8/25 [00:11<00:26,  1.59s/it][A
 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 9/25 [00:13<00:25,  1.59s/it][A
 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 10/25 [00:14<00:24,  1.60s/it][A
 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 11/25 [00:16<00:22,  1.62s/it][A
 48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 12/25 [00:18<00:21,  1.64s/it][A
 52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 13/25 [00:19<00:19,  1.61s/it][A
 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 14/25 [00:21<00:17,  1.62s/it][A
 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 15/25 [00:22<00:15,  1.58s/it][A
 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 16/25 [00:24<00:13,  1.55s/it][A
 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 17/25 [00:26<00:12,  1.60s/it][A
 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 18/25 [00:27<00:11,  1.58s/it][A
 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 19/25 [00:29<00:09,  1.60s/it][A
 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 20/25 [00:31<00:08,  1.63s/it][A
 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 21/25 [00:32<00:06,  1.66s/it][A
 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 22/25 [00:34<00:05,  1.67s/it][A
 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 23/25 [00:36<00:03,  1.67s/it][A
 96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 24/25 [00:37<00:01,  1.68s/it][A
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A                                                 
                                               [A 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [22:08<25:55,  6.30s/it]
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:39<00:00,  1.70s/it][A
                                               [A                                                  31%|â–ˆâ–ˆâ–ˆ       | 110/357 [22:08<25:55,  6.30s/it] 31%|â–ˆâ–ˆâ–ˆ       | 110/357 [22:08<49:42, 12.08s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:               eval/loss â–ˆâ–…â–‚â–â–â–â–â–â–â–â–
wandb:            eval/runtime â–ˆâ–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb: eval/samples_per_second â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡
wandb:   eval/steps_per_second â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡
wandb:             train/epoch â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:       train/global_step â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:         train/grad_norm â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:     train/learning_rate â–â–„â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:              train/loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:               eval/loss 0.04202
wandb:            eval/runtime 41.2553
wandb: eval/samples_per_second 4.848
wandb:   eval/steps_per_second 0.606
wandb:              total_flos 4.343124754823639e+17
wandb:             train/epoch 0.92632
wandb:       train/global_step 110
wandb:         train/grad_norm 0.13638
wandb:     train/learning_rate 0.00018
wandb:              train/loss 0.0432
wandb:                      +4 ...
wandb: 
wandb: ðŸš€ View run pddl_sft_cross_domain_pddl3_symbolized at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune/runs/8e3qckj4
wandb: â­ï¸ View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-finetune
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251217_163713-8e3qckj4/logs
{'eval_loss': 0.04202089458703995, 'eval_runtime': 41.2553, 'eval_samples_per_second': 4.848, 'eval_steps_per_second': 0.606, 'epoch': 0.93}
{'train_runtime': 1328.476, 'train_samples_per_second': 8.581, 'train_steps_per_second': 0.269, 'train_loss': 0.5383225652304563, 'epoch': 0.93}

Saving model to /jfan5/sft_models/gpt_oss_20b/cross_domain_pddl3_symbolized ...
Training completed!

==========================================
Fine-tuning completed!
==========================================
Model saved to: /jfan5/sft_models/gpt_oss_20b/cross_domain_pddl3_symbolized


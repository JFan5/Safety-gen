
CondaError: Run 'conda init' before 'conda activate'

==========================================
GRPO Training for Mistral-7B - Blocksworld
==========================================
Base model: /jfan5/sft_models/mistral_variant-blocksworld
Dataset: /jfan5/grpo_data-127/blocksworld.jsonl
Output: /jfan5/grpo_models/mistral_7b-blocksworld-1220-200

Training parameters:
  Epochs: 
  Batch size: 4
  Gradient accumulation: 4
  Learning rate: 1e-5
  Generations per prompt: 8
==========================================

/home/ubuntu/miniconda3/envs/llmstl/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
/home/ubuntu/miniconda3/envs/llmstl/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.
  warnings.warn(
ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.
Unsloth 2025.11.6 patched 32 layers with 0 QKV layers, 0 O layers and 0 MLP layers.
wandb: Currently logged in as: fjl2401 (fjl2401-university-of-notre-dame) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.22.2
wandb: Run data is saved locally in /home/ubuntu/Safety-gen/wandb/run-20251220_161040-389abb9t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grpo_mistral_7b-blocksworld-1220-200
wandb: ‚≠êÔ∏è View project at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-grpo-mistral7b
wandb: üöÄ View run at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-grpo-mistral7b/runs/389abb9t
wandb: Initializing weave.
[36m[1mweave[0m: wandb version 0.23.1 is available!  To upgrade, please run:
[36m[1mweave[0m:  $ pip install wandb --upgrade
[weave.trace.init_message|INFO]wandb version 0.23.1 is available!  To upgrade, please run:
 $ pip install wandb --upgrade
[36m[1mweave[0m: Logged in as Weights & Biases user: fjl2401.
[36m[1mweave[0m: View Weave data at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-grpo-mistral7b/weave
[weave.trace.init_message|INFO]Logged in as Weights & Biases user: fjl2401.
View Weave data at https://wandb.ai/fjl2401-university-of-notre-dame/pddl-grpo-mistral7b/weave
==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1
   \\   /|    Num examples = 500 | Num Epochs = 1 | Total steps = 200
O^O/ \_/ \    Batch size per device = 4 | Gradient accumulation steps = 4
\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16
 "-____-"     Trainable parameters = 83,886,080 of 7,331,909,632 (1.14% trained)
ü¶• Unsloth Zoo will now patch everything to make training faster!
==((====))==  Unsloth 2025.11.6: Fast Mistral patching. Transformers: 4.56.2. vLLM: 0.12.0.
   \\   /|    NVIDIA H100 PCIe. Num GPUs = 1. Max memory: 79.109 GB. Platform: Linux.
O^O/ \_/ \    Torch: 2.9.0+cu128. CUDA: 9.0. CUDA Toolkit: 12.8. Triton: 3.5.0
\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.33.post2. FA2 = False]
 "-____-"     Free license: http://github.com/unslothai/unsloth
Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!
unsloth/mistral-7b-instruct-v0.3-bnb-4bit does not have a padding token! Will use pad_token = [control_768].
============================================================
Reward Function Configuration:
  Using manual discrete reward table: compute_reward
  Scenario-specific reward functions: disabled
============================================================
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [01:05<3:35:44, 65.05s/it]  1%|          | 2/200 [01:37<2:31:29, 45.91s/it]  2%|‚ñè         | 3/200 [02:15<2:18:31, 42.19s/it]  2%|‚ñè         | 4/200 [02:37<1:52:37, 34.48s/it]  2%|‚ñé         | 5/200 [03:10<1:49:18, 33.63s/it]  3%|‚ñé         | 6/200 [03:57<2:03:58, 38.34s/it]  4%|‚ñé         | 7/200 [04:11<1:37:17, 30.25s/it]  4%|‚ñç         | 8/200 [04:17<1:12:20, 22.61s/it]  4%|‚ñç         | 9/200 [05:04<1:36:08, 30.20s/it]  5%|‚ñå         | 10/200 [05:21<1:22:42, 26.12s/it]  6%|‚ñå         | 11/200 [05:40<1:15:10, 23.87s/it]  6%|‚ñå         | 12/200 [05:53<1:05:10, 20.80s/it]  6%|‚ñã         | 13/200 [06:06<57:34, 18.47s/it]    7%|‚ñã         | 14/200 [06:35<1:06:24, 21.42s/it]  8%|‚ñä         | 15/200 [07:19<1:27:02, 28.23s/it]  8%|‚ñä         | 16/200 [07:32<1:12:19, 23.58s/it]  8%|‚ñä         | 17/200 [08:18<1:32:37, 30.37s/it]  9%|‚ñâ         | 18/200 [08:50<1:33:39, 30.88s/it] 10%|‚ñâ         | 19/200 [09:05<1:18:51, 26.14s/it] 10%|‚ñà         | 20/200 [09:36<1:23:23, 27.80s/it]                                                   10%|‚ñà         | 20/200 [09:36<1:23:23, 27.80s/it] 10%|‚ñà         | 21/200 [10:22<1:39:07, 33.22s/it] 11%|‚ñà         | 22/200 [10:43<1:27:10, 29.39s/it] 12%|‚ñà‚ñè        | 23/200 [11:07<1:21:55, 27.77s/it] 12%|‚ñà‚ñè        | 24/200 [11:53<1:37:15, 33.16s/it] 12%|‚ñà‚ñé        | 25/200 [12:38<1:47:48, 36.97s/it] 13%|‚ñà‚ñé        | 26/200 [13:24<1:54:57, 39.64s/it] 14%|‚ñà‚ñé        | 27/200 [14:10<1:59:41, 41.51s/it] 14%|‚ñà‚ñç        | 28/200 [14:56<2:02:43, 42.81s/it] 14%|‚ñà‚ñç        | 29/200 [15:42<2:04:43, 43.76s/it] 15%|‚ñà‚ñå        | 30/200 [16:28<2:05:52, 44.43s/it] 16%|‚ñà‚ñå        | 31/200 [17:14<2:06:19, 44.85s/it] 16%|‚ñà‚ñå        | 32/200 [18:00<2:06:32, 45.19s/it] 16%|‚ñà‚ñã        | 33/200 [18:46<2:06:28, 45.44s/it] 17%|‚ñà‚ñã        | 34/200 [19:32<2:06:05, 45.58s/it] 18%|‚ñà‚ñä        | 35/200 [20:18<2:05:39, 45.69s/it] 18%|‚ñà‚ñä        | 36/200 [21:03<2:05:00, 45.74s/it] 18%|‚ñà‚ñä        | 37/200 [21:49<2:04:15, 45.74s/it] 19%|‚ñà‚ñâ        | 38/200 [22:35<2:03:33, 45.76s/it] 20%|‚ñà‚ñâ        | 39/200 [23:21<2:02:50, 45.78s/it] 20%|‚ñà‚ñà        | 40/200 [24:07<2:02:25, 45.91s/it]                                                   20%|‚ñà‚ñà        | 40/200 [24:07<2:02:25, 45.91s/it] 20%|‚ñà‚ñà        | 41/200 [24:18<1:34:14, 35.56s/it] 21%|‚ñà‚ñà        | 42/200 [25:04<1:41:43, 38.63s/it] 22%|‚ñà‚ñà‚ñè       | 43/200 [25:50<1:46:52, 40.84s/it] 22%|‚ñà‚ñà‚ñè       | 44/200 [25:56<1:19:10, 30.45s/it] 22%|‚ñà‚ñà‚ñé       | 45/200 [26:42<1:30:40, 35.10s/it] 23%|‚ñà‚ñà‚ñé       | 46/200 [27:28<1:38:26, 38.35s/it] 24%|‚ñà‚ñà‚ñé       | 47/200 [28:14<1:43:31, 40.60s/it] 24%|‚ñà‚ñà‚ñç       | 48/200 [29:00<1:46:54, 42.20s/it] 24%|‚ñà‚ñà‚ñç       | 49/200 [29:08<1:20:24, 31.95s/it] 25%|‚ñà‚ñà‚ñå       | 50/200 [29:16<1:01:30, 24.61s/it] 26%|‚ñà‚ñà‚ñå       | 51/200 [29:23<47:56, 19.30s/it]   26%|‚ñà‚ñà‚ñå       | 52/200 [30:08<1:07:15, 27.27s/it] 26%|‚ñà‚ñà‚ñã       | 53/200 [30:17<52:51, 21.58s/it]   27%|‚ñà‚ñà‚ñã       | 54/200 [30:30<46:13, 19.00s/it] 28%|‚ñà‚ñà‚ñä       | 55/200 [31:15<1:05:19, 27.03s/it] 28%|‚ñà‚ñà‚ñä       | 56/200 [31:34<59:04, 24.62s/it]   28%|‚ñà‚ñà‚ñä       | 57/200 [32:20<1:13:47, 30.96s/it] 29%|‚ñà‚ñà‚ñâ       | 58/200 [32:30<58:32, 24.73s/it]   30%|‚ñà‚ñà‚ñâ       | 59/200 [32:41<48:12, 20.51s/it] 30%|‚ñà‚ñà‚ñà       | 60/200 [33:00<46:29, 19.92s/it]                                                 30%|‚ñà‚ñà‚ñà       | 60/200 [33:00<46:29, 19.92s/it] 30%|‚ñà‚ñà‚ñà       | 61/200 [33:47<1:04:53, 28.01s/it] 31%|‚ñà‚ñà‚ñà       | 62/200 [34:32<1:16:47, 33.39s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [35:19<1:24:54, 37.19s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [36:04<1:30:16, 39.82s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [36:51<1:33:48, 41.69s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [37:36<1:35:52, 42.93s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [38:22<1:37:03, 43.78s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [39:08<1:37:41, 44.40s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [39:54<1:37:56, 44.86s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [40:40<1:37:52, 45.17s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [41:26<1:37:39, 45.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [42:12<1:37:13, 45.58s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [42:58<1:36:39, 45.66s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [43:44<1:36:08, 45.79s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [44:30<1:35:27, 45.82s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [45:15<1:34:42, 45.83s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [46:01<1:34:03, 45.88s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [46:28<1:21:24, 40.03s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [47:14<1:24:19, 41.81s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [48:00<1:26:01, 43.01s/it]                                                   40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [48:00<1:26:01, 43.01s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [48:09<1:05:11, 32.87s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [48:55<1:12:20, 36.79s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [49:41<1:17:08, 39.56s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [50:27<1:20:12, 41.48s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [51:12<1:21:57, 42.76s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [51:23<1:02:45, 33.03s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [52:08<1:09:20, 36.82s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [52:54<1:13:46, 39.52s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [53:40<1:16:38, 41.42s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [54:26<1:18:28, 42.81s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [55:12<1:19:27, 43.74s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [55:58<1:19:50, 44.36s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [56:44<1:19:51, 44.78s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [57:30<1:19:42, 45.12s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [58:16<1:19:26, 45.39s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [59:01<1:18:52, 45.51s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [59:47<1:18:15, 45.58s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [1:00:33<1:17:35, 45.64s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [1:01:19<1:16:58, 45.73s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [1:02:05<1:16:19, 45.80s/it]                                                      50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [1:02:05<1:16:19, 45.80s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [1:02:51<1:15:39, 45.85s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [1:03:37<1:14:52, 45.84s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [1:04:23<1:14:08, 45.86s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [1:05:08<1:13:22, 45.86s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [1:05:54<1:12:35, 45.85s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [1:06:40<1:11:51, 45.87s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [1:07:26<1:11:08, 45.90s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [1:08:12<1:10:24, 45.92s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [1:08:58<1:09:33, 45.86s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [1:09:44<1:08:51, 45.91s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [1:10:30<1:08:01, 45.86s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [1:11:15<1:07:16, 45.87s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [1:12:01<1:06:30, 45.87s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [1:12:47<1:05:45, 45.88s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [1:13:33<1:05:02, 45.91s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [1:14:19<1:04:13, 45.87s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [1:15:05<1:03:24, 45.83s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [1:15:51<1:02:37, 45.83s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [1:16:36<1:01:51, 45.83s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [1:17:22<1:01:09, 45.87s/it]                                                      60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [1:17:22<1:01:09, 45.87s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [1:18:09<1:00:46, 46.16s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [1:18:55<59:49, 46.02s/it]   62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [1:19:41<59:03, 46.02s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [1:20:27<58:13, 45.96s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [1:21:13<57:25, 45.95s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [1:21:59<56:41, 45.96s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [1:22:19<46:26, 38.17s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [1:23:04<48:34, 40.48s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [1:23:50<49:51, 42.14s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [1:24:04<39:06, 33.52s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [1:24:50<42:48, 37.23s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [1:25:36<45:07, 39.82s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [1:26:22<46:30, 41.66s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [1:27:07<47:10, 42.89s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [1:27:53<47:24, 43.76s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [1:28:39<47:20, 44.39s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [1:29:25<47:07, 44.87s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [1:30:11<46:40, 45.17s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [1:30:57<46:07, 45.37s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [1:31:43<45:32, 45.54s/it]                                                    70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [1:31:43<45:32, 45.54s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [1:32:28<44:50, 45.59s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [1:32:53<38:04, 39.39s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [1:33:39<39:15, 41.32s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [1:34:25<39:47, 42.63s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [1:35:11<39:57, 43.60s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [1:35:56<39:49, 44.26s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [1:36:42<39:30, 44.73s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [1:37:28<39:03, 45.07s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [1:38:14<38:29, 45.29s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [1:39:00<37:51, 45.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [1:39:45<37:11, 45.54s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [1:40:31<36:31, 45.66s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [1:41:17<35:47, 45.68s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [1:42:03<35:05, 45.78s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [1:42:22<28:14, 37.64s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [1:43:08<29:24, 40.11s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [1:43:53<29:57, 41.81s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [1:44:40<30:09, 43.09s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [1:44:52<23:06, 33.82s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [1:45:37<24:56, 37.41s/it]                                                    80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [1:45:38<24:56, 37.41s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [1:46:23<25:54, 39.87s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [1:47:09<26:22, 41.65s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [1:47:55<26:28, 42.92s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [1:48:41<26:18, 43.84s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [1:49:27<25:57, 44.50s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [1:50:13<25:25, 44.86s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [1:50:59<24:51, 45.20s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [1:51:44<24:11, 45.37s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [1:52:30<23:29, 45.46s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [1:53:16<22:46, 45.55s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [1:54:02<22:04, 45.66s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [1:54:47<21:18, 45.68s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [1:55:33<20:33, 45.68s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [1:56:19<19:48, 45.72s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [1:57:05<19:05, 45.81s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [1:57:51<18:19, 45.83s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [1:58:01<13:29, 35.21s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [1:58:47<14:04, 38.38s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [1:59:33<14:13, 40.65s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [2:00:19<14:04, 42.24s/it]                                                    90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [2:00:19<14:04, 42.24s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [2:01:06<13:48, 43.59s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [2:01:51<13:17, 44.28s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [2:02:37<12:41, 44.78s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [2:03:23<12:00, 45.05s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [2:04:09<11:20, 45.34s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [2:04:55<10:36, 45.49s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [2:05:41<09:52, 45.60s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [2:06:27<09:08, 45.73s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [2:07:13<08:23, 45.78s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [2:07:59<07:38, 45.84s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [2:08:45<06:52, 45.84s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [2:09:30<06:06, 45.82s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [2:09:56<04:38, 39.76s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [2:10:42<04:09, 41.57s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [2:11:28<03:34, 42.82s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [2:12:13<02:54, 43.70s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [2:12:59<02:13, 44.38s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [2:13:45<01:29, 44.82s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [2:14:11<00:39, 39.06s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:14:57<00:00, 41.11s/it]                                                   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:14:57<00:00, 41.11s/it]                                                   100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:14:58<00:00, 41.11s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [2:14:58<00:00, 40.49s/it]
wandb: updating run metadata
wandb: 
wandb: Run history:
wandb:                               batch/scenario_count_blocksworld ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                batch/scenario_rate_blocksworld ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:    profiling/Time taken: UnslothGRPOTrainer._calculate_rewards ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:       profiling/Time taken: UnslothGRPOTrainer._prepare_inputs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      profiling/Time taken: UnslothGRPOTrainer.grpo_reward_func ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÜ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÇ‚ñÇ‚ñÉ
wandb: profiling/Time taken: UnslothGRPOTrainer.transformers.generate ‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                            reward_method/count_manual_discrete ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                             reward_method/rate_manual_discrete ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                 stats/count_goal_not_satisfied ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                                  stats/count_plan_format_error ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                                            +33 ...
wandb: 
wandb: Run summary:
wandb:                                            batch/main_scenario blocksworld
wandb:                               batch/scenario_count_blocksworld 16
wandb:                                batch/scenario_rate_blocksworld 1
wandb:    profiling/Time taken: UnslothGRPOTrainer._calculate_rewards 0.04787
wandb:       profiling/Time taken: UnslothGRPOTrainer._prepare_inputs 1e-05
wandb:      profiling/Time taken: UnslothGRPOTrainer.grpo_reward_func 0.04744
wandb: profiling/Time taken: UnslothGRPOTrainer.transformers.generate 41.25468
wandb:                            reward_method/count_manual_discrete 16
wandb:                             reward_method/rate_manual_discrete 1
wandb:                                 stats/count_goal_not_satisfied 16
wandb:                                                            +39 ...
wandb: 
wandb: üöÄ View run grpo_mistral_7b-blocksworld-1220-200 at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-grpo-mistral7b/runs/389abb9t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/fjl2401-university-of-notre-dame/pddl-grpo-mistral7b
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251220_161040-389abb9t/logs
Unsloth: Will smartly offload gradients to save VRAM!
{'loss': 0.0255, 'grad_norm': 0.03924652561545372, 'learning_rate': 9.5e-06, 'num_tokens': 139785.0, 'completions/mean_length': 228.628125, 'completions/min_length': 111.55, 'completions/max_length': 478.0, 'completions/clipped_ratio': 0.0125, 'completions/mean_terminated_length': 218.70734100341798, 'completions/min_terminated_length': 111.55, 'completions/max_terminated_length': 433.8, 'rewards/grpo_reward_func/mean': 0.12468750700354576, 'rewards/grpo_reward_func/std': 0.7067819997668267, 'reward': 0.12468750700354576, 'reward_std': 0.2700627751648426, 'frac_reward_zero_std': 0.475, 'completion_length': 478.0, 'kl': 2.5519042940810324, 'epoch': 0.08}
{'loss': 0.0119, 'grad_norm': 428.46783447265625, 'learning_rate': 8.944444444444446e-06, 'num_tokens': 359131.0, 'completions/mean_length': 479.55625, 'completions/min_length': 104.7, 'completions/max_length': 969.8, 'completions/clipped_ratio': 0.359375, 'completions/mean_terminated_length': 177.4851739883423, 'completions/min_terminated_length': 104.7, 'completions/max_terminated_length': 375.05, 'rewards/grpo_reward_func/mean': -0.07593749463558197, 'rewards/grpo_reward_func/std': 0.49844731837511064, 'reward': -0.07593749463558197, 'reward_std': 0.19537473991513252, 'frac_reward_zero_std': 0.65, 'completion_length': 969.8, 'kl': 1.186561393365264, 'epoch': 0.16}
{'loss': 0.0049, 'grad_norm': 0.0251177791506052, 'learning_rate': 7.833333333333333e-06, 'num_tokens': 489219.0, 'completions/mean_length': 203.525, 'completions/min_length': 95.7, 'completions/max_length': 581.45, 'completions/clipped_ratio': 0.071875, 'completions/mean_terminated_length': 144.87154731750488, 'completions/min_terminated_length': 95.7, 'completions/max_terminated_length': 292.1, 'rewards/grpo_reward_func/mean': 0.06281249970197678, 'rewards/grpo_reward_func/std': 0.5165819898247719, 'reward': 0.06281249970197678, 'reward_std': 0.1886855736374855, 'frac_reward_zero_std': 0.675, 'completion_length': 581.45, 'kl': 0.49278192687779665, 'epoch': 0.24}
{'loss': 0.0042, 'grad_norm': 0.009794003330171108, 'learning_rate': 6.7222222222222235e-06, 'num_tokens': 669418.0, 'completions/mean_length': 358.921875, 'completions/min_length': 87.55, 'completions/max_length': 1001.65, 'completions/clipped_ratio': 0.21875, 'completions/mean_terminated_length': 174.8288604736328, 'completions/min_terminated_length': 87.55, 'completions/max_terminated_length': 419.3, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 1001.65, 'kl': 0.4232473663985729, 'epoch': 0.32}
{'loss': 0.0063, 'grad_norm': 0.1450539082288742, 'learning_rate': 5.611111111111112e-06, 'num_tokens': 845884.0, 'completions/mean_length': 349.75625, 'completions/min_length': 91.35, 'completions/max_length': 940.95, 'completions/clipped_ratio': 0.1875, 'completions/mean_terminated_length': 208.0478202819824, 'completions/min_terminated_length': 91.35, 'completions/max_terminated_length': 503.85, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 940.95, 'kl': 0.6316476076841354, 'epoch': 0.4}
{'loss': 0.004, 'grad_norm': 0.05039534345269203, 'learning_rate': 4.5e-06, 'num_tokens': 1024456.0, 'completions/mean_length': 352.6375, 'completions/min_length': 90.55, 'completions/max_length': 1024.0, 'completions/clipped_ratio': 0.175, 'completions/mean_terminated_length': 210.62905807495116, 'completions/min_terminated_length': 90.55, 'completions/max_terminated_length': 518.15, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 1024.0, 'kl': 0.3975138427689672, 'epoch': 0.48}
{'loss': 0.0043, 'grad_norm': 0.21959678828716278, 'learning_rate': 3.3888888888888893e-06, 'num_tokens': 1210133.0, 'completions/mean_length': 372.990625, 'completions/min_length': 114.1, 'completions/max_length': 957.0, 'completions/clipped_ratio': 0.1625, 'completions/mean_terminated_length': 250.20111541748048, 'completions/min_terminated_length': 114.1, 'completions/max_terminated_length': 614.75, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 957.0, 'kl': 0.43052918538451196, 'epoch': 0.56}
{'loss': 0.0043, 'grad_norm': 0.04853089153766632, 'learning_rate': 2.277777777777778e-06, 'num_tokens': 1388530.0, 'completions/mean_length': 355.090625, 'completions/min_length': 89.9, 'completions/max_length': 930.25, 'completions/clipped_ratio': 0.171875, 'completions/mean_terminated_length': 219.23867835998536, 'completions/min_terminated_length': 89.9, 'completions/max_terminated_length': 580.6, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 930.25, 'kl': 0.43166575506329535, 'epoch': 0.64}
{'loss': 0.0575, 'grad_norm': 0.11589503288269043, 'learning_rate': 1.1666666666666668e-06, 'num_tokens': 1561825.0, 'completions/mean_length': 339.896875, 'completions/min_length': 93.55, 'completions/max_length': 983.15, 'completions/clipped_ratio': 0.15, 'completions/mean_terminated_length': 220.0259105682373, 'completions/min_terminated_length': 93.55, 'completions/max_terminated_length': 600.65, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 983.15, 'kl': 5.7526938140392305, 'epoch': 0.72}
{'loss': 0.0041, 'grad_norm': 0.015608476474881172, 'learning_rate': 5.555555555555556e-08, 'num_tokens': 1749021.0, 'completions/mean_length': 381.8875, 'completions/min_length': 96.25, 'completions/max_length': 977.65, 'completions/clipped_ratio': 0.178125, 'completions/mean_terminated_length': 246.15206985473634, 'completions/min_terminated_length': 96.25, 'completions/max_terminated_length': 621.05, 'rewards/grpo_reward_func/mean': -0.20000000298023224, 'rewards/grpo_reward_func/std': 0.0, 'reward': -0.20000000298023224, 'reward_std': 0.0, 'frac_reward_zero_std': 1.0, 'completion_length': 977.65, 'kl': 0.4083814058452845, 'epoch': 0.8}
{'train_runtime': 8098.0898, 'train_samples_per_second': 0.395, 'train_steps_per_second': 0.025, 'train_loss': 0.012706926986575127, 'epoch': 0.8}

==========================================
GRPO training completed!
==========================================
Model saved to: /jfan5/grpo_models/mistral_7b-blocksworld-1220-200

